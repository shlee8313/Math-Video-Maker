
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.1
=====================================

Claude Code í†µí•© ë²„ì „
- ì°½ì˜ì  ì‘ì—…(ëŒ€ë³¸, ì”¬, Manim ì½”ë“œ): Claude Codeê°€ skills/*.md ì°¸ì¡°í•˜ì—¬ ìƒì„±
- API ì‘ì—…(TTS, Whisper): ì´ Python ìŠ¤í¬ë¦½íŠ¸ê°€ ë‹´ë‹¹
- íŒŒì¼ ê´€ë¦¬: state.jsonìœ¼ë¡œ ì§„í–‰ ìƒíƒœ ì¶”ì 

ì‚¬ìš©ë²•:
    python math_video_pipeline.py --help
    python math_video_pipeline.py init --title "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬" --duration 480
    python math_video_pipeline.py tts --scene s1 --text "ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸"
    python math_video_pipeline.py tts-all
    python math_video_pipeline.py status
    python math_video_pipeline.py render --scene s1
    python math_video_pipeline.py render-all
"""

import argparse
import json
import os
import sys
import io
import subprocess
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì • (Windows ì½˜ì†” í˜¸í™˜)
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ============================================================================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (TTS + Whisper)
# ============================================================================

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (TTS/Whisperìš©).")
    print("   ì„¤ì¹˜: pip install openai")

try:
    from google.cloud import texttospeech
    GOOGLE_TTS_AVAILABLE = True
except ImportError:
    GOOGLE_TTS_AVAILABLE = False
    print("âš ï¸  Google Cloud TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install google-cloud-texttospeech")

# Gemini TTS (google-genai)
try:
    from google import genai
    from google.genai import types
    GEMINI_TTS_AVAILABLE = True
except ImportError:
    GEMINI_TTS_AVAILABLE = False
    print("âš ï¸  Gemini TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install google-genai")

import wave

# Supabase (ì—ì…‹ ê´€ë¦¬)
try:
    from supabase import create_client, Client as SupabaseClient
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âš ï¸  Supabase ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install supabase")

# PIL (ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°)
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False


# ============================================================================
# ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤
# ============================================================================

class QuotaExceededException(Exception):
    """API ì¼ì¼ í•œë„ ì´ˆê³¼ ì˜ˆì™¸"""
    pass


def get_openai_client() -> Optional['OpenAI']:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if not OPENAI_AVAILABLE:
        return None
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("OPENAI_API_KEY="):
                        api_key = line.split("=", 1)[1].strip().strip('"\'')
                        break
    
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— OPENAI_API_KEY=sk-... ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None
    
    return OpenAI(api_key=api_key)


def get_google_tts_client() -> Optional['texttospeech.TextToSpeechClient']:
    """Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if not GOOGLE_TTS_AVAILABLE:
        return None

    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if not credentials_path:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("GOOGLE_APPLICATION_CREDENTIALS="):
                        credentials_path = line.split("=", 1)[1].strip().strip('"\'')
                        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
                        break

    if not credentials_path or not Path(credentials_path).exists():
        print("âŒ GOOGLE_APPLICATION_CREDENTIALSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— GOOGLE_APPLICATION_CREDENTIALS=ê²½ë¡œ ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    try:
        return texttospeech.TextToSpeechClient()
    except Exception as e:
        print(f"âŒ Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def get_gemini_client() -> Optional['genai.Client']:
    """Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± (TTSìš©)"""
    if not GEMINI_TTS_AVAILABLE:
        return None

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("GOOGLE_API_KEY="):
                        api_key = line.split("=", 1)[1].strip().strip('"\'')
                        break

    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Gemini TTSìš©).")
        print("   .env íŒŒì¼ì— GOOGLE_API_KEY=... ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    try:
        return genai.Client(api_key=api_key)
    except Exception as e:
        print(f"âŒ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


# ============================================================================
# ì„¤ì • ë° ìƒìˆ˜
# ============================================================================

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬)
PROJECT_ROOT = Path(__file__).parent.resolve()

# ì£¼ìš” ê²½ë¡œ
STATE_FILE = PROJECT_ROOT / "state.json"
OUTPUT_DIR = PROJECT_ROOT / "output"
SKILLS_DIR = PROJECT_ROOT / "skills"

# TTS ì„¤ì • (OpenAI gpt-4o-mini-tts)
TTS_CONFIG = {
    "voices": {
        "ash": "ì°¨ë¶„í•œ ë‚¨ì„± (ê¸°ë³¸ê°’)",
        "alloy": "ì¤‘ì„±ì , ê· í˜•ì¡íŒ",
        "ballad": "ë¶€ë“œëŸ¬ìš´ ë‚­ë…",
        "coral": "ë”°ëœ»í•œ ì—¬ì„±",
        "echo": "ë‚¨ì„±ì , ì°¨ë¶„í•¨",
        "fable": "ì˜êµ­ì‹ ì–µì–‘",
        "onyx": "ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬",
        "nova": "ì—¬ì„±ì , ë°ê³  ì¹œê·¼",
        "sage": "ì§€ì ì¸ í†¤",
        "shimmer": "ì—¬ì„±ì , ë¶€ë“œëŸ¬ì›€",
        "verse": "í‘œí˜„ë ¥ í’ë¶€",
        "marin": "ê³ í’ˆì§ˆ",
        "cedar": "ê³ í’ˆì§ˆ"
    },
    "default_voice": "alloy",
    "model": "gpt-4o-mini-tts",
    "audio_encoding": "MP3"
}

# ìŠ¤íƒ€ì¼ ì„¤ì •
STYLE_CONFIG = {
    "minimal": {
        "glow": False,
        "primary_color": "WHITE",
        "background_color": "BLACK",
        "flash_frequency": "low"
    },
    "cyberpunk": {
        "glow": True,
        "primary_color": "CYAN",
        "background_color": "#0a0a0a",
        "flash_frequency": "high"
    },
    "paper": {
        "glow": False,
        "primary_color": "BLACK",
        "background_color": "#f5f5dc",
        "flash_frequency": "medium"
    },
    "space": {
        "glow": True,
        "primary_color": "BLUE",
        "background_color": "#000011",
        "flash_frequency": "medium"
    },
    "geometric": {
        "glow": False,
        "primary_color": "GOLD",
        "background_color": "#1a1a1a",
        "flash_frequency": "medium"
    },
    "stickman": {
        "glow": False,
        "primary_color": "WHITE",
        "background_color": "#1a1a2e",
        "flash_frequency": "medium"
    }
}

# ì»¬ëŸ¬ íŒ”ë ˆíŠ¸
COLOR_PALETTE = {
    "variable": "YELLOW",
    "constant": "ORANGE",
    "result": "GREEN",
    "emphasis": "RED",
    "auxiliary": "GRAY_B"
}


# ============================================================================
# ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class StateManager:
    """í”„ë¡œì íŠ¸ ìƒíƒœ ê´€ë¦¬"""
    
    def __init__(self, state_file: Path = STATE_FILE):
        self.state_file = state_file
        self._state = None
    
    def load(self) -> Dict[str, Any]:
        """state.json ë¡œë“œ"""
        if self._state is not None:
            return self._state

        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    self._state = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸  {self.state_file} íŒŒì‹± ì˜¤ë¥˜. ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                self._state = self._default_state()
        else:
            self._state = self._default_state()

        return self._state

    def reload(self) -> Dict[str, Any]:
        """state.json ê°•ì œ ì¬ë¡œë“œ (ìºì‹œ ë¬´ì‹œ)"""
        self._state = None
        return self.load()
    
    def save(self) -> None:
        """state.json ì €ì¥"""
        if self._state is None:
            self._state = self._default_state()
        
        self._state["last_updated"] = datetime.now().isoformat()
        
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self._state, f, ensure_ascii=False, indent=2)
    
    def _default_state(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìƒíƒœ"""
        return {
            "project_id": None,
            "title": None,
            "current_phase": "idle",
            "settings": {
                "style": "cyberpunk",
                "difficulty": "intermediate",
                "duration": 480,
                "aspect_ratio": "16:9",
                "voice": "ko-KR-Neural2-C",
                "subtitle_style": "karaoke"
            },
            "scenes": {
                "total": 0,
                "completed": [],
                "pending": [],
                "current": None
            },
            "files": {
                "script": None,
                "tts_script": None,
                "scenes": None,
                "audio": [],
                "manim": [],
                "subtitles": []
            },
            "last_updated": None
        }
    
    def get(self, key: str, default: Any = None) -> Any:
        """ìƒíƒœ ê°’ ì¡°íšŒ"""
        state = self.load()
        keys = key.split(".")
        value = state
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        return value
    
    def set(self, key: str, value: Any) -> None:
        """ìƒíƒœ ê°’ ì„¤ì •"""
        state = self.load()
        keys = key.split(".")
        target = state
        for k in keys[:-1]:
            if k not in target:
                target[k] = {}
            target = target[k]
        target[keys[-1]] = value
        self._state = state
    
    def update_phase(self, phase: str) -> None:
        """í˜„ì¬ ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        self.set("current_phase", phase)
        self.save()
        print(f"âœ… state.json ì—…ë°ì´íŠ¸ë¨: current_phase = {phase}")
    
    def add_completed_scene(self, scene_id: str) -> None:
        """ì™„ë£Œëœ ì”¬ ì¶”ê°€"""
        state = self.load()
        
        if scene_id in state["scenes"]["pending"]:
            state["scenes"]["pending"].remove(scene_id)
        
        if scene_id not in state["scenes"]["completed"]:
            state["scenes"]["completed"].append(scene_id)
        
        # í˜„ì¬ ì”¬ ì—…ë°ì´íŠ¸
        if state["scenes"]["pending"]:
            state["scenes"]["current"] = state["scenes"]["pending"][0]
        else:
            state["scenes"]["current"] = None
        
        self._state = state
        self.save()
    
    def add_file(self, category: str, filepath: str) -> None:
        """íŒŒì¼ ê²½ë¡œ ì¶”ê°€"""
        state = self.load()
        
        if category not in state["files"]:
            state["files"][category] = []
        
        if isinstance(state["files"][category], list):
            if filepath not in state["files"][category]:
                state["files"][category].append(filepath)
        else:
            state["files"][category] = filepath
        
        self._state = state
        self.save()
    
    # ========================================================================
    # /clear í›„ ì¬ê°œë¥¼ ìœ„í•œ ìƒì„¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤
    # ========================================================================
    
    def update_script_approved(self, project_id: str) -> None:
        """Step 2 ì™„ë£Œ: ëŒ€ë³¸ ìŠ¹ì¸ í›„"""
        state = self.load()
        
        state['current_phase'] = 'script_approved'
        
        # files ì´ˆê¸°í™”
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['script'] = f"output/{project_id}/1_script/reading_script.json"
        state['files']['tts_script'] = f"output/{project_id}/1_script/tts_script.json"
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: script_approved")
        print(f"   ğŸ“ ëŒ€ë³¸ ê²½ë¡œ: {state['files']['script']}")
    
    def update_scenes_approved(self, project_id: str, scene_ids: List[str]) -> None:
        """Step 3 ì™„ë£Œ: ì”¬ ë¶„í•  ìŠ¹ì¸ í›„"""
        state = self.load()
        
        state['current_phase'] = 'scenes_approved'
        
        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['scenes'] = f"output/{project_id}/2_scenes/scenes.json"
        
        # scenes ì •ë³´ ì—…ë°ì´íŠ¸
        state['scenes'] = {
            'total': len(scene_ids),
            'completed': [],
            'pending': scene_ids,
            'current': scene_ids[0] if scene_ids else None
        }
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: scenes_approved")
        print(f"   ğŸ¬ ì”¬ ë¶„í• : {len(scene_ids)}ê°œ ì”¬")
    
    def update_tts_completed(self, project_id: str, audio_files: List[str]) -> None:
        """Step 4 ì™„ë£Œ: TTS ìƒì„± ì™„ë£Œ í›„"""
        state = self.load()
        
        state['current_phase'] = 'tts_completed'
        
        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['audio'] = audio_files
        
        self._state = state
        self.save()

        print(f"âœ… state.json ì—…ë°ì´íŠ¸: tts_completed")
        print(f"   ğŸ¤ TTS ì™„ë£Œ: {len(audio_files)}ê°œ íŒŒì¼")

    def update_tts_partial(self, project_id: str, audio_files: List[str], resume_from: int) -> None:
        """TTS ë¶€ë¶„ ì™„ë£Œ: í•œë„ ì´ˆê³¼ë¡œ ì¤‘ë‹¨ë¨"""
        state = self.load()

        state['current_phase'] = 'tts_partial'
        state['tts_resume_from'] = resume_from

        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None,
                'tts_script': None,
                'scenes': None,
                'audio': [],
                'manim': [],
                'subtitles': []
            }

        state['files']['audio'] = audio_files

        self._state = state
        self.save()

        print(f"âš ï¸  state.json ì—…ë°ì´íŠ¸: tts_partial (s{resume_from}ë¶€í„° ì¬ê°œ í•„ìš”)")

    def update_manim_scene_completed(self, scene_id: str, manim_file: str) -> None:
        """Step 5 ì§„í–‰: ì”¬ë³„ Manim ì½”ë“œ ì™„ë£Œ í›„"""
        state = self.load()
        
        state['current_phase'] = 'manim_coding'
        
        # scenes ì—…ë°ì´íŠ¸
        if 'scenes' not in state:
            state['scenes'] = {'total': 0, 'completed': [], 'pending': [], 'current': None}
        
        # completedì— ì¶”ê°€
        if scene_id not in state['scenes']['completed']:
            state['scenes']['completed'].append(scene_id)
        
        # pendingì—ì„œ ì œê±°
        if scene_id in state['scenes']['pending']:
            state['scenes']['pending'].remove(scene_id)
        
        # current ì—…ë°ì´íŠ¸ (ë‹¤ìŒ pending ì”¬)
        if state['scenes']['pending']:
            state['scenes']['current'] = state['scenes']['pending'][0]
        else:
            state['scenes']['current'] = None
            state['current_phase'] = 'manim_completed'
        
        # files.manim ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        if manim_file not in state['files']['manim']:
            state['files']['manim'].append(manim_file)
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: {scene_id} ì½”ë“œ ì™„ë£Œ")
        print(f"   ì™„ë£Œ: {state['scenes']['completed']}")
        print(f"   ë‚¨ìŒ: {state['scenes']['pending']}")
    
    def update_rendering(self) -> None:
        """Step 6: ë Œë”ë§ ì‹œì‘"""
        state = self.load()
        state['current_phase'] = 'rendering'
        self._state = state
        self.save()
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: rendering")
    
    def update_completed(self, final_video_path: str) -> None:
        """ëª¨ë“  ì‘ì—… ì™„ë£Œ"""
        state = self.load()
        
        state['current_phase'] = 'completed'
        
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['final_video'] = final_video_path
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: completed")
        print(f"   ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ: {final_video_path}")
    
    def get_resume_point(self) -> tuple:
        """ì¬ê°œ ì§€ì  í™•ì¸ ë° ì•ˆë‚´"""
        state = self.load()
        
        if not state.get("project_id"):
            return ("ì‹œì‘", "ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”. python math_video_pipeline.py init --title \"ì£¼ì œ\"")
        
        phase = state.get('current_phase', 'initialized')
        
        resume_guide = {
            'idle': ('ì‹œì‘', 'ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”.'),
            'initialized': ('ëŒ€ë³¸ ì‘ì„±', 'skills/script-writer.mdë¥¼ ì°¸ì¡°í•˜ì—¬ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.'),
            'script_approved': ('ì”¬ ë¶„í• ', 'skills/scene-director.mdë¥¼ ì°¸ì¡°í•˜ì—¬ ì”¬ì„ ë¶„í• í•˜ì„¸ìš”.'),
            'scenes_approved': ('TTS ìƒì„±', 'python math_video_pipeline.py tts-all ì‹¤í–‰'),
            'tts_completed': ('Manim ì½”ë“œ', f"ì”¬ {state.get('scenes', {}).get('current', 's1')} ì½”ë“œ ì‘ì„±"),
            'manim_coding': ('Manim ì½”ë“œ ê³„ì†', f"ì”¬ {state.get('scenes', {}).get('current', 's1')} ì½”ë“œ ì‘ì„±"),
            'manim_completed': ('ë Œë”ë§', 'python math_video_pipeline.py render-all ì‹¤í–‰'),
            'rendering': ('ë Œë”ë§ ëŒ€ê¸°', 'ë Œë”ë§ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'),
            'completed': ('ì™„ë£Œ', 'í”„ë¡œì íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
        }
        
        next_step, guide = resume_guide.get(phase, ('ì•Œ ìˆ˜ ì—†ìŒ', 'ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.'))
        
        return (next_step, guide)


# ============================================================================
# í”„ë¡œì íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class ProjectManager:
    """í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ë° ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def init_project(
        self,
        title: str,
        duration: int = 480,
        style: str = "cyberpunk",
        difficulty: str = "intermediate",
        aspect_ratio: str = "16:9",
        voice: str = "ko-KR-Neural2-C"
    ) -> str:
        """ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”"""
        
        # í”„ë¡œì íŠ¸ ID ìƒì„±
        project_id = f"P{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        project_dir = OUTPUT_DIR / project_id
        folders = [
            "0_audio",
            "1_script",
            "2_scenes",
            "3_visual_plans",
            "4_manim_code",
            "5_validation",
            "6_image_prompts",
            "7_subtitles",
            "8_renders",
            "9_backgrounds",
            "10_scene_final"
        ]
        
        for folder in folders:
            (project_dir / folder).mkdir(parents=True, exist_ok=True)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state.set("project_id", project_id)
        self.state.set("title", title)
        self.state.set("current_phase", "initialized")
        self.state.set("settings.style", style)
        self.state.set("settings.difficulty", difficulty)
        self.state.set("settings.duration", duration)
        self.state.set("settings.aspect_ratio", aspect_ratio)
        self.state.set("settings.voice", voice)
        self.state.set("scenes.total", 0)
        self.state.set("scenes.completed", [])
        self.state.set("scenes.pending", [])
        self.state.set("scenes.current", None)
        self.state.set("files.script", None)
        self.state.set("files.tts_script", None)
        self.state.set("files.scenes", None)
        self.state.set("files.audio", [])
        self.state.set("files.manim", [])
        self.state.set("files.subtitles", [])
        self.state.save()
        
        print(f"âœ… í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ: {project_id}")
        print(f"   ğŸ“ ì¶œë ¥ í´ë”: {project_dir}")
        print(f"   ğŸ“ ì œëª©: {title}")
        print(f"   â±ï¸  ê¸¸ì´: {duration}ì´ˆ ({duration//60}ë¶„ {duration%60}ì´ˆ)")
        print(f"   ğŸ“ ì¢…íš¡ë¹„: {aspect_ratio}")
        print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {style}")
        print(f"   ğŸ“Š ë‚œì´ë„: {difficulty}")
        print(f"   ğŸ¤ ìŒì„±: {voice}")
        print()
        print("ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        print("   Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±ì„ ìš”ì²­í•˜ì„¸ìš”:")
        print(f'   "skills/script-writer.md ì½ê³  "{title}" ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"')
        
        return project_id
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def show_status(self) -> None:
        """í˜„ì¬ ìƒíƒœ ì¶œë ¥"""
        state = self.state.load()
        
        print("\n" + "="*60)
        print("ğŸ“Š í”„ë¡œì íŠ¸ ìƒíƒœ")
        print("="*60)
        
        if not state["project_id"]:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("\nìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘:")
            print('   python math_video_pipeline.py init --title "ì£¼ì œ"')
            return
        
        print(f"ğŸ†” í”„ë¡œì íŠ¸ ID: {state['project_id']}")
        print(f"ğŸ“ ì œëª©: {state['title']}")
        print(f"ğŸ“ í˜„ì¬ ë‹¨ê³„: {state['current_phase']}")
        print()
        
        settings = state.get("settings", {})
        print("âš™ï¸  ì„¤ì •:")
        print(f"   ìŠ¤íƒ€ì¼: {settings.get('style', 'N/A')}")
        print(f"   ë‚œì´ë„: {settings.get('difficulty', 'N/A')}")
        print(f"   ê¸¸ì´: {settings.get('duration', 0)}ì´ˆ")
        print(f"   ì¢…íš¡ë¹„: {settings.get('aspect_ratio', 'N/A')}")
        print(f"   ìŒì„±: {settings.get('voice', 'N/A')}")
        print()
        
        scenes = state.get("scenes", {})
        print("ğŸ¬ ì”¬ ì§„í–‰ ìƒí™©:")
        print(f"   ì´ ì”¬: {scenes.get('total', 0)}ê°œ")
        print(f"   ì™„ë£Œ: {len(scenes.get('completed', []))}ê°œ {scenes.get('completed', [])}")
        print(f"   ëŒ€ê¸°: {len(scenes.get('pending', []))}ê°œ {scenes.get('pending', [])}")
        print(f"   í˜„ì¬: {scenes.get('current', 'N/A')}")
        print()
        
        files = state.get("files", {})
        print("ğŸ“ íŒŒì¼:")
        print(f"   ëŒ€ë³¸: {'âœ… ' + files.get('script') if files.get('script') else 'âŒ ì—†ìŒ'}")
        print(f"   TTSëŒ€ë³¸: {'âœ… ' + files.get('tts_script') if files.get('tts_script') else 'âŒ ì—†ìŒ'}")
        print(f"   ì”¬: {'âœ… ' + files.get('scenes') if files.get('scenes') else 'âŒ ì—†ìŒ'}")
        print(f"   ì˜¤ë””ì˜¤: {len(files.get('audio', []))}ê°œ")
        print(f"   Manim: {len(files.get('manim', []))}ê°œ")
        print(f"   ìë§‰: {len(files.get('subtitles', []))}ê°œ")
        print()
        
        if state.get("last_updated"):
            print(f"ğŸ• ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {state['last_updated']}")
        
        print("="*60)
        
        # ì¬ê°œ ì§€ì  ì•ˆë‚´
        next_step, guide = self.state.get_resume_point()
        print(f"\nğŸ”„ ì¬ê°œ ì§€ì : {next_step}")
        print(f"   ğŸ“Œ {guide}")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        self._suggest_next_step(state)
    
    def _suggest_next_step(self, state: Dict) -> None:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        phase = state.get("current_phase", "idle")
        
        print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        
        if phase == "idle":
            print('   í”„ë¡œì íŠ¸ ì‹œì‘: python math_video_pipeline.py init --title "ì£¼ì œ"')
        
        elif phase == "initialized":
            print("   Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±:")
            print('   "skills/script-writer.md ì½ê³  ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"')
        
        elif phase == "script_approved":
            print("   Claude Codeì—ì„œ ì”¬ ë¶„í• :")
            print('   "skills/scene-director.md ì½ê³  ì”¬ ë¶„í• í•´ì¤˜"')
        
        elif phase == "scenes_approved":
            print("   TTS ìƒì„±: python math_video_pipeline.py tts-all")
        
        elif phase == "tts_completed":
            current = state.get("scenes", {}).get("current", "s1")
            print(f"   Claude Codeì—ì„œ Manim ì½”ë“œ:")
            print(f'   "skills/manim-coder.md ì½ê³  {current} ì½”ë“œ ìƒì„±í•´ì¤˜"')
        
        elif phase == "manim_coding":
            pending = state.get("scenes", {}).get("pending", [])
            if pending:
                next_scene = pending[0]
                print(f"   ë‹¤ìŒ ì”¬ ì²˜ë¦¬: {next_scene}")
                print(f'   "skills/manim-coder.md ì½ê³  {next_scene} ì½”ë“œ ìƒì„±í•´ì¤˜"')
            else:
                print("   ëª¨ë“  ì”¬ ì™„ë£Œ! ë Œë”ë§ ì¤€ë¹„:")
                print("   python math_video_pipeline.py render-all")
        
        elif phase == "manim_completed":
            print("   ë Œë”ë§ ì‹¤í–‰:")
            print("   python math_video_pipeline.py render-all")
        
        elif phase == "completed":
            print("   ğŸ‰ í”„ë¡œì íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


# ============================================================================
# TTS ìƒì„±ê¸° í´ë˜ìŠ¤
# ============================================================================

class TTSGenerator:
    """OpenAI TTS (gpt-4o-mini-tts) - ë¬¸ì¥ë³„ ë¶„í•  ìƒì„±"""

    # OpenAI gpt-4o-mini-tts ì§€ì› ìŒì„± (13ê°œ)
    OPENAI_VOICES = {
        "alloy": "ì¤‘ì„±ì , ê· í˜•ì¡íŒ",
        "ash": "ì°¨ë¶„í•œ ë‚¨ì„± [ê¸°ë³¸ê°’]",
        "ballad": "ë¶€ë“œëŸ¬ìš´ ë‚­ë…",
        "coral": "ë”°ëœ»í•œ ì—¬ì„±",
        "echo": "ë‚¨ì„±ì , ì°¨ë¶„í•¨",
        "fable": "ì˜êµ­ì‹ ì–µì–‘",
        "onyx": "ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬",
        "nova": "ì—¬ì„±ì , ë°ê³  ì¹œê·¼",
        "sage": "ì§€ì ì¸ í†¤",
        "shimmer": "ì—¬ì„±ì , ë¶€ë“œëŸ¬ì›€",
        "verse": "í‘œí˜„ë ¥ í’ë¶€",
        "marin": "ê³ í’ˆì§ˆ ì¶”ì²œ",
        "cedar": "ê³ í’ˆì§ˆ ì¶”ì²œ",
    }

    # í•œêµ­ì–´ TTS ê¸°ë³¸ instructions
    DEFAULT_INSTRUCTIONS = "Speak in a deep, calm, educational Korean tone with clear pronunciation."

    def __init__(self, state_manager: StateManager):
        self.state = state_manager
        self.openai_client = get_openai_client()

    def _split_into_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ì¤„ë°”ê¿ˆ ê¸°ì¤€)

        TTS ë…¹ìŒì„ ìœ„í•´ ê° ì¤„ì„ ê°œë³„ ë¬¸ì¥ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        - \n\n (ë¹ˆ ì¤„): ë¬¸ë‹¨ êµ¬ë¶„
        - \n (ì¤„ë°”ê¿ˆ): ë¬¸ì¥ êµ¬ë¶„
        """
        # ëª¨ë“  ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í•  (ë¹ˆ ì¤„ì´ë“  ë‹¨ì¼ ì¤„ë°”ê¿ˆì´ë“ )
        lines = [line.strip() for line in text.split('\n') if line.strip()]

        return lines

    def _save_wav(self, filename: Path, pcm_data: bytes, channels: int = 1, rate: int = 24000, sample_width: int = 2):
        """PCM ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥"""
        with wave.open(str(filename), "wb") as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(rate)
            wf.writeframes(pcm_data)

    def _get_wav_duration(self, filename: Path) -> float:
        """WAV íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ê³„ì‚°"""
        try:
            with wave.open(str(filename), "rb") as wf:
                frames = wf.getnframes()
                rate = wf.getframerate()
                return frames / float(rate)
        except:
            return 0.0

    def _save_partial_timing(self, audio_dir: Path, scene_id: str, voice_name: str,
                             sentence_results: list, audio_files: list, total_duration: float):
        """ë¶€ë¶„ ì™„ë£Œëœ TTS íƒ€ì´ë° ì €ì¥ (í•œë„ ì´ˆê³¼ ì‹œ ì‚¬ìš©)"""
        timing_file = audio_dir / f"{scene_id}_timing_partial.json"
        timing_data = {
            "scene_id": scene_id,
            "voice": voice_name,
            "total_duration": total_duration,
            "sentence_count": len(sentence_results),
            "sentences": sentence_results,
            "audio_files": audio_files,
            "created_at": datetime.now().isoformat(),
            "status": "partial"  # ë¶€ë¶„ ì™„ë£Œ í‘œì‹œ
        }
        with open(timing_file, 'w', encoding='utf-8') as f:
            json.dump(timing_data, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ“ ë¶€ë¶„ ì €ì¥: {timing_file}")

    def _generate_openai_tts(self, text: str, voice: str, output_file: Path,
                              instructions: str = None, max_retries: int = 3) -> bool:
        """OpenAI gpt-4o-mini-ttsë¡œ ìŒì„± ìƒì„± (MP3 ì¶œë ¥)"""
        import time

        # instructions ê¸°ë³¸ê°’
        if instructions is None:
            instructions = self.DEFAULT_INSTRUCTIONS

        for attempt in range(max_retries):
            try:
                response = self.openai_client.audio.speech.create(
                    model="gpt-4o-mini-tts",  # ìƒˆ ëª¨ë¸ (í•œêµ­ì–´ í’ˆì§ˆ ê°œì„ , ì €ë ´)
                    voice=voice,
                    input=text,
                    instructions=instructions,  # ìŒì„± ìŠ¤íƒ€ì¼ ì§€ì •
                    response_format="mp3"
                )

                # MP3 íŒŒì¼ë¡œ ì €ì¥
                mp3_file = output_file.with_suffix('.mp3')
                response.stream_to_file(str(mp3_file))

                # ì„±ê³µ í›„ ì§§ì€ ëŒ€ê¸° (Rate limit ë°©ì§€)
                time.sleep(0.3)
                return True

            except Exception as e:
                error_str = str(e).lower()
                if "429" in str(e) or "rate" in error_str:
                    wait_time = 5 * (2 ** attempt)  # 5, 10, 20ì´ˆ
                    print(f"      â³ Rate limit - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"      âŒ OpenAI TTS ì‹¤íŒ¨: {e}")
                    if attempt < max_retries - 1:
                        time.sleep(2)

        return False

    def _get_mp3_duration(self, filename: Path) -> float:
        """MP3 íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ê³„ì‚° (mutagen ë˜ëŠ” ffprobe ì‚¬ìš©)"""
        try:
            # mutagen ì‹œë„
            from mutagen.mp3 import MP3
            audio = MP3(str(filename))
            return audio.info.length
        except ImportError:
            pass
        except Exception:
            pass

        try:
            # ffprobe ì‹œë„
            import subprocess
            result = subprocess.run(
                ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                 '-of', 'csv=p=0', str(filename)],
                capture_output=True, text=True
            )
            if result.returncode == 0 and result.stdout.strip():
                return float(result.stdout.strip())
        except Exception:
            pass

        return 0.0

    def _extract_voice_name(self, voice_setting: str) -> str:
        """ì„¤ì •ì—ì„œ OpenAI ìŒì„± ì´ë¦„ ì¶”ì¶œ"""
        voice_setting_lower = voice_setting.lower()
        for voice_name in self.OPENAI_VOICES.keys():
            if voice_name in voice_setting_lower:
                return voice_name
        return "ash"  # ê¸°ë³¸ê°’

    # ========================================================================
    # [DEPRECATED] ê¸°ì¡´ generate() - ë¬¸ì¥ë³„ TTS ë°©ì‹
    # ========================================================================
    # ì´ìœ : ë¬¸ì¥ë³„ë¡œ TTSë¥¼ í˜¸ì¶œí•˜ë©´ ë¬¸ì¥ ì‚¬ì´ê°€ ë¶€ìì—°ìŠ¤ëŸ½ê²Œ ëŠê¸°ê³ ,
    #       ìë§‰ì´ 2ì¤„ë¡œ ë‚˜ì˜¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŒ.
    # ê°œì„ : ì”¬ ì „ì²´ë¥¼ í•œ ë²ˆì— TTS â†’ Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ
    # ========================================================================
    # def generate_old(
    #     self,
    #     scene_id: str,
    #     text: str,
    #     voice: Optional[str] = None
    # ) -> Optional[Dict[str, Any]]:
    #     """OpenAI TTS - ë¬¸ì¥ë³„ ìŒì„± ìƒì„± (DEPRECATED)"""
    #
    #     if not self.openai_client:
    #         print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    #         print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    #         return None
    #
    #     project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
    #     audio_dir = project_dir / "0_audio"
    #     audio_dir.mkdir(parents=True, exist_ok=True)
    #
    #     # ìŒì„± ì„¤ì • (ê¸°ë³¸ê°’: ash)
    #     voice_setting = voice or self.state.get("settings.voice", "ash")
    #     voice_name = self._extract_voice_name(voice_setting)
    #
    #     print(f"\nğŸ¤ [{scene_id}] TTS ìƒì„± ì¤‘... (OpenAI)")
    #     print(f"   ìŒì„±: {voice_name}")
    #
    #     # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    #     sentences = self._split_into_sentences(text)
    #     print(f"   ë¬¸ì¥ ìˆ˜: {len(sentences)}ê°œ")
    #
    #     sentence_results = []
    #     total_duration = 0.0
    #     audio_files = []
    #
    #     for idx, sentence in enumerate(sentences, 1):
    #         sentence_id = f"{scene_id}_{idx}"
    #         audio_file = audio_dir / f"{sentence_id}.mp3"
    #
    #         # ë¬¸ì¥ ë¯¸ë¦¬ë³´ê¸° (ë„ˆë¬´ ê¸¸ë©´ ìë¦„)
    #         preview = sentence[:40] + "..." if len(sentence) > 40 else sentence
    #         print(f"      [{idx}/{len(sentences)}] {preview}")
    #
    #         # OpenAI TTS ìƒì„±
    #         success = self._generate_openai_tts(sentence, voice_name, audio_file)
    #
    #         if success:
    #             duration = self._get_mp3_duration(audio_file)
    #             gap = 0.1  # ë¬¸ì¥ ì‚¬ì´ ì—¬ìœ  ì‹œê°„
    #             sentence_results.append({
    #                 "sentence_id": sentence_id,
    #                 "sentence_index": idx,
    #                 "text": sentence,
    #                 "audio_file": str(audio_file),
    #                 "start": total_duration,
    #                 "end": total_duration + duration + gap,
    #                 "duration": duration + gap
    #             })
    #             audio_files.append(str(audio_file))
    #             total_duration += duration + gap
    #             print(f"         âœ… {duration:.2f}ì´ˆ (+{gap}s gap)")
    #         else:
    #             print(f"         âŒ ì‹¤íŒ¨")
    #
    #     if not sentence_results:
    #         return None
    #
    #     # íƒ€ì´ë° JSON ì €ì¥
    #     timing_file = audio_dir / f"{scene_id}_timing.json"
    #     timing_data = {
    #         "scene_id": scene_id,
    #         "voice": voice_name,
    #         "total_duration": total_duration,
    #         "sentence_count": len(sentence_results),
    #         "sentences": sentence_results,
    #         "audio_files": audio_files,
    #         "created_at": datetime.now().isoformat()
    #     }
    #
    #     with open(timing_file, 'w', encoding='utf-8') as f:
    #         json.dump(timing_data, f, ensure_ascii=False, indent=2)
    #
    #     print(f"   âœ… ì™„ë£Œ: {len(sentence_results)}ê°œ ë¬¸ì¥, ì´ {total_duration:.2f}ì´ˆ")
    #
    #     # stateì— ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€
    #     for af in audio_files:
    #         self.state.add_file("audio", af)
    #
    #     return timing_data
    # ========================================================================

    def _transcribe_with_whisper(self, audio_file: Path, original_text: str) -> Optional[Dict[str, Any]]:
        """Whisper APIë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„í•˜ì—¬ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ

        Args:
            audio_file: ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            original_text: ì›ë³¸ í…ìŠ¤íŠ¸ (íŒíŠ¸ìš©)

        Returns:
            {
                "segments": [...],  # ë¬¸ì¥ë³„ ì‹œê°„ ì •ë³´
                "words": [...],     # ë‹¨ì–´ë³„ ì‹œê°„ ì •ë³´ (ìˆì„ ê²½ìš°)
                "full_text": "...", # ì „ì‚¬ëœ ì „ì²´ í…ìŠ¤íŠ¸
                "duration": 10.5    # ì´ ê¸¸ì´
            }
        """
        if not self.openai_client:
            return None

        try:
            print(f"   ğŸ“Š Whisper íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì¤‘...")

            # Whisper í”„ë¡¬í”„íŠ¸ (ì¸ì‹ ì •í™•ë„ í–¥ìƒìš©)
            prompt = f"""[ì—„ê²© ê·œì¹™]
1. ìŒì„±ì— ë“¤ë¦° ë‚´ìš©ë§Œ ì •í™•íˆ ì „ì‚¬
2. ì¸ì‚¬ë§, ê°ì‚¬, ì¶”ì„ìƒˆ, ê°íƒ„ì‚¬ ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€
3. íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì‹¤ì œ ë°œí™” ì‹œê°„ ì •í™•íˆ ë°˜ì˜

ì´ê²ƒì€ ìˆ˜í•™ êµìœ¡ ì˜ìƒ ë‚˜ë ˆì´ì…˜ì…ë‹ˆë‹¤.
ìˆ˜í•™ ìš©ì–´: ë¯¸ë¶„, ì ë¶„, ë²¡í„°, ë‚´ì , ì œê³±ê·¼, í•¨ìˆ˜, ê·¸ë˜í”„ ë“±

ì˜ˆìƒ ë‚´ìš©: {original_text[:200]}"""

            with open(audio_file, "rb") as f:
                # verbose_jsonìœ¼ë¡œ segmentë³„ timestamp íšë“
                response = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ko",
                    response_format="verbose_json",
                    timestamp_granularities=["segment", "word"],
                    prompt=prompt
                )

            result = {
                "segments": [],
                "words": [],
                "full_text": response.text,
                "duration": response.duration if hasattr(response, 'duration') else 0
            }

            # Segment ì •ë³´ ì¶”ì¶œ (ë¬¸ì¥ ë‹¨ìœ„)
            if hasattr(response, 'segments') and response.segments:
                for seg in response.segments:
                    result["segments"].append({
                        "text": seg.text.strip() if hasattr(seg, 'text') else "",
                        "start": seg.start if hasattr(seg, 'start') else 0,
                        "end": seg.end if hasattr(seg, 'end') else 0,
                        "duration": (seg.end - seg.start) if hasattr(seg, 'end') and hasattr(seg, 'start') else 0
                    })

            # Word ì •ë³´ ì¶”ì¶œ (ë‹¨ì–´ ë‹¨ìœ„) - ìˆìœ¼ë©´
            if hasattr(response, 'words') and response.words:
                for word in response.words:
                    result["words"].append({
                        "text": word.word.strip() if hasattr(word, 'word') else "",
                        "start": word.start if hasattr(word, 'start') else 0,
                        "end": word.end if hasattr(word, 'end') else 0
                    })

            print(f"      âœ… {len(result['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(result['words'])}ê°œ ë‹¨ì–´ ì¶”ì¶œ")

            return result

        except Exception as e:
            print(f"      âŒ Whisper ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def generate(
        self,
        scene_id: str,
        text: str,
        voice: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """OpenAI TTS + Whisper - ì”¬ ì „ì²´ ìŒì„± ìƒì„± í›„ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ

        ê°œì„ ì :
        - ì”¬ ì „ì²´ë¥¼ í•œ ë²ˆì— TTS â†’ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
        - Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ â†’ ì •í™•í•œ ìë§‰ íƒ€ì´ë°
        - íŒŒì¼ 1ê°œë¡œ ê´€ë¦¬ ìš©ì´
        """

        if not self.openai_client:
            print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return None

        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        audio_dir = project_dir / "0_audio"
        audio_dir.mkdir(parents=True, exist_ok=True)

        # ìŒì„± ì„¤ì • (ê¸°ë³¸ê°’: alloy)
        voice_setting = voice or self.state.get("settings.voice", "alloy")
        voice_name = self._extract_voice_name(voice_setting)

        print(f"\nğŸ¤ [{scene_id}] TTS ìƒì„± ì¤‘... (OpenAI + Whisper)")
        print(f"   ìŒì„±: {voice_name}")

        # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        preview = text[:60] + "..." if len(text) > 60 else text
        print(f"   í…ìŠ¤íŠ¸: {preview}")

        # 1. ì”¬ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ TTS ìƒì„± (íŒŒì¼ 1ê°œ)
        audio_file = audio_dir / f"{scene_id}.mp3"
        print(f"   ğŸ”Š TTS ìƒì„± ì¤‘...")

        success = self._generate_openai_tts(text, voice_name, audio_file)

        if not success:
            print(f"   âŒ TTS ìƒì„± ì‹¤íŒ¨")
            return None

        # ì „ì²´ duration í™•ì¸
        total_duration = self._get_mp3_duration(audio_file)
        print(f"   âœ… TTS ì™„ë£Œ: {total_duration:.2f}ì´ˆ")

        # 2. Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ
        whisper_result = self._transcribe_with_whisper(audio_file, text)

        if not whisper_result or not whisper_result.get("segments"):
            # Whisper ì‹¤íŒ¨ ì‹œ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ segmentë¡œ ì²˜ë¦¬
            print(f"   âš ï¸ Whisper ë¶„ì„ ì‹¤íŒ¨, ì „ì²´ë¥¼ ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬")
            whisper_result = {
                "segments": [{
                    "text": text,
                    "start": 0,
                    "end": total_duration,
                    "duration": total_duration
                }],
                "words": [],
                "full_text": text,
                "duration": total_duration
            }

        # 3. timing.json í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê¸°ì¡´ í˜•ì‹ í˜¸í™˜)
        sentence_results = []
        for idx, seg in enumerate(whisper_result["segments"], 1):
            sentence_results.append({
                "sentence_id": f"{scene_id}_{idx}",
                "sentence_index": idx,
                "text": seg["text"],
                "start": seg["start"],
                "end": seg["end"],
                "duration": seg["duration"]
            })

        # íƒ€ì´ë° JSON ì €ì¥
        timing_file = audio_dir / f"{scene_id}_timing.json"
        timing_data = {
            "scene_id": scene_id,
            "voice": voice_name,
            "total_duration": total_duration,
            "sentence_count": len(sentence_results),
            "sentences": sentence_results,
            "audio_files": [str(audio_file)],  # ì´ì œ íŒŒì¼ 1ê°œ
            "words": whisper_result.get("words", []),  # ë‹¨ì–´ë³„ íƒ€ì´ë° (ë³´ë„ˆìŠ¤)
            "whisper_text": whisper_result.get("full_text", ""),  # Whisper ì „ì‚¬ ê²°ê³¼
            "created_at": datetime.now().isoformat(),
            "method": "tts_whisper"  # ìƒˆ ë°©ì‹ í‘œì‹œ
        }

        with open(timing_file, 'w', encoding='utf-8') as f:
            json.dump(timing_data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… ì™„ë£Œ: {len(sentence_results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì´ {total_duration:.2f}ì´ˆ")

        # ì „ì‚¬ ì •í™•ë„ í‘œì‹œ
        if whisper_result.get("full_text"):
            # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ì²´í¬
            original_clean = text.replace(" ", "").replace(",", "").replace(".", "")
            whisper_clean = whisper_result["full_text"].replace(" ", "").replace(",", "").replace(".", "")
            if original_clean and whisper_clean:
                # ê³µí†µ ê¸€ì ìˆ˜ ê¸°ë°˜ ìœ ì‚¬ë„
                common = sum(1 for c in whisper_clean if c in original_clean)
                similarity = (common / max(len(original_clean), len(whisper_clean))) * 100
                print(f"   ğŸ“ ì „ì‚¬ ìœ ì‚¬ë„: {similarity:.1f}%")

        # stateì— ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€
        self.state.add_file("audio", str(audio_file))

        return timing_data
    
    def generate_all_from_scenes(self, start_from: int = 1) -> List[Dict[str, Any]]:
        """scenes.jsonì˜ ëª¨ë“  ì”¬ì— ëŒ€í•´ TTS ìƒì„± (ë¬¸ì¥ë³„)

        Args:
            start_from: ì‹œì‘í•  ì”¬ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘, ì˜ˆ: 14ë©´ s14ë¶€í„° ì‹œì‘)
        """
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        audio_dir = project_dir / "0_audio"

        if not scenes_file.exists():
            print(f"âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
            return []

        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # scenes.jsonì´ ë°°ì—´ì´ë©´ ì§ì ‘ ì‚¬ìš©, ê°ì²´ë©´ scenes í‚¤ ì‚¬ìš©
        if isinstance(data, list):
            scenes = data
        else:
            scenes = data if isinstance(data, list) else data.get("scenes", [])
        if not scenes:
            print("âŒ ì”¬ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        print(f"\nğŸ¬ ì´ {len(scenes)}ê°œ ì”¬ TTS ìƒì„± ì‹œì‘ (OpenAI TTS)")
        if start_from > 1:
            print(f"   s{start_from}ë¶€í„° ì‹œì‘ (s1-s{start_from-1} ê±´ë„ˆëœ€)")
        print("="*60)

        results = []
        all_audio_files = []
        total_sentences = 0
        total_duration = 0.0
        skipped = 0

        for i, scene in enumerate(scenes, 1):
            scene_id = scene.get("scene_id", f"s{i}")

            # start_from ì´ì „ì˜ ì”¬ì€ ê±´ë„ˆë›°ê¸°
            scene_num = int(scene_id[1:]) if scene_id.startswith('s') and scene_id[1:].isdigit() else i
            if scene_num < start_from:
                # ê¸°ì¡´ íƒ€ì´ë° íŒŒì¼ì´ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
                timing_file = audio_dir / f"{scene_id}_timing.json"
                if timing_file.exists():
                    with open(timing_file, 'r', encoding='utf-8') as f:
                        existing = json.load(f)
                        results.append(existing)
                        all_audio_files.extend(existing.get("audio_files", []))
                        total_sentences += existing.get("sentence_count", 0)
                        total_duration += existing.get("total_duration", 0.0)
                skipped += 1
                continue

            text = scene.get("narration_tts") or scene.get("narration_display", "")

            if not text:
                print(f"\nâš ï¸  [{scene_id}] ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            print(f"\n[{i}/{len(scenes)}] {scene_id}")

            try:
                result = self.generate(scene_id, text)
            except QuotaExceededException:
                # í•œë„ ì´ˆê³¼ ì‹œ í˜„ì¬ê¹Œì§€ ì§„í–‰ ìƒí™© ì €ì¥ í›„ ì¤‘ë‹¨
                print("\n" + "="*60)
                print(f"âš ï¸  TTS ìƒì„± ì¤‘ë‹¨: {len(results)}/{len(scenes)}ê°œ ì”¬ ì™„ë£Œ")
                print(f"   ì´ ë¬¸ì¥: {total_sentences}ê°œ")
                print(f"   ì´ ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")
                print(f"\n   ğŸ“Œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì´ì–´ì„œ ì§„í–‰í•˜ì„¸ìš”:")
                print(f"   python math_video_pipeline.py tts-all --start-from {scene_num}")
                print("="*60)

                # ë¶€ë¶„ ì™„ë£Œ ìƒíƒœ ì €ì¥
                if results:
                    self.state.update_tts_partial(project_id, all_audio_files, scene_num)

                return results  # í˜„ì¬ê¹Œì§€ ê²°ê³¼ ë°˜í™˜

            if result:
                results.append(result)
                # ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ì§‘
                all_audio_files.extend(result.get("audio_files", []))
                total_sentences += result.get("sentence_count", 0)
                total_duration += result.get("total_duration", 0.0)

        print("\n" + "="*60)
        print(f"âœ… TTS ìƒì„± ì™„ë£Œ: {len(results)}/{len(scenes)}ê°œ ì”¬")
        print(f"   ì´ ë¬¸ì¥: {total_sentences}ê°œ")
        print(f"   ì´ ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")

        if results:
            self.state.update_tts_completed(project_id, all_audio_files)

        return results

    def generate_for_scene(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ì”¬ì˜ TTS ì¬ìƒì„± (scenes.jsonì—ì„œ í…ìŠ¤íŠ¸ ìë™ ë¡œë“œ)"""
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_dir = project_dir / "2_scenes"

        # ê°œë³„ ì”¬ íŒŒì¼ ë¨¼ì € í™•ì¸
        scene_file = scenes_dir / f"{scene_id}.json"
        if scene_file.exists():
            with open(scene_file, 'r', encoding='utf-8') as f:
                scene_data = json.load(f)
        else:
            # scenes.jsonì—ì„œ ì°¾ê¸°
            scenes_file = scenes_dir / "scenes.json"
            if not scenes_file.exists():
                print(f"âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
                return None

            with open(scenes_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            scenes = data if isinstance(data, list) else data.get("scenes", [])
            scene_data = None
            for scene in scenes:
                if scene.get("scene_id") == scene_id:
                    scene_data = scene
                    break

            if not scene_data:
                print(f"âŒ ì”¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_id}")
                return None

        text = scene_data.get("narration_tts") or scene_data.get("narration_display", "")
        if not text:
            print(f"âŒ {scene_id}: ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print(f"\nğŸ¤ {scene_id} TTS ì¬ìƒì„± ì‹œì‘...")
        result = self.generate(scene_id, text)

        if result:
            print(f"âœ… {scene_id} TTS ìƒì„± ì™„ë£Œ: {result.get('total_duration', 0):.1f}ì´ˆ")

        return result

    def verify_sync(self, scene_id: Optional[str] = None) -> dict:
        """ëŒ€ë³¸(scenes.json)ê³¼ TTS ë…¹ìŒ(timing.json) ë™ê¸°í™” ê²€ì¦

        Args:
            scene_id: íŠ¹ì • ì”¬ë§Œ ê²€ì¦ (Noneì´ë©´ ì „ì²´ ê²€ì¦)

        Returns:
            {"ok": [...], "mismatch": [...], "missing_scene": [...], "missing_timing": [...]}
        """
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_dir = project_dir / "2_scenes"
        audio_dir = project_dir / "0_audio"

        result = {"ok": [], "mismatch": [], "missing_scene": [], "missing_timing": []}

        def normalize(text: str) -> str:
            """ë¹„êµë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ê·œí™” (êµ¬ë‘ì /ê³µë°± ì œê±°)"""
            return text.replace(',', '').replace('.', '').replace('...', '').replace(' ', '').replace('?', '').replace('!', '')[:40]

        def check_scene(sid: str):
            scene_file = scenes_dir / f"{sid}.json"
            timing_file = audio_dir / f"{sid}_timing.json"

            if not scene_file.exists():
                result["missing_scene"].append(sid)
                return
            if not timing_file.exists():
                result["missing_timing"].append(sid)
                return

            with open(scene_file, 'r', encoding='utf-8') as f:
                scene_data = json.load(f)
            with open(timing_file, 'r', encoding='utf-8') as f:
                timing_data = json.load(f)

            scene_tts = scene_data.get('narration_tts', '').strip()
            whisper_text = timing_data.get('whisper_text', '').strip()

            if normalize(scene_tts) == normalize(whisper_text):
                result["ok"].append(sid)
            else:
                result["mismatch"].append({
                    "scene_id": sid,
                    "script": scene_tts[:60] + "..." if len(scene_tts) > 60 else scene_tts,
                    "recorded": whisper_text[:60] + "..." if len(whisper_text) > 60 else whisper_text
                })

        if scene_id:
            # ë‹¨ì¼ ì”¬ ê²€ì¦
            check_scene(scene_id)
        else:
            # ì „ì²´ ê²€ì¦ - scenes í´ë”ì˜ ëª¨ë“  s*.json
            import re
            scene_files = sorted(scenes_dir.glob("s*.json"),
                                key=lambda p: (int(re.match(r's(\d+)', p.stem).group(1)) if re.match(r's(\d+)', p.stem) else 0, p.stem))
            for sf in scene_files:
                sid = sf.stem
                if re.match(r's\d+[a-z]?$', sid):  # s1, s2, s32a ë“±
                    check_scene(sid)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“‹ ëŒ€ë³¸-TTS ë™ê¸°í™” ê²€ì¦ ê²°ê³¼")
        print("="*60)

        if result["ok"]:
            print(f"\nâœ… ì¼ì¹˜: {len(result['ok'])}ê°œ")
            if len(result["ok"]) <= 10:
                print(f"   {', '.join(result['ok'])}")

        if result["mismatch"]:
            print(f"\nâŒ ë¶ˆì¼ì¹˜: {len(result['mismatch'])}ê°œ")
            for m in result["mismatch"][:5]:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                print(f"\n   [{m['scene_id']}]")
                print(f"   ëŒ€ë³¸: {m['script']}")
                print(f"   ë…¹ìŒ: {m['recorded']}")
            if len(result["mismatch"]) > 5:
                mismatch_ids = [m["scene_id"] for m in result["mismatch"][5:]]
                print(f"\n   ... ì™¸ {len(mismatch_ids)}ê°œ: {', '.join(mismatch_ids)}")

            # TTS ì¬ìƒì„± ì•ˆë‚´
            first_mismatch = result["mismatch"][0]["scene_id"]
            scene_num = int(first_mismatch[1:]) if first_mismatch[1:].isdigit() else 1
            print(f"\n   ğŸ’¡ í•´ê²°: python math_video_pipeline.py tts-all --start-from {scene_num}")

        if result["missing_scene"]:
            print(f"\nâš ï¸ ì”¬ íŒŒì¼ ì—†ìŒ: {', '.join(result['missing_scene'])}")

        if result["missing_timing"]:
            print(f"\nâš ï¸ íƒ€ì´ë° íŒŒì¼ ì—†ìŒ: {', '.join(result['missing_timing'])}")

        if not result["mismatch"] and not result["missing_scene"] and not result["missing_timing"]:
            print("\nğŸ‰ ëª¨ë“  ì”¬ì´ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")

        print("\n" + "="*60)

        return result

    def export_texts(self) -> Optional[Path]:
        """ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ JSON ë‚´ë³´ë‚´ê¸°

        scenes.jsonì—ì„œ ëª¨ë“  ì”¬ì˜ narration_ttsë¥¼ ë¬¸ì¥ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬
        0_audio/tts_texts.jsonìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

        Returns:
            ìƒì„±ëœ JSON íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        project_dir = OUTPUT_DIR / project_id
        scenes_file = project_dir / "2_scenes" / "scenes.json"

        if not scenes_file.exists():
            print(f"âŒ scenes.jsonì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
            return None

        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes_data = json.load(f)

        # scenes.jsonì€ ë°°ì—´ í˜•íƒœì¼ ìˆ˜ë„, {"scenes": [...]} í˜•íƒœì¼ ìˆ˜ë„ ìˆìŒ
        if isinstance(scenes_data, list):
            scenes = scenes_data
        else:
            scenes = scenes_data.get("scenes", [])

        if not scenes:
            print("âŒ scenes.jsonì— ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì˜¤ë””ì˜¤ í´ë” ìƒì„±
        audio_dir = project_dir / "0_audio"
        audio_dir.mkdir(parents=True, exist_ok=True)

        # ë¬¸ì¥ë³„ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        tts_texts = {}
        total_sentences = 0

        print(f"ğŸ™ï¸ ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°")
        print("=" * 60)

        for scene in scenes:
            scene_id = scene.get("scene_id", "")
            narration_tts = scene.get("narration_tts", "")

            if not narration_tts:
                continue

            # ë¬¸ì¥ ë¶„í• 
            sentences = self._split_into_sentences(narration_tts)

            for idx, sentence in enumerate(sentences, 1):
                key = f"{scene_id}_{idx}"
                tts_texts[key] = sentence
                total_sentences += 1

            print(f"   {scene_id}: {len(sentences)}ê°œ ë¬¸ì¥")

        # JSON ì €ì¥
        output_file = audio_dir / "tts_texts.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(tts_texts, f, ensure_ascii=False, indent=2)

        print("=" * 60)
        print(f"âœ… í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!")
        print(f"   ğŸ“ íŒŒì¼: {output_file}")
        print(f"   ğŸ“Š ì´ {len(scenes)}ê°œ ì”¬, {total_sentences}ê°œ ë¬¸ì¥")
        print()
        print("ğŸ“‹ ë…¹ìŒ ì•ˆë‚´:")
        print("   1. ê° ë¬¸ì¥ë³„ë¡œ ê°œë³„ íŒŒì¼ ë…¹ìŒ")
        print("   2. íŒŒì¼ëª…: s1_1.mp3, s1_2.mp3, s2_1.wav ...")
        print(f"   3. ì €ì¥ ìœ„ì¹˜: {audio_dir}")
        print()
        print('ë…¹ìŒ ì™„ë£Œ í›„ "python math_video_pipeline.py audio-check" ì‹¤í–‰')

        return output_file

    def check_audio_files(self) -> Dict[str, List[str]]:
        """ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ëˆ„ë½ í™•ì¸

        tts_texts.jsonê³¼ ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¹„êµí•˜ì—¬
        ëˆ„ë½ëœ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            {"available": [...], "missing": [...]}
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"available": [], "missing": []}

        project_dir = OUTPUT_DIR / project_id
        audio_dir = project_dir / "0_audio"
        texts_file = audio_dir / "tts_texts.json"

        if not texts_file.exists():
            print(f"âŒ tts_texts.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ë¨¼ì € 'python math_video_pipeline.py tts-export' ì‹¤í–‰í•˜ì„¸ìš”.")
            return {"available": [], "missing": []}

        with open(texts_file, 'r', encoding='utf-8') as f:
            tts_texts = json.load(f)

        # íŒŒì¼ í™•ì¸
        available = []
        missing = []

        print(f"ğŸ” ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ í™•ì¸")
        print("=" * 60)

        for key in tts_texts.keys():
            # mp3 ë˜ëŠ” wav í™•ì¸
            mp3_file = audio_dir / f"{key}.mp3"
            wav_file = audio_dir / f"{key}.wav"

            if mp3_file.exists():
                available.append(f"{key}.mp3")
            elif wav_file.exists():
                available.append(f"{key}.wav")
            else:
                missing.append(key)

        total = len(tts_texts)

        if missing:
            print(f"âš ï¸  ëˆ„ë½ëœ íŒŒì¼: {len(missing)}/{total}ê°œ")
            print()
            for key in missing[:20]:  # ìµœëŒ€ 20ê°œë§Œ í‘œì‹œ
                print(f"   âŒ {key}.mp3 (ë˜ëŠ” .wav)")
                print(f"      í…ìŠ¤íŠ¸: {tts_texts[key][:50]}...")
            if len(missing) > 20:
                print(f"   ... ì™¸ {len(missing) - 20}ê°œ")
            print()
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {audio_dir}")
        else:
            print(f"âœ… ëª¨ë“  íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ! ({len(available)}/{total}ê°œ)")
            print()
            print('ë‹¤ìŒ ë‹¨ê³„: "python math_video_pipeline.py audio-process"')

        print("=" * 60)

        return {"available": available, "missing": missing}

    def process_audio_files(self) -> bool:
        """ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ì²˜ë¦¬ (Whisper ë¶„ì„ + timing.json ìƒì„±)

        ê° ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ durationì„ ì¸¡ì •í•˜ê³ 
        ì”¬ë³„ timing.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        project_dir = OUTPUT_DIR / project_id
        audio_dir = project_dir / "0_audio"
        texts_file = audio_dir / "tts_texts.json"

        if not texts_file.exists():
            print(f"âŒ tts_texts.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ë¨¼ì € 'python math_video_pipeline.py tts-export' ì‹¤í–‰í•˜ì„¸ìš”.")
            return False

        # ëˆ„ë½ íŒŒì¼ í™•ì¸
        check_result = self.check_audio_files()
        if check_result["missing"]:
            print(f"\nâŒ ëˆ„ë½ëœ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë…¹ìŒì„ ì™„ë£Œí•˜ì„¸ìš”.")
            return False

        with open(texts_file, 'r', encoding='utf-8') as f:
            tts_texts = json.load(f)

        print()
        print(f"ğŸ§ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)

        # ì”¬ë³„ë¡œ ê·¸ë£¹í™”
        scene_sentences = {}
        for key, text in tts_texts.items():
            # key: s1_1, s1_2, s2_1 ...
            parts = key.rsplit('_', 1)
            scene_id = parts[0]
            sentence_idx = int(parts[1])

            if scene_id not in scene_sentences:
                scene_sentences[scene_id] = []
            scene_sentences[scene_id].append({
                "key": key,
                "index": sentence_idx,
                "text": text
            })

        # ê° ì”¬ë³„ë¡œ ì²˜ë¦¬
        all_audio_files = []

        for scene_id in sorted(scene_sentences.keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 0):
            sentences = sorted(scene_sentences[scene_id], key=lambda x: x["index"])

            print(f"\n[{scene_id}] {len(sentences)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì¤‘...")

            sentence_results = []
            audio_files = []
            current_time = 0.0

            for sent in sentences:
                key = sent["key"]

                # íŒŒì¼ ì°¾ê¸° (mp3 ë˜ëŠ” wav)
                mp3_file = audio_dir / f"{key}.mp3"
                wav_file = audio_dir / f"{key}.wav"

                if mp3_file.exists():
                    audio_file = mp3_file
                    file_ext = "mp3"
                else:
                    audio_file = wav_file
                    file_ext = "wav"

                # duration ì¸¡ì •
                duration = self._get_audio_duration(audio_file)
                gap = 0.1  # ë¬¸ì¥ ì‚¬ì´ ì—¬ìœ  ì‹œê°„

                sentence_results.append({
                    "index": sent["index"],
                    "text": sent["text"],
                    "file": f"{key}.{file_ext}",
                    "start": round(current_time, 3),
                    "end": round(current_time + duration + gap, 3),
                    "duration": round(duration + gap, 3)
                })

                audio_files.append(f"{key}.{file_ext}")
                all_audio_files.append(f"{key}.{file_ext}")
                current_time += duration + gap

                print(f"   {key}: {duration:.2f}ì´ˆ (+{gap}s gap)")

            # timing.json ì €ì¥
            timing_file = audio_dir / f"{scene_id}_timing.json"
            timing_data = {
                "scene_id": scene_id,
                "voice": "external_recording",
                "total_duration": round(current_time, 3),
                "sentence_count": len(sentence_results),
                "sentences": sentence_results,
                "audio_files": audio_files,
                "created_at": datetime.now().isoformat()
            }

            with open(timing_file, 'w', encoding='utf-8') as f:
                json.dump(timing_data, f, ensure_ascii=False, indent=2)

            print(f"   âœ… {timing_file.name} ì €ì¥ (ì´ {current_time:.2f}ì´ˆ)")

        # state ì—…ë°ì´íŠ¸
        self.state.update_tts_completed(project_id, all_audio_files)

        print()
        print("=" * 60)
        print(f"âœ… ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   ğŸ“Š {len(scene_sentences)}ê°œ ì”¬, {len(all_audio_files)}ê°œ íŒŒì¼")
        print(f"   ğŸ“ timing.json ìƒì„± ì™„ë£Œ")
        print()
        print("ë‹¤ìŒ ë‹¨ê³„: Manim ì½”ë“œ ìƒì„±")

        return True

    def _get_audio_duration(self, audio_file: Path) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ì¸¡ì • (mp3/wav ì§€ì›)"""
        import subprocess

        try:
            # ffprobe ì‚¬ìš©
            result = subprocess.run(
                [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    str(audio_file)
                ],
                capture_output=True,
                text=True
            )
            return float(result.stdout.strip())
        except:
            pass

        # wav íŒŒì¼ì¸ ê²½ìš° wave ëª¨ë“ˆ ì‚¬ìš©
        if audio_file.suffix.lower() == ".wav":
            return self._get_wav_duration(audio_file)

        # mp3 íŒŒì¼ì¸ ê²½ìš° mutagen ì‹œë„
        try:
            from mutagen.mp3 import MP3
            audio = MP3(str(audio_file))
            return audio.info.length
        except:
            pass

        print(f"      âš ï¸  duration ì¸¡ì • ì‹¤íŒ¨: {audio_file.name}")
        return 0.0

# ============================================================================
# íŒŒì¼ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class FileManager:
    """íŒŒì¼ ì €ì¥ ë° ë¡œë“œ"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def save_script(self, script: Dict[str, Any]) -> Optional[Path]:
        """ëŒ€ë³¸ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        project_id = self.state.get("project_id")
        script_dir = project_dir / "1_script"
        script_dir.mkdir(parents=True, exist_ok=True)
        
        # JSON ì €ì¥
        json_file = script_dir / "reading_script.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(script, f, ensure_ascii=False, indent=2)
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        md_file = script_dir / "reading_script.md"
        md_content = self._script_to_markdown(script)
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        self.state.update_script_approved(project_id)
        
        print(f"âœ… ëŒ€ë³¸ ì €ì¥ ì™„ë£Œ")
        print(f"   JSON: {json_file}")
        print(f"   Markdown: {md_file}")
        
        return json_file
    
    def _script_to_markdown(self, script: Dict[str, Any]) -> str:
        """ëŒ€ë³¸ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        lines = [
            f"# {script.get('title', 'ì œëª© ì—†ìŒ')}",
            "",
            "## Hook",
            script.get('hook', ''),
            "",
            "## ë¶„ì„",
            script.get('analysis', ''),
            "",
            "## í•µì‹¬ ìˆ˜í•™",
            script.get('core_math', ''),
            "",
            "## ì ìš©",
            script.get('application', ''),
            "",
            "## ì•„ì›ƒíŠ¸ë¡œ",
            script.get('outro', ''),
            "",
            "---",
            "",
            "## ë©”íƒ€ ì •ë³´",
        ]
        
        meta = script.get('meta', {})
        for key, value in meta.items():
            lines.append(f"- {key}: {value}")
        
        return "\n".join(lines)
    
    def save_scenes(self, scenes: List[Dict[str, Any]]) -> Optional[Path]:
        """ì”¬ ë¶„í•  ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        project_id = self.state.get("project_id")
        scenes_dir = project_dir / "2_scenes"
        scenes_dir.mkdir(parents=True, exist_ok=True)
        
        scenes_file = scenes_dir / "scenes.json"
        
        data = {
            "project_id": project_id,
            "total_scenes": len(scenes),
            "total_duration": sum(s.get("duration", 0) for s in scenes),
            "scenes": scenes,
            "created_at": datetime.now().isoformat()
        }
        
        with open(scenes_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        self.state.update_scenes_approved(project_id, scene_ids)
        
        print(f"âœ… ì”¬ ë¶„í•  ì €ì¥ ì™„ë£Œ")
        print(f"   íŒŒì¼: {scenes_file}")
        print(f"   ì´ ì”¬: {len(scenes)}ê°œ")
        print(f"   ì´ ì‹œê°„: {data['total_duration']}ì´ˆ")
        
        return scenes_file
    
    def save_manim_code(self, scene_id: str, code: str) -> Optional[Path]:
        """Manim ì½”ë“œ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        code_dir = project_dir / "4_manim_code"
        code_dir.mkdir(parents=True, exist_ok=True)
        
        code_file = code_dir / f"{scene_id}_manim.py"
        
        with open(code_file, 'w', encoding='utf-8') as f:
            f.write(code)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        self.state.update_manim_scene_completed(scene_id, str(code_file))
        
        print(f"âœ… Manim ì½”ë“œ ì €ì¥: {code_file}")
        
        return code_file
    
    def save_subtitles(self, scene_id: str, subtitles: Dict[str, Any]) -> Optional[Path]:
        """ìë§‰ ë°ì´í„° ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        subtitles_dir = project_dir / "7_subtitles"
        subtitles_dir.mkdir(parents=True, exist_ok=True)
        
        subtitles_file = subtitles_dir / f"{scene_id}_subtitles.json"
        
        with open(subtitles_file, 'w', encoding='utf-8') as f:
            json.dump(subtitles, f, ensure_ascii=False, indent=2)
        
        self.state.add_file("subtitles", str(subtitles_file))
        
        print(f"âœ… ìë§‰ ì €ì¥: {subtitles_file}")
        
        return subtitles_file
    
    def save_image_prompt(self, scene_id: str, prompt: str) -> Optional[Path]:
        """ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        prompts_dir = project_dir / "6_image_prompts"
        prompts_dir.mkdir(parents=True, exist_ok=True)
        
        prompt_file = prompts_dir / f"{scene_id}_background.txt"
        
        with open(prompt_file, 'w', encoding='utf-8') as f:
            f.write(prompt)
        
        print(f"âœ… ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompt_file}")
        
        return prompt_file
    
    def load_scenes(self) -> Optional[List[Dict[str, Any]]]:
        """ì”¬ ë°ì´í„° ë¡œë“œ"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        
        if not scenes_file.exists():
            return None
        
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return data.get("scenes", [])
    
    def load_timing(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """íƒ€ì´ë° ë°ì´í„° ë¡œë“œ"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        timing_file = project_dir / "0_audio" / f"{scene_id}_timing.json"
        
        if not timing_file.exists():
            return None
        
        with open(timing_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def list_files(self) -> Dict[str, List[str]]:
        """í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return {}
        
        files = {}
        
        for folder in project_dir.iterdir():
            if folder.is_dir():
                files[folder.name] = [f.name for f in folder.iterdir() if f.is_file()]
        
        return files


# ============================================================================
# Supabase í´ë¼ì´ì–¸íŠ¸
# ============================================================================

def get_supabase_client() -> Optional['SupabaseClient']:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Service Role Key ì‚¬ìš©)"""
    if not SUPABASE_AVAILABLE:
        return None

    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_KEY")

    if not url or not key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("SUPABASE_URL="):
                        url = line.split("=", 1)[1].strip().strip('"\'')
                    elif line.startswith("SUPABASE_SERVICE_KEY="):
                        key = line.split("=", 1)[1].strip().strip('"\'')

    if not url or not key:
        print("âŒ SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    return create_client(url, key)


# ============================================================================
# ì—ì…‹ ê´€ë¦¬ í´ë˜ìŠ¤ (Supabase ì—°ë™)
# ============================================================================

class AssetManager:
    """ì—ì…‹ ê´€ë¦¬ (Supabase Storage + DB ì—°ë™)"""

    BUCKET_NAME = "math-video-assets"
    ASSETS_DIR = Path("assets")

    def __init__(self, state_manager: StateManager):
        self.state = state_manager
        self.supabase = get_supabase_client()

    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None

    def check_assets(self) -> dict:
        """
        ì—ì…‹ ì²´í¬: Supabase ì¡°íšŒ + ë‹¤ìš´ë¡œë“œ + ëˆ„ë½ ëª©ë¡ ìƒì„± + scenes.json í™•ì¥ì ì—…ë°ì´íŠ¸

        Returns:
            {"available": [...], "missing": [...], "downloaded": [...]}
        """
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"available": [], "missing": [], "downloaded": []}

        scenes_file = project_dir / "2_scenes" / "scenes.json"
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì”¬ ë¶„í• ì„ ì§„í–‰í•˜ì„¸ìš”.")
            return {"available": [], "missing": [], "downloaded": []}

        # 1. scenes.jsonì—ì„œ required_elements ìˆ˜ì§‘
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        scenes = data if isinstance(data, list) else data.get("scenes", [])

        required_assets = {}  # file_path -> {scenes, description, tags, original_name}
        for scene in scenes:
            scene_id = scene.get("scene_id", "unknown")

            # 1. required_elementsì—ì„œ ì¶”ì¶œ
            elements = scene.get("required_elements", [])
            for elem in elements:
                if isinstance(elem, str) and "/" in elem:
                    # ì´ë¯¸ ê²½ë¡œ í˜•ì‹
                    base_name = elem.rsplit(".", 1)[0] if "." in elem else elem
                    if base_name not in required_assets:
                        required_assets[base_name] = {"scenes": [], "description": "", "tags": [], "original_name": elem}
                    required_assets[base_name]["scenes"].append(scene_id)
                elif isinstance(elem, dict) and elem.get("type") in ["image", "icon"]:
                    # {"type": "image"/"icon", "asset": "snack_bag" ë˜ëŠ” "snack_bag.png", "role": "..."} í˜•ì‹
                    asset_name = elem.get("asset", elem.get("file", elem.get("path", "")))
                    elem_type = elem.get("type")
                    if asset_name:
                        # í™•ì¥ì ì œê±°
                        base_name = asset_name.rsplit(".", 1)[0] if "." in asset_name else asset_name

                        # ì¹´í…Œê³ ë¦¬ ê²°ì •: typeì´ iconì´ë©´ icons/, ì•„ë‹ˆë©´ ê¸°ì¡´ ë¡œì§
                        if elem_type == "icon":
                            file_path = f"icons/{base_name}"
                        elif "stickman" in base_name or "pigou" in base_name:
                            file_path = f"characters/{base_name}"
                        elif "_icon" in base_name or base_name in ["question_mark", "exclamation", "lightbulb", "checkmark", "arrow_right", "star", "heart", "clock", "calendar", "battery_low", "server_icon", "algorithm_icon", "amazon_logo", "dollar_sign"]:
                            file_path = f"icons/{base_name}"
                        else:
                            file_path = f"objects/{base_name}"

                        if file_path not in required_assets:
                            required_assets[file_path] = {
                                "scenes": [],
                                "description": elem.get("role", elem.get("description", "")),
                                "tags": [],
                                "original_name": asset_name
                            }
                        required_assets[file_path]["scenes"].append(scene_id)

            # 2. required_assetsì—ì„œë„ ì¶”ì¶œ (ë³„ë„ í•„ë“œ)
            assets_list = scene.get("required_assets", [])
            for asset in assets_list:
                if isinstance(asset, dict):
                    category = asset.get("category", "objects")
                    filename = asset.get("filename", "")
                    if filename:
                        # í™•ì¥ì ì œê±°
                        base_name = filename.rsplit(".", 1)[0] if "." in filename else filename
                        file_path = f"{category}/{base_name}"
                        if file_path not in required_assets:
                            required_assets[file_path] = {
                                "scenes": [],
                                "description": asset.get("description", ""),
                                "tags": [category, base_name],
                                "original_name": filename
                            }
                        if scene_id not in required_assets[file_path]["scenes"]:
                            required_assets[file_path]["scenes"].append(scene_id)

        print(f"\nğŸ“‹ í•„ìš”í•œ ì—ì…‹: {len(required_assets)}ê°œ")

        # 2. ì‹¤ì œ íŒŒì¼ í™•ì¥ì ì°¾ê¸° (ë¡œì»¬ì—ì„œ .png ë˜ëŠ” .svg íƒìƒ‰)
        resolved_assets = {}  # base_path -> actual_path (with extension)
        for base_path in required_assets.keys():
            # ë¡œì»¬ì—ì„œ .png, .svg ìˆœì„œë¡œ ì°¾ê¸°
            for ext in [".png", ".svg"]:
                local_path = self.ASSETS_DIR / f"{base_path}{ext}"
                if local_path.exists():
                    resolved_assets[base_path] = f"{base_path}{ext}"
                    break
            # ì—†ìœ¼ë©´ ì¼ë‹¨ .pngë¡œ ê°€ì • (ëˆ„ë½ ëª©ë¡ì— ì¶”ê°€ë¨)
            if base_path not in resolved_assets:
                resolved_assets[base_path] = f"{base_path}.png"

        if not self.supabase:
            print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨. ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸í•©ë‹ˆë‹¤.")
            result = self._check_local_only(required_assets, resolved_assets)
            # scenes.json ì—…ë°ì´íŠ¸
            self._update_scenes_with_extensions(scenes_file, scenes, resolved_assets)
            return result

        # 3. Supabaseì—ì„œ ë³´ìœ  ëª©ë¡ ì¡°íšŒ
        try:
            result = self.supabase.table("assets").select("file_path, folder, file_name, description, tags").execute()
            supabase_assets = {item["file_path"]: item for item in result.data}
            print(f"â˜ï¸  Supabase ë³´ìœ : {len(supabase_assets)}ê°œ")

            # Supabaseì—ì„œë„ í™•ì¥ì ì°¾ê¸°
            for base_path in required_assets.keys():
                if base_path not in resolved_assets or not (self.ASSETS_DIR / resolved_assets[base_path]).exists():
                    for ext in [".png", ".svg"]:
                        full_path = f"{base_path}{ext}"
                        if full_path in supabase_assets:
                            resolved_assets[base_path] = full_path
                            break
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            supabase_assets = {}

        available = []
        missing = []
        downloaded = []

        # 4. ê° ì—ì…‹ í™•ì¸ (í™•ì¥ì í¬í•¨ëœ ê²½ë¡œë¡œ)
        for base_path, info in required_assets.items():
            file_path = resolved_assets.get(base_path, f"{base_path}.png")
            local_path = self.ASSETS_DIR / file_path

            if file_path in supabase_assets:
                # Supabaseì— ìˆìŒ
                if local_path.exists():
                    # ë¡œì»¬ì—ë„ ìˆìŒ
                    available.append(file_path)
                else:
                    # ë¡œì»¬ì— ì—†ìŒ â†’ ë‹¤ìš´ë¡œë“œ
                    if self._download_asset(file_path):
                        downloaded.append(file_path)
                        available.append(file_path)
                    else:
                        missing.append({
                            "file_path": file_path,
                            "base_path": base_path,
                            "folder": file_path.rsplit("/", 1)[0] if "/" in file_path else "",
                            "file_name": file_path.rsplit("/", 1)[-1],
                            "description": supabase_assets[file_path].get("description", ""),
                            "tags": supabase_assets[file_path].get("tags", []),
                            "used_in_scenes": info["scenes"],
                            "spec": {"min_size": "500x500", "format": "PNG or SVG", "background": "transparent"}
                        })
            else:
                # Supabaseì— ì—†ìŒ
                if local_path.exists():
                    # ë¡œì»¬ì—ë§Œ ìˆìŒ (ì—…ë¡œë“œ í•„ìš”)
                    available.append(file_path)
                else:
                    # ì–´ë””ì—ë„ ì—†ìŒ
                    missing.append({
                        "file_path": file_path,
                        "base_path": base_path,
                        "folder": file_path.rsplit("/", 1)[0] if "/" in file_path else "",
                        "file_name": file_path.rsplit("/", 1)[-1],
                        "description": info.get("description", f"ì—ì…‹: {file_path}"),
                        "tags": info.get("tags", [file_path.split("/")[0], base_path.rsplit("/", 1)[-1]]),
                        "used_in_scenes": info["scenes"],
                        "spec": {"min_size": "500x500", "format": "PNG or SVG", "background": "transparent"}
                    })

        # 5. ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥: {len(available)}ê°œ")
        if downloaded:
            print(f"â¬‡ï¸  ë‹¤ìš´ë¡œë“œë¨: {len(downloaded)}ê°œ")
            for fp in downloaded:
                print(f"   - {fp}")

        if missing:
            print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")
            for m in missing:
                print(f"   - {m['file_path']} (ì”¬: {', '.join(m['used_in_scenes'])})")

            # missing_assets.json ì €ì¥
            missing_file = project_dir / "missing_assets.json"
            with open(missing_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "missing": missing,
                    "generated_at": datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“„ ëˆ„ë½ ëª©ë¡ ì €ì¥: {missing_file}")
        else:
            print("\nğŸ‰ ëª¨ë“  ì—ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
            # state.json ì—…ë°ì´íŠ¸
            self.state.set("assets.required", [resolved_assets[k] for k in required_assets.keys()])
            self.state.set("assets.available", available)
            self.state.set("assets.missing", [])
            self.state.update_phase("assets_checked")

        # 6. scenes.json ì—…ë°ì´íŠ¸ (í™•ì¥ì ë°˜ì˜)
        self._update_scenes_with_extensions(scenes_file, scenes, resolved_assets)

        return {"available": available, "missing": missing, "downloaded": downloaded}

    def _update_scenes_with_extensions(self, scenes_file: Path, scenes: list, resolved_assets: dict) -> bool:
        """scenes.jsonì— ì‹¤ì œ íŒŒì¼ í™•ì¥ìë¥¼ ë°˜ì˜"""
        updated = False

        for scene in scenes:
            # 1. required_elements ì—…ë°ì´íŠ¸
            elements = scene.get("required_elements", [])
            for elem in elements:
                if isinstance(elem, dict) and elem.get("type") == "image":
                    asset_name = elem.get("asset", "")
                    if asset_name:
                        base_name = asset_name.rsplit(".", 1)[0] if "." in asset_name else asset_name

                        # ì¹´í…Œê³ ë¦¬ ì¶”ì¸¡
                        if "stickman" in base_name or "pigou" in base_name:
                            base_path = f"characters/{base_name}"
                        elif "_icon" in base_name or base_name in ["question_mark", "exclamation", "lightbulb", "checkmark", "arrow_right", "star", "heart", "clock", "calendar", "battery_low", "server_icon", "algorithm_icon", "amazon_logo", "dollar_sign"]:
                            base_path = f"icons/{base_name}"
                        else:
                            base_path = f"objects/{base_name}"

                        if base_path in resolved_assets:
                            new_name = resolved_assets[base_path].rsplit("/", 1)[-1]  # íŒŒì¼ëª…ë§Œ
                            if asset_name != new_name:
                                elem["asset"] = new_name
                                updated = True

            # 2. required_assets ì—…ë°ì´íŠ¸
            assets_list = scene.get("required_assets", [])
            for asset in assets_list:
                if isinstance(asset, dict):
                    category = asset.get("category", "objects")
                    filename = asset.get("filename", "")
                    if filename:
                        base_name = filename.rsplit(".", 1)[0] if "." in filename else filename
                        base_path = f"{category}/{base_name}"

                        if base_path in resolved_assets:
                            new_filename = resolved_assets[base_path].rsplit("/", 1)[-1]
                            if filename != new_filename:
                                asset["filename"] = new_filename
                                updated = True

        if updated:
            with open(scenes_file, 'w', encoding='utf-8') as f:
                json.dump(scenes, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“ scenes.json ì—…ë°ì´íŠ¸ë¨ (í™•ì¥ì ë°˜ì˜)")

        return updated

    def _check_local_only(self, required_assets: dict, resolved_assets: dict) -> dict:
        """ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸ (Supabase ì—†ì„ ë•Œ)

        Args:
            required_assets: í•„ìš”í•œ ì—ì…‹ (í™•ì¥ì ì—†ëŠ” ê²½ë¡œ -> info)
            resolved_assets: ì‹¤ì œ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì—†ëŠ” ê²½ë¡œ -> í™•ì¥ì ìˆëŠ” ê²½ë¡œ)
        """
        available = []
        missing = []

        for base_path, info in required_assets.items():
            # resolved_assetsì—ì„œ ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸
            if base_path in resolved_assets:
                actual_path = resolved_assets[base_path]
                available.append(actual_path)
            else:
                # ëˆ„ë½ëœ ì—ì…‹
                category = base_path.rsplit("/", 1)[0] if "/" in base_path else ""
                is_icon = category == "icons"
                missing.append({
                    "file_path": base_path,  # í™•ì¥ì ì—†ëŠ” ê²½ë¡œ
                    "folder": category,
                    "file_name": base_path.rsplit("/", 1)[-1],
                    "description": info.get("description", f"ì—ì…‹: {base_path}"),
                    "tags": info.get("tags", []),
                    "used_in_scenes": info["scenes"],
                    "spec": {
                        "min_size": "300x300" if is_icon else "500x500",
                        "format": "SVG (ê¶Œì¥) ë˜ëŠ” PNG" if is_icon else "PNG",
                        "background": "transparent"
                    }
                })

        print(f"âœ… ë¡œì»¬ ì¡´ì¬: {len(available)}ê°œ")
        print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")

        return {"available": available, "missing": missing, "downloaded": []}

    def _download_asset(self, file_path: str) -> bool:
        """Supabase Storageì—ì„œ ì—ì…‹ ë‹¤ìš´ë¡œë“œ"""
        try:
            local_path = self.ASSETS_DIR / file_path
            local_path.parent.mkdir(parents=True, exist_ok=True)

            data = self.supabase.storage.from_(self.BUCKET_NAME).download(file_path)

            with open(local_path, 'wb') as f:
                f.write(data)

            return True
        except Exception as e:
            print(f"   âš ï¸  ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")
            return False

    def sync_assets(self) -> dict:
        """
        ì—ì…‹ ë™ê¸°í™”: ë¡œì»¬ ì‹ ê·œ íŒŒì¼ â†’ Supabase ì—…ë¡œë“œ
        missing_assets.json ì°¸ì¡°í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì ìš©

        Returns:
            {"uploaded": [...], "failed": [...]}
        """
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"uploaded": [], "failed": []}

        if not self.supabase:
            print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨.")
            return {"uploaded": [], "failed": []}

        # missing_assets.json ë¡œë“œ
        missing_file = project_dir / "missing_assets.json"
        missing_metadata = {}
        if missing_file.exists():
            with open(missing_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data.get("missing", []):
                    missing_metadata[item["file_path"]] = item

        # Supabase ë³´ìœ  ëª©ë¡ ì¡°íšŒ
        try:
            result = self.supabase.table("assets").select("file_path").execute()
            supabase_paths = {item["file_path"] for item in result.data}
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            supabase_paths = set()

        uploaded = []
        failed = []

        # ë¡œì»¬ assets í´ë” ìŠ¤ìº” (PNG + SVG)
        asset_files = list(self.ASSETS_DIR.rglob("*.png")) + list(self.ASSETS_DIR.rglob("*.svg"))

        for asset_file in asset_files:
            rel_path = asset_file.relative_to(self.ASSETS_DIR).as_posix()

            if rel_path in supabase_paths:
                continue  # ì´ë¯¸ ì—…ë¡œë“œë¨

            print(f"\nğŸ“¤ ì—…ë¡œë“œ ì¤‘: {rel_path}")

            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            metadata = missing_metadata.get(rel_path, {})
            folder = rel_path.rsplit("/", 1)[0] if "/" in rel_path else ""
            file_name = rel_path.rsplit("/", 1)[-1]

            if self._upload_asset(asset_file, rel_path, folder, file_name, metadata):
                uploaded.append(rel_path)
            else:
                failed.append(rel_path)

        print(f"\n{'='*50}")
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {len(uploaded)}ê°œ")
        if failed:
            print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
            for fp in failed:
                print(f"   - {fp}")

        # ì—…ë¡œë“œ í›„ ë‹¤ì‹œ ì²´í¬
        if uploaded:
            print("\nğŸ”„ ì—ì…‹ ìƒíƒœ ì¬í™•ì¸ ì¤‘...")
            self.check_assets()

        # ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸
        self.update_catalog()

        return {"uploaded": uploaded, "failed": failed}

    def update_catalog(self) -> bool:
        """
        Supabaseì—ì„œ ì „ì²´ ì—ì…‹ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ asset-catalog.md ìë™ ìƒì„±
        """
        if not self.supabase:
            print("âš ï¸  Supabase ì—°ê²° ì—†ìŒ. ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸ ìƒëµ.")
            return False

        try:
            result = self.supabase.table("assets").select("*").execute()
            assets = result.data
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return False

        if not assets:
            print("âš ï¸  Supabaseì— ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        categories = {
            "characters": [],
            "objects": [],
            "icons": [],
            "metaphors": []
        }

        for asset in assets:
            folder = asset.get("folder", "objects")
            if folder not in categories:
                folder = "objects"
            categories[folder].append(asset)

        # Markdown ìƒì„±
        catalog_path = Path("skills/asset-catalog.md")

        lines = [
            "# ì—ì…‹ ì¹´íƒˆë¡œê·¸",
            "",
            "> ì´ íŒŒì¼ì€ `asset-sync` ì‹¤í–‰ ì‹œ Supabaseì—ì„œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.",
            "> ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”.",
            "",
            f"**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ì´ ì—ì…‹ ìˆ˜**: {len(assets)}ê°œ",
            "",
            "---",
            "",
        ]

        # ì¹´í…Œê³ ë¦¬ë³„ í…Œì´ë¸” ìƒì„±
        category_info = {
            "characters": ("ìºë¦­í„°", "characters/"),
            "objects": ("ë¬¼ì²´", "objects/"),
            "icons": ("ì•„ì´ì½˜", "icons/"),
            "metaphors": ("ì€ìœ /ë¹„ìœ ", "metaphors/")
        }

        for cat_key, (cat_name, cat_path) in category_info.items():
            cat_assets = categories.get(cat_key, [])
            if not cat_assets:
                continue

            lines.append(f"## {cat_name} ({cat_path})")
            lines.append("")
            lines.append("| íŒŒì¼ëª… | ì„¤ëª… | í¬ê¸° | íƒœê·¸ |")
            lines.append("|--------|------|------|------|")

            for asset in sorted(cat_assets, key=lambda x: x.get("file_name", "")):
                file_name = asset.get("file_name", "unknown")
                description = asset.get("description", "")[:50]  # 50ì ì œí•œ
                width = asset.get("width", "?")
                height = asset.get("height", "?")
                size_str = f"{width}x{height}" if width and height else "?"
                tags = asset.get("tags", [])
                # tagsê°€ ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° flatten
                if tags and isinstance(tags[0], list):
                    tags = [item for sublist in tags for item in sublist]
                # ë¬¸ìì—´ë§Œ í•„í„°ë§
                tags = [t for t in tags if isinstance(t, str)]
                tags_str = ", ".join(tags[:3]) if tags else ""  # íƒœê·¸ 3ê°œê¹Œì§€

                lines.append(f"| `{file_name}` | {description} | {size_str} | {tags_str} |")

            lines.append("")

        # íŒŒì¼ ì‚¬ì–‘ ì„¹ì…˜
        lines.extend([
            "---",
            "",
            "## ì—ì…‹ íŒŒì¼ ì‚¬ì–‘",
            "",
            "| ì¹´í…Œê³ ë¦¬ | ê¶Œì¥ í¬ê¸° | ìŠ¤íƒ€ì¼ |",
            "|----------|-----------|--------|",
            "| characters | 500x700 px | ì¡¸ë¼ë§¨ stick figure |",
            "| objects | 500x500 px | minimalist 2D |",
            "| icons | 300x300 px | minimalist 2D |",
            "| metaphors | 700x500 px | minimalist 2D |",
            "",
            "**ê³µí†µ ì‚¬ì–‘**:",
            "- í¬ë§·: PNG (íˆ¬ëª… ë°°ê²½)",
            "- ìƒì„± ì‹œ í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ìƒì„± í›„ ë°°ê²½ ì œê±°",
            "- ë‚´ë¶€ëŠ” ë°˜ë“œì‹œ solid colorë¡œ ì±„ìš°ê¸°",
            "",
        ])

        # íŒŒì¼ ì €ì¥
        catalog_path.parent.mkdir(parents=True, exist_ok=True)
        with open(catalog_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        print(f"\nğŸ“‹ ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸: {catalog_path}")
        print(f"   - ì´ {len(assets)}ê°œ ì—ì…‹ ë“±ë¡")

        return True

    def _upload_asset(self, local_path: Path, storage_path: str, folder: str, file_name: str, metadata: dict) -> bool:
        """ë‹¨ì¼ ì—ì…‹ ì—…ë¡œë“œ (Storage + DB)"""
        try:
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            is_svg = file_name.lower().endswith(".svg")
            content_type = "image/svg+xml" if is_svg else "image/png"

            # 1. Storage ì—…ë¡œë“œ
            with open(local_path, 'rb') as f:
                file_data = f.read()

            try:
                self.supabase.storage.from_(self.BUCKET_NAME).upload(
                    path=storage_path,
                    file=file_data,
                    file_options={"content-type": content_type}
                )
                print(f"   [STORAGE] OK")
            except Exception as e:
                if "Duplicate" in str(e) or "already exists" in str(e):
                    print(f"   [STORAGE] Already exists")
                else:
                    raise e

            # 2. ì´ë¯¸ì§€ ì •ë³´
            width, height, file_size = None, None, local_path.stat().st_size

            if is_svg:
                # SVG íŒŒì¼ì€ viewBoxì—ì„œ í¬ê¸° ì¶”ì¶œ ì‹œë„
                try:
                    import re
                    svg_content = local_path.read_text(encoding='utf-8')
                    # viewBox="0 0 300 300" ë˜ëŠ” width="300" height="300" ì¶”ì¶œ
                    viewbox_match = re.search(r'viewBox="[^"]*\s+(\d+)\s+(\d+)"', svg_content)
                    if viewbox_match:
                        width, height = int(viewbox_match.group(1)), int(viewbox_match.group(2))
                    else:
                        width_match = re.search(r'width="(\d+)"', svg_content)
                        height_match = re.search(r'height="(\d+)"', svg_content)
                        if width_match and height_match:
                            width, height = int(width_match.group(1)), int(height_match.group(1))
                except:
                    pass
            elif PIL_AVAILABLE:
                try:
                    with Image.open(local_path) as img:
                        width, height = img.size
                except:
                    pass

            # 3. DB ì €ì¥
            # í™•ì¥ì ì œê±° (íƒœê·¸ìš©)
            base_name = file_name.rsplit(".", 1)[0] if "." in file_name else file_name

            db_data = {
                "file_name": file_name,
                "folder": folder,
                "storage_path": storage_path,
                "description": metadata.get("description", f"{folder} asset: {file_name}"),
                "tags": metadata.get("tags", [folder, base_name]),
                "width": width,
                "height": height,
                "file_size": file_size,
            }

            self.supabase.table("assets").upsert(
                db_data,
                on_conflict="folder,file_name"
            ).execute()
            print(f"   [DB] OK")

            return True
        except Exception as e:
            print(f"   [ERROR] {e}")
            return False


# ============================================================================
# ì´ë¯¸ì§€ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class ImageManager:
    """ë°°ê²½ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë° íŒŒì¼ ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def export_prompts(self) -> Optional[Path]:
        """ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        prompts_dir = project_dir / "6_image_prompts"
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì”¬ ë¶„í• ì„ ì§„í–‰í•˜ì„¸ìš”.")
            return None
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        if not scenes:
            print("âŒ ì”¬ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ìŠ¤íƒ€ì¼ ì •ë³´
        style = self.state.get("settings.style", "cyberpunk")
        aspect_ratio = self.state.get("settings.aspect_ratio", "16:9")
        
        # ë°°ì¹˜ íŒŒì¼ ìƒì„±
        batch_file = prompts_dir / "prompts_batch.txt"
        prompts_dir.mkdir(parents=True, exist_ok=True)
        
        lines = [
            "=" * 70,
            f"í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            f"ì œëª©: {self.state.get('title')}",
            f"ìŠ¤íƒ€ì¼: {style}",
            f"ì¢…íš¡ë¹„: {aspect_ratio}",
            f"ì´ ì”¬: {len(scenes)}ê°œ",
            "=" * 70,
            "",
            "ğŸ“Œ ì‚¬ìš©ë²•:",
            "1. ê° í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± AIì— ì…ë ¥",
            "2. ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ",
            f"3. íŒŒì¼ëª…ì„ s1_bg.png, s2_bg.png, ... í˜•ì‹ìœ¼ë¡œ ë³€ê²½",
            f"4. 9_backgrounds/ í´ë”ì— ì €ì¥",
            "5. python math_video_pipeline.py images-check ë¡œ ê²€ì¦",
            "",
            "=" * 70,
            ""
        ]
        
        # ê° ì”¬ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        for i, scene in enumerate(scenes):
            scene_id = scene.get("scene_id", f"s{i+1}")
            section = scene.get("section", "")
            duration = scene.get("duration", 0)
            visual_concept = scene.get("visual_concept", "")
            
            # ê°œë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ë„ ì €ì¥
            prompt = self._generate_prompt(style, aspect_ratio, visual_concept, section)
            
            prompt_file = prompts_dir / f"{scene_id}_background.txt"
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(prompt)
            
            # ë°°ì¹˜ íŒŒì¼ì— ì¶”ê°€
            lines.append(f"=== Scene {scene_id} ({section}) ===")
            lines.append(f"[Duration: {duration}ì´ˆ]")
            lines.append(f"[Visual: {visual_concept[:50]}...]" if len(visual_concept) > 50 else f"[Visual: {visual_concept}]")
            lines.append("")
            lines.append(prompt)
            lines.append("")
            lines.append("-" * 70)
            lines.append("")
        
        # ë°°ì¹˜ íŒŒì¼ ì €ì¥
        with open(batch_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
        
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ")
        print(f"   ğŸ“„ ë°°ì¹˜ íŒŒì¼: {batch_file}")
        print(f"   ğŸ“ ê°œë³„ íŒŒì¼: {prompts_dir}/")
        print(f"   ğŸ¬ ì´ {len(scenes)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        
        return batch_file
    
    def _generate_prompt(self, style: str, aspect_ratio: str, visual_concept: str, section: str) -> str:
        """ìŠ¤íƒ€ì¼ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ìŠ¤íƒ€ì¼ë³„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        style_prompts = {
            "minimal": {
                "base": "minimalist mathematical background, clean dark gradient from black center to deep gray edges",
                "accent": "subtle geometric pattern",
                "equation_color": "bright yellow and white"
            },
            "cyberpunk": {
                "base": "cyberpunk mathematical background, dark futuristic scene with neon cyan and magenta accents, digital grid",
                "accent": "holographic glow effects, circuit patterns",
                "equation_color": "bright cyan and magenta"
            },
            "paper": {
                "base": "vintage paper texture background, warm beige to cream gradient, subtle paper grain",
                "accent": "aged parchment feel, soft edges",
                "equation_color": "dark ink, handwritten style"
            },
            "space": {
                "base": "deep space background, cosmic scene with distant stars and nebula in dark purple and blue",
                "accent": "galaxy swirls, stellar glow",
                "equation_color": "bright white and yellow"
            },
            "geometric": {
                "base": "geometric pattern background, symmetrical mathematical shapes, golden ratio spiral",
                "accent": "sacred geometry, precise lines",
                "equation_color": "gold and white"
            },
            "stickman": {
                "base": "dark colorful background gradient from deep blue to purple, clean and simple",
                "accent": "subtle playful elements, friendly atmosphere",
                "equation_color": "bright white and yellow"
            }
        }
        
        config = style_prompts.get(style, style_prompts["cyberpunk"])
        
        # ì¢…íš¡ë¹„ í…ìŠ¤íŠ¸
        ratio_text = "16:9 widescreen horizontal" if aspect_ratio == "16:9" else "9:16 vertical portrait mobile"
        
        prompt = f"""{config['base']},
{config['accent']},
mathematical education video background,
no text, no letters, no numbers, no Korean, no equations,
suitable for {config['equation_color']} mathematical equations overlay,
{ratio_text} ratio,
high contrast, professional education aesthetic,
8K quality, sharp details

Negative prompt: text, letters, numbers, words, Korean, Chinese, Japanese, equations, formulas, mathematical symbols, writing, watermark, logo, signature, blurry, low quality, pixelated, faces, people, hands"""

        return prompt
    
    def check_images(self) -> Dict[str, Any]:
        """ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "message": "No active project"}
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        backgrounds_dir = project_dir / "9_backgrounds"
        
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "message": "No scenes file"}
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        
        # ì´ë¯¸ì§€ í™•ì¸
        found = []
        missing = []
        
        for scene_id in scene_ids:
            # ì—¬ëŸ¬ í™•ì¥ì í™•ì¸
            image_found = False
            for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                image_file = backgrounds_dir / f"{scene_id}_bg{ext}"
                if image_file.exists():
                    found.append(str(image_file.name))
                    image_found = True
                    break
            
            if not image_found:
                missing.append(f"{scene_id}_bg.png")
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ–¼ï¸  ë°°ê²½ ì´ë¯¸ì§€ ìƒíƒœ í™•ì¸")
        print("=" * 60)
        print(f"ğŸ“ í´ë”: {backgrounds_dir}")
        print(f"ğŸ¬ ì´ ì”¬: {len(scene_ids)}ê°œ")
        print(f"âœ… ì¤€ë¹„ë¨: {len(found)}ê°œ")
        print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")
        print()
        
        if found:
            print("âœ… ì¤€ë¹„ëœ ì´ë¯¸ì§€:")
            for f in found:
                print(f"   - {f}")
            print()
        
        if missing:
            print("âŒ ëˆ„ë½ëœ ì´ë¯¸ì§€:")
            for m in missing:
                print(f"   - {m}")
            print()
            print("ğŸ“Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´:")
            print("   1. python math_video_pipeline.py prompts-export")
            print("   2. í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„± (Midjourney, DALL-E ë“±)")
            print(f"   3. {backgrounds_dir}/ ì— ì €ì¥")
        else:
            print("ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        print("=" * 60)
        
        return {
            "status": "complete" if not missing else "incomplete",
            "total": len(scene_ids),
            "found": found,
            "missing": missing
        }
    
    def import_images(self, source_dir: str) -> Dict[str, Any]:
        """ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "imported": 0}
        
        source_path = Path(source_dir)
        if not source_path.exists():
            print(f"âŒ ì†ŒìŠ¤ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_dir}")
            return {"status": "error", "imported": 0}
        
        backgrounds_dir = project_dir / "9_backgrounds"
        backgrounds_dir.mkdir(parents=True, exist_ok=True)
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "imported": 0}
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        
        # ì†ŒìŠ¤ í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ë“¤
        image_extensions = {".png", ".jpg", ".jpeg", ".webp"}
        source_images = sorted([
            f for f in source_path.iterdir() 
            if f.is_file() and f.suffix.lower() in image_extensions
        ])
        
        if not source_images:
            print(f"âŒ ì†ŒìŠ¤ í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {source_dir}")
            return {"status": "error", "imported": 0}
        
        print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°")
        print(f"   ì†ŒìŠ¤: {source_dir}")
        print(f"   ëŒ€ìƒ: {backgrounds_dir}")
        print(f"   ë°œê²¬ëœ ì´ë¯¸ì§€: {len(source_images)}ê°œ")
        print(f"   í•„ìš”í•œ ì”¬: {len(scene_ids)}ê°œ")
        print()
        
        imported = []
        
        # ë°©ë²• 1: íŒŒì¼ëª…ì— ì”¬ IDê°€ í¬í•¨ëœ ê²½ìš°
        for scene_id in scene_ids:
            for img in source_images:
                if scene_id in img.stem.lower():
                    dest = backgrounds_dir / f"{scene_id}_bg{img.suffix}"
                    if not dest.exists():
                        import shutil
                        shutil.copy2(img, dest)
                        imported.append(f"{img.name} â†’ {dest.name}")
                        print(f"   âœ… {img.name} â†’ {dest.name}")
                    break
        
        # ë°©ë²• 2: ìˆœì„œëŒ€ë¡œ ë§¤ì¹­ (ì•„ì§ ë§¤ì¹­ ì•ˆ ëœ ê²ƒë“¤)
        remaining_scenes = [s for s in scene_ids if not (backgrounds_dir / f"{s}_bg.png").exists() 
                          and not (backgrounds_dir / f"{s}_bg.jpg").exists()
                          and not (backgrounds_dir / f"{s}_bg.jpeg").exists()
                          and not (backgrounds_dir / f"{s}_bg.webp").exists()]
        
        remaining_images = [img for img in source_images 
                          if not any(img.name in i for i in imported)]
        
        for scene_id, img in zip(remaining_scenes, remaining_images):
            dest = backgrounds_dir / f"{scene_id}_bg{img.suffix}"
            import shutil
            shutil.copy2(img, dest)
            imported.append(f"{img.name} â†’ {dest.name}")
            print(f"   âœ… {img.name} â†’ {dest.name} (ìˆœì„œ ë§¤ì¹­)")
        
        print()
        print(f"âœ… ì´ {len(imported)}ê°œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
        
        # ê²€ì¦ ì‹¤í–‰
        print()
        self.check_images()
        
        return {
            "status": "success",
            "imported": len(imported),
            "files": imported
        }


# ============================================================================
# ë Œë”ë§ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class RenderManager:
    """Manim ë Œë”ë§ ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def render_scene(
        self,
        scene_id: str,
        quality: str = "l",  # l=low, m=medium, h=high, k=4k
        preview: bool = True
    ) -> bool:
        """ë‹¨ì¼ ì”¬ ë Œë”ë§"""
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_file = project_dir / "4_manim_code" / f"{scene_id}_manim.py"
        
        if not code_file.exists():
            print(f"âŒ ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {code_file}")
            return False
        
        # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ (scene_idë¥¼ PascalCaseë¡œ)
        class_name = scene_id.capitalize()
        
        # Manim ëª…ë ¹ì–´ êµ¬ì„±
        cmd = ["manim"]

        if preview:
            cmd.append("-p")

        cmd.append(f"-q{quality}")
        cmd.append("--transparent")  # íˆ¬ëª… ë°°ê²½ (ë°°ê²½ ì´ë¯¸ì§€ í•©ì„±ìš©)
        cmd.append(str(code_file))
        cmd.append(class_name)
        
        print(f"\nğŸ¬ ë Œë”ë§: {scene_id}")
        print(f"   ëª…ë ¹ì–´: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"   âœ… ë Œë”ë§ ì„±ê³µ")
                return True
            else:
                print(f"   âŒ ë Œë”ë§ ì‹¤íŒ¨")
                print(f"   ì˜¤ë¥˜: {result.stderr}")
                return False
                
        except FileNotFoundError:
            print("   âŒ Manimì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜: pip install manim")
            return False
        except Exception as e:
            print(f"   âŒ ë Œë”ë§ ì˜¤ë¥˜: {e}")
            return False
    
    def render_all(
        self,
        quality: str = "l",
        preview: bool = False
    ) -> Dict[str, bool]:
        """ëª¨ë“  ì”¬ ë Œë”ë§"""
        
        # ë Œë”ë§ ì‹œì‘ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state.update_rendering()
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_dir = project_dir / "4_manim_code"
        
        if not code_dir.exists():
            print(f"âŒ ì½”ë“œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {code_dir}")
            return {}
        
        # ëª¨ë“  Manim íŒŒì¼ ì°¾ê¸°
        code_files = list(code_dir.glob("*_manim.py"))
        
        if not code_files:
            print("âŒ Manim ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        print(f"\nğŸ¬ ì´ {len(code_files)}ê°œ ì”¬ ë Œë”ë§ ì‹œì‘")
        print("="*60)
        
        results = {}
        
        for code_file in sorted(code_files):
            scene_id = code_file.stem.replace("_manim", "")
            success = self.render_scene(scene_id, quality, preview)
            results[scene_id] = success
        
        print("\n" + "="*60)
        success_count = sum(1 for v in results.values() if v)
        print(f"âœ… ë Œë”ë§ ì™„ë£Œ: {success_count}/{len(results)}ê°œ ì„±ê³µ")

        # ë Œë”ë§ ì„±ê³µí•œ ê²ƒì´ ìˆìœ¼ë©´ ê²°ê³¼ë¬¼ ìë™ ìˆ˜ì§‘
        if success_count > 0:
            print("\nğŸ“¦ ë Œë”ë§ ê²°ê³¼ë¬¼ ìë™ ìˆ˜ì§‘ ì¤‘...")
            self.collect_renders()

        return results

    def collect_renders(self) -> Dict[str, str]:
        """media/videos/ í´ë”ì—ì„œ ë Œë”ë§ ê²°ê³¼ë¬¼ì„ ìˆ˜ì§‘í•˜ì—¬ 8_renders/ë¡œ ë³µì‚¬"""

        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        renders_dir = project_dir / "8_renders"
        renders_dir.mkdir(parents=True, exist_ok=True)

        # Manim ê¸°ë³¸ ì¶œë ¥ í´ë”
        media_dir = Path("media/videos")

        if not media_dir.exists():
            print(f"âŒ media/videos í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        # í”„ë¡œì íŠ¸ì˜ ì”¬ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        scenes = self.state.get("scenes", {})
        completed_scenes = scenes.get("completed", [])

        if not completed_scenes:
            # ì½”ë“œ íŒŒì¼ì—ì„œ ì”¬ ID ì¶”ì¶œ
            code_dir = project_dir / "4_manim_code"
            if code_dir.exists():
                code_files = list(code_dir.glob("*_manim.py"))
                completed_scenes = [f.stem.replace("_manim", "") for f in code_files]

        print(f"\nğŸ“¦ ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘")
        print(f"   ì†ŒìŠ¤: {media_dir}")
        print(f"   ëŒ€ìƒ: {renders_dir}")
        print(f"   ì”¬ ê°œìˆ˜: {len(completed_scenes)}")
        print("="*60)

        collected = {}
        missing = []

        for scene_id in completed_scenes:
            # ì”¬ë³„ í´ë” ì°¾ê¸° (ì˜ˆ: s1_manim, s2_manim ë“±)
            scene_folder_pattern = f"{scene_id}_manim"
            scene_folders = list(media_dir.glob(scene_folder_pattern))

            if not scene_folders:
                missing.append(scene_id)
                continue

            scene_folder = scene_folders[0]

            # í’ˆì§ˆ í´ë” ì°¾ê¸° (480p15, 720p30, 1080p60 ë“±)
            quality_folders = [d for d in scene_folder.iterdir() if d.is_dir()]

            if not quality_folders:
                missing.append(scene_id)
                continue

            # ê°€ì¥ ìµœê·¼ í´ë” ì‚¬ìš© (ë³´í†µ í•˜ë‚˜ë¿)
            quality_folder = sorted(quality_folders, key=lambda x: x.stat().st_mtime, reverse=True)[0]

            # ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸° (.mov ë˜ëŠ” .mp4)
            video_files = list(quality_folder.glob("*.mov")) + list(quality_folder.glob("*.mp4"))

            if not video_files:
                missing.append(scene_id)
                continue

            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
            source_file = sorted(video_files, key=lambda x: x.stat().st_mtime, reverse=True)[0]

            # ëŒ€ìƒ íŒŒì¼ëª… (scene_id.í™•ì¥ì)
            dest_file = renders_dir / f"{scene_id}{source_file.suffix}"

            # ë³µì‚¬
            import shutil
            shutil.copy2(source_file, dest_file)

            collected[scene_id] = str(dest_file)
            print(f"   âœ… {scene_id}: {source_file.name} â†’ {dest_file.name}")

        print("\n" + "="*60)
        print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(collected)}ê°œ")

        if missing:
            print(f"âš ï¸  ëˆ„ë½: {len(missing)}ê°œ - {', '.join(missing)}")

        # state.json ì—…ë°ì´íŠ¸
        if collected:
            state_data = self.state.load()
            state_data.setdefault("files", {})["renders"] = list(collected.values())
            state_data["current_phase"] = "rendered"
            self.state.save()
            print(f"\nğŸ“ state.json ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            print(f"   current_phase: rendered")
            print(f"   files.renders: {len(collected)}ê°œ íŒŒì¼")

        return collected

    def generate_render_script(self) -> Optional[Path]:
        """ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_dir = project_dir / "4_manim_code"
        
        if not code_dir.exists():
            return None
        
        code_files = sorted(code_dir.glob("*_manim.py"))
        
        if not code_files:
            return None
        
        # Bash ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        script_file = project_dir / "render_all.sh"
        
        lines = [
            "#!/bin/bash",
            "# Manim ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸",
            f"# í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            f"# ìƒì„±ì¼: {datetime.now().isoformat()}",
            "",
            "set -e  # ì˜¤ë¥˜ ì‹œ ì¤‘ë‹¨",
            "",
        ]
        
        for code_file in code_files:
            scene_id = code_file.stem.replace("_manim", "")
            class_name = scene_id.capitalize()
            
            lines.append(f'echo "ë Œë”ë§: {scene_id}..."')
            lines.append(f'manim -pql "{code_file}" {class_name}')
            lines.append("")
        
        lines.append('echo "ëª¨ë“  ì”¬ ë Œë”ë§ ì™„ë£Œ!"')
        
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
        
        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ (Unix)
        try:
            script_file.chmod(0o755)
        except:
            pass
        
        # Windowsìš© ë°°ì¹˜ íŒŒì¼ë„ ìƒì„±
        bat_file = project_dir / "render_all.bat"
        
        bat_lines = [
            "@echo off",
            f"REM Manim ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸",
            f"REM í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            "",
        ]
        
        for code_file in code_files:
            scene_id = code_file.stem.replace("_manim", "")
            class_name = scene_id.capitalize()
            
            bat_lines.append(f'echo ë Œë”ë§: {scene_id}...')
            bat_lines.append(f'manim -pql "{code_file}" {class_name}')
            bat_lines.append("")
        
        bat_lines.append('echo ëª¨ë“  ì”¬ ë Œë”ë§ ì™„ë£Œ!')
        bat_lines.append("pause")
        
        with open(bat_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(bat_lines))
        
        print(f"âœ… ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
        print(f"   Bash: {script_file}")
        print(f"   Windows: {bat_file}")

        return script_file


# ============================================================================
# ì”¬ ë¶„í•  ì €ì¥ (í† í° ì ˆì•½)
# ============================================================================

class SceneSplitter:
    """scenes.jsonì„ ê°œë³„ ì”¬ íŒŒì¼ë¡œ ë¶„í• """

    def __init__(self, state: StateManager):
        self.state = state

    def split(self):
        """scenes.jsonì„ ê°œë³„ íŒŒì¼ë¡œ ë¶„í• """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        scenes_path = Path(f"output/{project_id}/2_scenes/scenes.json")
        if not scenes_path.exists():
            print(f"âŒ scenes.jsonì´ ì—†ìŠµë‹ˆë‹¤: {scenes_path}")
            return

        # scenes.json ì½ê¸°
        with open(scenes_path, "r", encoding="utf-8") as f:
            scenes = json.load(f)

        if not scenes:
            print("âŒ scenes.jsonì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return

        # ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
        output_dir = scenes_path.parent
        saved_count = 0

        for scene in scenes:
            scene_id = scene.get("scene_id", "unknown")
            scene_file = output_dir / f"{scene_id}.json"

            with open(scene_file, "w", encoding="utf-8") as f:
                json.dump(scene, f, ensure_ascii=False, indent=2)

            saved_count += 1

        print(f"âœ… {saved_count}ê°œ ì”¬ì„ ê°œë³„ íŒŒì¼ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        print(f"   ìœ„ì¹˜: {output_dir}/")
        print(f"   ì˜ˆ: {output_dir}/s1.json, s2.json, ...")
        print(f"\nğŸ’¡ ì´ì œ Claudeê°€ í•„ìš”í•œ ì”¬ë§Œ ì½ì–´ í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.")


# ============================================================================
# ì˜ìƒ í•©ì„± ë° ìë§‰ ê´€ë¦¬
# ============================================================================

class ComposerManager:
    """ì˜ìƒ í•©ì„± ë° ìë§‰ ìƒì„± ê´€ë¦¬"""

    def __init__(self, state: StateManager):
        self.state = state
        self.ffmpeg_path = self._find_ffmpeg()
        self.ffprobe_path = self._find_ffprobe()

    def _find_ffmpeg(self) -> str:
        """FFmpeg ê²½ë¡œ ì°¾ê¸°"""
        import shutil

        # ì‹œìŠ¤í…œ PATHì—ì„œ ì°¾ê¸°
        ffmpeg = shutil.which("ffmpeg")
        if ffmpeg:
            return ffmpeg

        # Windows ì¼ë°˜ì ì¸ ê²½ë¡œë“¤
        common_paths = [
            Path(os.environ.get("LOCALAPPDATA", "")) / "Microsoft/WinGet/Links/ffmpeg.exe",
            Path("C:/ffmpeg/bin/ffmpeg.exe"),
            Path("C:/Program Files/ffmpeg/bin/ffmpeg.exe"),
        ]

        for path in common_paths:
            if path.exists():
                return str(path)

        return "ffmpeg"  # PATHì— ìˆë‹¤ê³  ê°€ì •

    def _find_ffprobe(self) -> str:
        """FFprobe ê²½ë¡œ ì°¾ê¸°"""
        import shutil

        ffprobe = shutil.which("ffprobe")
        if ffprobe:
            return ffprobe

        # FFmpegì™€ ê°™ì€ í´ë”ì—ì„œ ì°¾ê¸°
        ffmpeg_dir = Path(self.ffmpeg_path).parent
        ffprobe_path = ffmpeg_dir / "ffprobe.exe"
        if ffprobe_path.exists():
            return str(ffprobe_path)

        return "ffprobe"

    def _get_duration(self, file_path: Path) -> Optional[float]:
        """ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ê¸¸ì´ í™•ì¸ (ffprobe ì‚¬ìš©)"""
        try:
            result = subprocess.run([
                self.ffprobe_path, "-v", "error",
                "-show_entries", "format=duration",
                "-of", "csv=p=0", str(file_path)
            ], capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return float(result.stdout.strip())
        except Exception as e:
            print(f"  âš ï¸ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return None

    def _get_project_paths(self) -> Dict[str, Path]:
        """í”„ë¡œì íŠ¸ ê²½ë¡œë“¤ ë°˜í™˜"""
        project_id = self.state.get("project_id")
        if not project_id:
            return {}

        base = Path("output") / project_id
        return {
            "base": base,
            "audio": base / "0_audio",
            "scenes": base / "2_scenes",
            "subtitles": base / "7_subtitles",
            "renders": base / "8_renders",
            "backgrounds": base / "9_backgrounds",
            "final": base / "10_scene_final",
        }

    def _format_srt_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜: HH:MM:SS,mmm"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def generate_subtitles(self) -> bool:
        """ëª¨ë“  ì”¬ì˜ SRT ìë§‰ ìƒì„± (ë¬¸ì¥ ë‹¨ìœ„)

        í…ìŠ¤íŠ¸ ì†ŒìŠ¤: scenes.jsonì˜ narration_display (Whisper ì¸ì‹ ê²°ê³¼ê°€ ì•„ë‹˜!)
        íƒ€ì´ë° ì†ŒìŠ¤: timing.jsonì˜ sentences ë°°ì—´ (Whisper segments)

        ë°©ì‹:
        1. narration_displayë¥¼ .?! ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¦¬ â†’ í…ìŠ¤íŠ¸
        2. timing.jsonì˜ sentences ë°°ì—´ì—ì„œ íƒ€ì´ë° ì¶”ì¶œ â†’ start/end
        3. ë¬¸ì¥ ìˆ˜ ì¼ì¹˜í•˜ë©´ 1:1 ë§¤í•‘, ë¶ˆì¼ì¹˜í•˜ë©´ ê· ë“± ë¶„ë°°
        """
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        audio_path = paths["audio"]
        subtitle_path = paths["subtitles"]
        scenes_path = paths["scenes"]

        # ìë§‰ í´ë” ìƒì„±
        subtitle_path.mkdir(parents=True, exist_ok=True)

        # scenes.jsonì—ì„œ ìë§‰ í…ìŠ¤íŠ¸ ë¡œë“œ
        # ìš°ì„ ìˆœìœ„: subtitle_display (;; í¬í•¨) > narration_display
        scene_texts = {}
        for scene_file in scenes_path.glob("s*.json"):
            try:
                with open(scene_file, 'r', encoding='utf-8') as f:
                    scene_data = json.load(f)
                    scene_id = scene_data.get('scene_id', scene_file.stem)
                    # subtitle_display ìš°ì„ , ì—†ìœ¼ë©´ narration_display fallback
                    subtitle_text = scene_data.get('subtitle_display', '')
                    if not subtitle_text:
                        subtitle_text = scene_data.get('narration_display', '')
                    scene_texts[scene_id] = subtitle_text
            except Exception as e:
                print(f"  âš ï¸ {scene_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")

        # timing íŒŒì¼ ì°¾ê¸° (s32a ê°™ì€ IDë„ ì§€ì›)
        def scene_sort_key(path):
            scene_id = path.stem.split("_")[0][1:]  # "s32a" -> "32a"
            import re
            match = re.match(r'(\d+)([a-z]*)', scene_id)
            if match:
                return (int(match.group(1)), match.group(2))
            return (0, scene_id)

        timing_files = sorted(audio_path.glob("*_timing.json"), key=scene_sort_key)

        if not timing_files:
            print("âŒ timing.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¨¼ì € TTS ìƒì„± ë˜ëŠ” audio-processë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return False

        generated = []

        for timing_file in timing_files:
            scene_id = timing_file.stem.replace("_timing", "")

            with open(timing_file, 'r', encoding='utf-8') as f:
                timing_data = json.load(f)

            # ì›ë³¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (Whisper ê²°ê³¼ê°€ ì•„ë‹Œ narration_display ì‚¬ìš©!)
            original_text = scene_texts.get(scene_id, '')
            if not original_text:
                print(f"  âš ï¸ {scene_id}: narration_display ì—†ìŒ, Whisper í…ìŠ¤íŠ¸ ì‚¬ìš©")
                original_text = timing_data.get('whisper_text', '')

            total_duration = timing_data.get('total_duration', timing_data.get('duration', 0))
            timing_sentences = timing_data.get('sentences', timing_data.get('segments', []))

            # narration_displayë¥¼ ë¬¸ì¥ ë¶„ë¦¬ (.?! ê¸°ì¤€)
            display_sentences = self._split_sentences(original_text)

            if not display_sentences or total_duration <= 0:
                # SRT íŒŒì¼ ì €ì¥ (ë¹ˆ íŒŒì¼)
                srt_file = subtitle_path / f"{scene_id}.srt"
                with open(srt_file, 'w', encoding='utf-8') as f:
                    f.write("")
                generated.append(scene_id)
                continue

            # íƒ€ì´ë° ê³„ì‚°: sentences ë°°ì—´ íƒ€ì´ë° + narration_display í…ìŠ¤íŠ¸
            sentence_timings = self._calculate_sentence_timings_from_segments(
                display_sentences, timing_sentences, total_duration
            )

            # SRT ìƒì„± - ë¬¸ì¥ ë‹¨ìœ„
            srt_lines = []
            for idx, (sentence, start, end) in enumerate(sentence_timings, 1):
                start_time = self._format_srt_time(start)
                end_time = self._format_srt_time(end)

                srt_lines.append(str(idx))
                srt_lines.append(f"{start_time} --> {end_time}")
                srt_lines.append(sentence)
                srt_lines.append("")

            # SRT íŒŒì¼ ì €ì¥
            srt_file = subtitle_path / f"{scene_id}.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write("\n".join(srt_lines))

            generated.append(scene_id)
            print(f"  âœ… {scene_id}.srt: {len(display_sentences)}ë¬¸ì¥")

        print(f"\nâœ… ìë§‰ ìƒì„± ì™„ë£Œ: {len(generated)}ê°œ íŒŒì¼")
        print(f"   ìœ„ì¹˜: {subtitle_path}")
        print(f"   â„¹ï¸  í…ìŠ¤íŠ¸: narration_display, íƒ€ì´ë°: Whisper segments")

        return True

    def generate_subtitle_for_scene(self, scene_id: str) -> bool:
        """ë‹¨ì¼ ì”¬ì˜ SRT ìë§‰ ìƒì„±"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        audio_path = paths["audio"]
        subtitle_path = paths["subtitles"]
        scenes_path = paths["scenes"]

        subtitle_path.mkdir(parents=True, exist_ok=True)

        # ì”¬ íŒŒì¼ì—ì„œ subtitle_display ë˜ëŠ” narration_display ë¡œë“œ
        scene_file = scenes_path / f"{scene_id}.json"
        if not scene_file.exists():
            print(f"âŒ ì”¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_file}")
            return False

        with open(scene_file, 'r', encoding='utf-8') as f:
            scene_data = json.load(f)
        # subtitle_display ìš°ì„ , ì—†ìœ¼ë©´ narration_display fallback
        original_text = scene_data.get('subtitle_display', '')
        if not original_text:
            original_text = scene_data.get('narration_display', '')

        # timing íŒŒì¼ ë¡œë“œ
        timing_file = audio_path / f"{scene_id}_timing.json"
        if not timing_file.exists():
            print(f"âŒ íƒ€ì´ë° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {timing_file}")
            return False

        with open(timing_file, 'r', encoding='utf-8') as f:
            timing_data = json.load(f)

        total_duration = timing_data.get('total_duration', 0)
        timing_sentences = timing_data.get('sentences', [])

        # ë¬¸ì¥ ë¶„ë¦¬ ë° íƒ€ì´ë° ê³„ì‚°
        display_sentences = self._split_sentences(original_text)

        if not display_sentences or total_duration <= 0:
            srt_file = subtitle_path / f"{scene_id}.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write("")
            print(f"  âš ï¸ {scene_id}: ë¹ˆ ìë§‰ ìƒì„±")
            return True

        sentence_timings = self._calculate_sentence_timings_from_segments(
            display_sentences, timing_sentences, total_duration
        )

        # SRT ìƒì„±
        srt_lines = []
        for idx, (sentence, start, end) in enumerate(sentence_timings, 1):
            start_time = self._format_srt_time(start)
            end_time = self._format_srt_time(end)
            srt_lines.append(str(idx))
            srt_lines.append(f"{start_time} --> {end_time}")
            srt_lines.append(sentence)
            srt_lines.append("")

        srt_file = subtitle_path / f"{scene_id}.srt"
        with open(srt_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(srt_lines))

        print(f"âœ… {scene_id}.srt ìƒì„± ì™„ë£Œ: {len(display_sentences)}ë¬¸ì¥")
        return True

    def _split_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬

        í•µì‹¬: Scene Directorê°€ s{n}.jsonì˜ subtitle_displayì— ;;ë¡œ ë¶„í•  ìœ„ì¹˜ë¥¼ ì§€ì •
        Pythonì€ ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ë§Œ ìˆ˜í–‰ (ìë™ ë¶„í•  ì—†ìŒ)

        - ;; êµ¬ë¶„ìê°€ ìˆìœ¼ë©´: ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        - ;; êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´: í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìë§‰ìœ¼ë¡œ ì‚¬ìš©
        """
        if not text:
            return []

        # ;; êµ¬ë¶„ìê°€ ìˆìœ¼ë©´ ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        if ';;' in text:
            sentences = text.split(';;')
            sentences = [s.strip() for s in sentences if s.strip()]
            return sentences

        # ;; ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìë§‰ìœ¼ë¡œ ë°˜í™˜
        return [text.strip()]

    def _calculate_sentence_timings_from_segments(
        self,
        display_sentences: List[str],
        timing_sentences: List[dict],
        total_duration: float
    ) -> List[tuple]:
        """ë¬¸ì¥ë³„ íƒ€ì´ë° ê³„ì‚° (ê· ë“± ë¶„ë°° ë°©ì‹)

        ============================================================
        [ìë§‰ íƒ€ì´ë° ê³„ì‚° ë¡œì§] - ê· ë“± ë¶„ë°°
        ============================================================

        Whisperì˜ í•œê³„:
        - segments: ë°œí™” ë‹¨ìœ„(pause ê¸°ì¤€)ì´ì§€ ë¬¸ì¥ ë‹¨ìœ„(.?!)ê°€ ì•„ë‹˜
        - words: í…ìŠ¤íŠ¸ ì˜¤ì¸ì‹ ë§ìŒ ("íƒ„ë ¥ì„±" â†’ "íŒ”ë ¥ì„±")

        ë”°ë¼ì„œ ê· ë“± ë¶„ë°° ì‚¬ìš©:
        - í…ìŠ¤íŠ¸: narration_displayì—ì„œ .?! ê¸°ì¤€ ë¶„ë¦¬ (ì •í™•í•¨)
        - íƒ€ì´ë°: total_duration / ë¬¸ì¥ìˆ˜ (ê·¼ì‚¬ì¹˜)

        ì˜ˆì‹œ (s16, 14.35ì´ˆ, 5ë¬¸ì¥):
        - ë¬¸ì¥1: 0.00 ~ 2.87ì´ˆ
        - ë¬¸ì¥2: 2.87 ~ 5.74ì´ˆ
        - ë¬¸ì¥3: 5.74 ~ 8.61ì´ˆ
        - ë¬¸ì¥4: 8.61 ~ 11.48ì´ˆ
        - ë¬¸ì¥5: 11.48 ~ 14.35ì´ˆ
        ============================================================

        Args:
            display_sentences: narration_displayì—ì„œ ë¶„ë¦¬í•œ ë¬¸ì¥ë“¤ (í…ìŠ¤íŠ¸ìš©)
            timing_sentences: timing.jsonì˜ sentences ë°°ì—´ (í˜„ì¬ ë¯¸ì‚¬ìš©)
            total_duration: ì „ì²´ ì˜¤ë””ì˜¤ ê¸¸ì´

        Returns:
            List of (sentence_text, start_time, end_time)
        """
        n_display = len(display_sentences)

        # ============================================================
        # ê· ë“± ë¶„ë°°: total_duration / ë¬¸ì¥ìˆ˜
        # ============================================================
        duration_per_sentence = total_duration / n_display
        result = []
        for i, sentence in enumerate(display_sentences):
            start = i * duration_per_sentence
            end = (i + 1) * duration_per_sentence
            # ë§ˆì§€ë§‰ ë¬¸ì¥ì€ ì •í™•íˆ total_durationê¹Œì§€
            if i == n_display - 1:
                end = total_duration
            result.append((sentence, start, end))
        return result

    def _merge_audio(self, scene_id: str) -> Optional[Path]:
        """ì”¬ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ë°˜í™˜ (ìƒˆ ë°©ì‹: ë‹¨ì¼ íŒŒì¼ / êµ¬ ë°©ì‹: ë³‘í•©)"""
        paths = self._get_project_paths()
        audio_path = paths["audio"]

        # 1. ìƒˆ ë°©ì‹: ë‹¨ì¼ íŒŒì¼ (s1.mp3) í™•ì¸
        single_file = audio_path / f"{scene_id}.mp3"
        if single_file.exists():
            return single_file

        # 2. êµ¬ ë°©ì‹: ë¬¸ì¥ë³„ íŒŒì¼ë“¤ (s1_1.mp3, s1_2.mp3, ...) ë³‘í•©
        audio_files = sorted(
            audio_path.glob(f"{scene_id}_*.mp3"),
            key=lambda x: int(x.stem.split("_")[1]) if "_" in x.stem and x.stem.split("_")[1].isdigit() else 0
        )

        # timing.json, concat.txt ë“± ì œì™¸
        audio_files = [f for f in audio_files if not any(x in f.stem for x in ["timing", "concat", "merged"])]

        if not audio_files:
            print(f"  âš ï¸  {scene_id}: ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ")
            return None

        # íŒŒì¼ì´ 1ê°œë©´ ë°”ë¡œ ë°˜í™˜
        if len(audio_files) == 1:
            return audio_files[0]

        merged_file = audio_path / f"{scene_id}_merged.mp3"

        # ì´ë¯¸ ë³‘í•©ëœ íŒŒì¼ì´ ìˆê³  ìµœì‹ ì´ë©´ ì¬ì‚¬ìš©
        if merged_file.exists():
            merged_time = merged_file.stat().st_mtime
            if all(f.stat().st_mtime < merged_time for f in audio_files):
                return merged_file

        # concat íŒŒì¼ ìƒì„±
        concat_file = audio_path / f"{scene_id}_concat.txt"
        with open(concat_file, 'w', encoding='utf-8') as f:
            for audio in audio_files:
                f.write(f"file '{audio.name}'\n")

        # FFmpegë¡œ ë³‘í•©
        cmd = [
            self.ffmpeg_path,
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
            "-c", "copy",
            "-y", str(merged_file)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"  âŒ {scene_id}: ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨")
            return None

        return merged_file

    def _find_manim_render(self, scene_id: str) -> Optional[Path]:
        """Manim ë Œë”ë§ ê²°ê³¼ ì°¾ê¸°"""
        # media/videos/{scene_id}_manim í´ë”ì—ì„œ ì°¾ê¸°
        media_path = Path("media/videos") / f"{scene_id}_manim"

        if media_path.exists():
            # í’ˆì§ˆë³„ í´ë” í™•ì¸ (ë†’ì€ í’ˆì§ˆ ìš°ì„ )
            for quality in ["1080p60", "1080p30", "720p30", "480p15"]:
                quality_path = media_path / quality
                if quality_path.exists():
                    # Scene*.mov ë˜ëŠ” Scene*.mp4 ì°¾ê¸°
                    for ext in ["mov", "mp4"]:
                        scene_files = list(quality_path.glob(f"Scene*.{ext}"))
                        if scene_files:
                            return scene_files[0]

        # 8_renders í´ë”ì—ì„œë„ ì°¾ê¸°
        paths = self._get_project_paths()
        renders_path = paths.get("renders")
        if renders_path and renders_path.exists():
            for ext in ["mov", "mp4"]:
                render_files = list(renders_path.glob(f"{scene_id}*.{ext}"))
                if render_files:
                    return render_files[0]

        return None

    def _find_background(self, scene_id: str) -> Optional[Path]:
        """ë°°ê²½ ì´ë¯¸ì§€ ì°¾ê¸°"""
        paths = self._get_project_paths()
        bg_path = paths.get("backgrounds")

        if not bg_path or not bg_path.exists():
            return None

        for ext in ["png", "jpg", "jpeg", "webp"]:
            bg_file = bg_path / f"{scene_id}_bg.{ext}"
            if bg_file.exists():
                return bg_file

        return None

    def compose_scene(self, scene_id: str, with_subtitle: bool = True) -> Optional[Path]:
        """ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½ + Manim + ì˜¤ë””ì˜¤ + ìë§‰)"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print(f"\nğŸ¬ {scene_id} í•©ì„± ì‹œì‘...")

        # ì¶œë ¥ í´ë” ìƒì„±
        final_path = paths["final"]
        final_path.mkdir(parents=True, exist_ok=True)

        # í•„ìš”í•œ íŒŒì¼ë“¤ ì°¾ê¸°
        manim_file = self._find_manim_render(scene_id)
        bg_file = self._find_background(scene_id)
        audio_file = self._merge_audio(scene_id)
        subtitle_file = paths["subtitles"] / f"{scene_id}.srt" if with_subtitle else None

        # íŒŒì¼ ì²´í¬
        if not manim_file:
            print(f"  âŒ Manim ë Œë”ë§ íŒŒì¼ ì—†ìŒ")
            return None

        if not audio_file:
            print(f"  âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ")
            return None

        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ì˜¤ë””ì˜¤ ê¸°ì¤€ìœ¼ë¡œ ì˜ìƒ ê¸¸ì´ ê²°ì •)
        audio_duration = self._get_duration(audio_file)
        if not audio_duration:
            print(f"  âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ë¶ˆê°€, ê¸°ë³¸ê°’ ì‚¬ìš©")
            audio_duration = 30.0

        print(f"  ğŸ“¹ Manim: {manim_file.name}")
        print(f"  ğŸµ Audio: {audio_file.name} ({audio_duration:.2f}ì´ˆ)")
        if bg_file:
            print(f"  ğŸ–¼ï¸  Background: {bg_file.name}")
        if subtitle_file and subtitle_file.exists():
            print(f"  ğŸ“ Subtitle: {subtitle_file.name}")

        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_file = final_path / f"{scene_id}_final.mp4"

        # ìë§‰ í•„í„° ì¤€ë¹„ (ë¬¸ì¥ ë‹¨ìœ„, í™”ë©´ ë§¨ ì•„ë˜ ë°°ì¹˜)
        # MarginV=15: í™”ë©´ ì•„ë˜ ì—¬ìœ 
        # MarginL/R=20: ì¢Œìš° ì—¬ë°±
        # FontSize=20: ê°€ë…ì„± í™•ë³´
        subtitle_filter_part = ""
        if with_subtitle and subtitle_file and subtitle_file.exists():
            srt_path = str(subtitle_file).replace("\\", "/").replace(":", "\\:")
            subtitle_filter_part = (
                f",subtitles='{srt_path}':"
                f"force_style='FontName=Malgun Gothic,FontSize=20,"
                f"PrimaryColour=&HFFFFFF,OutlineColour=&H000000,"
                f"Outline=2,Shadow=1,MarginV=15,MarginL=20,MarginR=20'"
            )

        # FFmpeg í•©ì„± ëª…ë ¹ êµ¬ì„± (ë°°ê²½ + Manim + ì˜¤ë””ì˜¤ + ìë§‰ í•œ ë²ˆì—)
        # eof_action=repeat: Manim ì˜ìƒ ëë‚˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
        if bg_file:
            # ë°°ê²½ + Manim ì˜¤ë²„ë ˆì´ + ìë§‰
            # subtitles í•„í„°ëŠ” overlay í›„ ë³„ë„ ì²´ì¸ìœ¼ë¡œ ì ìš©
            if with_subtitle and subtitle_file and subtitle_file.exists():
                srt_path_fc = str(subtitle_file).replace("\\", "/").replace(":", "\\:")
                filter_complex = (
                    f"[0:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                    f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2[bg];"
                    f"[1:v]scale=1920:1080:force_original_aspect_ratio=decrease,format=rgba[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2:eof_action=repeat[ov];"
                    f"[ov]subtitles='{srt_path_fc}':"
                    f"force_style='FontName=Malgun Gothic,FontSize=20,"
                    f"PrimaryColour=&HFFFFFF,OutlineColour=&H000000,"
                    f"Outline=2,Shadow=1,MarginV=15,MarginL=20,MarginR=20'[outv]"
                )
            else:
                filter_complex = (
                    f"[0:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                    f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2[bg];"
                    f"[1:v]scale=1920:1080:force_original_aspect_ratio=decrease,format=rgba[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2:eof_action=repeat[outv]"
                )

            cmd = [
                self.ffmpeg_path,
                "-loop", "1", "-i", str(bg_file),
                "-i", str(manim_file),
                "-i", str(audio_file),
                "-filter_complex", filter_complex,
                "-map", "[outv]", "-map", "2:a",
                "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                "-c:a", "aac", "-b:a", "192k",
                "-t", str(audio_duration),
                "-y", str(output_file)
            ]
        else:
            # Manimë§Œ ì‚¬ìš© (ë°°ê²½ ì—†ìŒ) + ìë§‰
            # tpad: Manim ëë‚˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
            video_filter = f"scale=1920:1080,tpad=stop_mode=clone:stop_duration={audio_duration}{subtitle_filter_part}"
            cmd = [
                self.ffmpeg_path,
                "-i", str(manim_file),
                "-i", str(audio_file),
                "-vf", video_filter,
                "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                "-c:a", "aac", "-b:a", "192k",
                "-t", str(audio_duration),
                "-y", str(output_file)
            ]

        # í•©ì„± ì‹¤í–‰
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"  âŒ í•©ì„± ì‹¤íŒ¨: {result.stderr[:200]}")
            return None

        if with_subtitle and subtitle_file and subtitle_file.exists():
            print(f"  âœ… ìë§‰ í¬í•¨ í•©ì„± ì™„ë£Œ")

        print(f"  âœ… í•©ì„± ì™„ë£Œ: {output_file.name}")
        return output_file

    def compose_all(self, with_subtitle: bool = True) -> List[Path]:
        """ëª¨ë“  ì”¬ í•©ì„±"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # scenes.jsonì—ì„œ ì”¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        scenes_file = paths["scenes"] / "scenes.json"
        if not scenes_file.exists():
            print("âŒ scenes.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes = json.load(f)

        scene_ids = [s["scene_id"] for s in scenes]

        print(f"\nğŸ¬ ì „ì²´ ì”¬ í•©ì„± ì‹œì‘ ({len(scene_ids)}ê°œ)")
        print("=" * 50)

        composed = []
        failed = []

        for i, scene_id in enumerate(scene_ids, 1):
            print(f"\n[{i}/{len(scene_ids)}] {scene_id}")

            result = self.compose_scene(scene_id, with_subtitle=with_subtitle)

            if result:
                composed.append(result)
            else:
                failed.append(scene_id)

        print("\n" + "=" * 50)
        print(f"âœ… í•©ì„± ì™„ë£Œ: {len(composed)}ê°œ")
        if failed:
            print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ ({', '.join(failed)})")

        return composed

    def merge_final(self) -> Optional[Path]:
        """ëª¨ë“  ì”¬ì„ í•˜ë‚˜ì˜ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        final_path = paths["final"]

        # í•©ì„±ëœ ì”¬ íŒŒì¼ ì°¾ê¸° (ìë§‰ í¬í•¨ ë²„ì „ ìš°ì„ )
        scene_files = []

        # scenes.jsonì—ì„œ ìˆœì„œ ê°€ì ¸ì˜¤ê¸°
        scenes_file = paths["scenes"] / "scenes.json"
        if scenes_file.exists():
            with open(scenes_file, 'r', encoding='utf-8') as f:
                scenes = json.load(f)
            scene_ids = [s["scene_id"] for s in scenes]
        else:
            # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
            all_files = list(final_path.glob("*_final*.mp4"))
            scene_ids = sorted(set(f.stem.split("_")[0] for f in all_files),
                             key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)

        for scene_id in scene_ids:
            scene_file = final_path / f"{scene_id}_final.mp4"
            if scene_file.exists():
                scene_files.append(scene_file)

        if not scene_files:
            print("âŒ í•©ì„±ëœ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¨¼ì € compose-allì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return None

        print(f"\nğŸ¬ ìµœì¢… ì˜ìƒ ë³‘í•© ({len(scene_files)}ê°œ ì”¬)")

        # concat íŒŒì¼ ìƒì„±
        concat_file = final_path / "final_concat.txt"
        with open(concat_file, 'w', encoding='utf-8') as f:
            for video in scene_files:
                f.write(f"file '{video.name}'\n")

        # ì¶œë ¥ íŒŒì¼
        output_file = paths["base"] / "final_video.mp4"

        # FFmpeg ë³‘í•©
        cmd = [
            self.ffmpeg_path,
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
            "-c", "copy",
            "-y", str(output_file)
        ]

        print("  ë³‘í•© ì¤‘...")
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"  âŒ ë³‘í•© ì‹¤íŒ¨: {result.stderr[:200]}")
            return None

        # íŒŒì¼ ì •ë³´ ì¶œë ¥
        probe_cmd = [
            self.ffprobe_path,
            "-v", "error",
            "-show_entries", "format=duration,size",
            "-of", "json",
            str(output_file)
        ]

        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)

        if probe_result.returncode == 0:
            info = json.loads(probe_result.stdout)
            duration = float(info.get("format", {}).get("duration", 0))
            size = int(info.get("format", {}).get("size", 0))

            mins = int(duration // 60)
            secs = int(duration % 60)
            size_mb = size / (1024 * 1024)

            print(f"\nâœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ!")
            print(f"   ğŸ“ íŒŒì¼: {output_file}")
            print(f"   â±ï¸  ê¸¸ì´: {mins}ë¶„ {secs}ì´ˆ")
            print(f"   ğŸ’¾ í¬ê¸°: {size_mb:.1f} MB")
        else:
            print(f"\nâœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_file}")

        # state.json ì—…ë°ì´íŠ¸
        self.state.update("current_phase", "completed")
        self.state.update("files.final_video", str(output_file))

        return output_file


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def convert_to_tts_text(text: str) -> str:
    """
    ì½ê¸°ìš© í…ìŠ¤íŠ¸ë¥¼ TTSìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    (ìˆ«ì/ê¸°í˜¸ â†’ í•œê¸€ ë°œìŒ)
    """
    
    # ë³€í™˜ ê·œì¹™
    conversions = [
        # ì—°ì‚°ì
        (r'Ã—', ' ê³±í•˜ê¸° '),
        (r'\*', ' ê³±í•˜ê¸° '),
        (r'Ã·', ' ë‚˜ëˆ„ê¸° '),
        (r'/', ' ë‚˜ëˆ„ê¸° '),
        (r'\+', ' í”ŒëŸ¬ìŠ¤ '),
        (r'(?<!\w)-(?!\w)', ' ë§ˆì´ë„ˆìŠ¤ '),  # ë‹¨ë… ë§ˆì´ë„ˆìŠ¤ë§Œ
        (r'=', 'ëŠ” '),
        
        # ìˆ˜í•™ ê¸°í˜¸
        (r'âˆš', 'ë£¨íŠ¸ '),
        (r'Â²', ' ì œê³±'),
        (r'Â³', ' ì„¸ì œê³±'),
        (r'âˆ«', 'ì ë¶„ '),
        (r'Î£', 'ì‹œê·¸ë§ˆ '),
        (r'âˆ', 'ë¬´í•œëŒ€'),
        (r'Ï€', 'íŒŒì´'),
        (r'Î¸', 'ì„¸íƒ€'),
        (r'Î±', 'ì•ŒíŒŒ'),
        (r'Î²', 'ë² íƒ€'),
        (r'Î³', 'ê°ë§ˆ'),
        (r'Î”', 'ë¸íƒ€'),
        
        # í•¨ìˆ˜ í‘œê¸°
        (r'f\(x\)', 'ì—í”„ì—‘ìŠ¤'),
        (r'g\(x\)', 'ì§€ì—‘ìŠ¤'),
        (r'h\(x\)', 'ì—ì´ì¹˜ì—‘ìŠ¤'),
        (r'dy/dx', 'ë””ì™€ì´ ë””ì—‘ìŠ¤'),
        (r'd/dx', 'ë”” ë””ì—‘ìŠ¤'),
        (r'dx', 'ë””ì—‘ìŠ¤'),
        (r'dy', 'ë””ì™€ì´'),
        (r'lim', 'ê·¹í•œê°’ '),
        (r'sin', 'ì‚¬ì¸ '),
        (r'cos', 'ì½”ì‚¬ì¸ '),
        (r'tan', 'íƒ„ì  íŠ¸ '),
        (r'log', 'ë¡œê·¸ '),
        (r'ln', 'ìì—°ë¡œê·¸ '),
        
        # ë‹¨ìœ„
        (r'cmÂ²', 'ì œê³±ì„¼í‹°ë¯¸í„°'),
        (r'cm', 'ì„¼í‹°ë¯¸í„°'),
        (r'mÂ²', 'ì œê³±ë¯¸í„°'),
        (r'km', 'í‚¬ë¡œë¯¸í„°'),
        (r'kg', 'í‚¬ë¡œê·¸ë¨'),
        
        # ìˆ«ì (ë‘ ìë¦¬ ì´ìƒì€ ê·¸ëŒ€ë¡œ)
        (r'\b0\b', 'ì˜'),
        (r'\b1\b', 'ì¼'),
        (r'\b2\b', 'ì´'),
        (r'\b3\b', 'ì‚¼'),
        (r'\b4\b', 'ì‚¬'),
        (r'\b5\b', 'ì˜¤'),
        (r'\b6\b', 'ìœ¡'),
        (r'\b7\b', 'ì¹ '),
        (r'\b8\b', 'íŒ”'),
        (r'\b9\b', 'êµ¬'),
        (r'\b10\b', 'ì‹­'),
    ]
    
    result = text
    for pattern, replacement in conversions:
        result = re.sub(pattern, replacement, result)
    
    # ì—°ì† ê³µë°± ì œê±°
    result = re.sub(r'\s+', ' ', result)
    
    return result.strip()


def print_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    help_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.4                        â•‘
â•‘        Claude Code í†µí•© ë²„ì „ (gpt-4o-mini-tts)                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ ì‚¬ìš©ë²•:
    python math_video_pipeline.py <ëª…ë ¹ì–´> [ì˜µì…˜]

ğŸ“‹ ëª…ë ¹ì–´:

  init          ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
                --title "ì œëª©"     ì˜ìƒ ì œëª© (í•„ìˆ˜)
                --duration 480     ê¸¸ì´(ì´ˆ), ê¸°ë³¸ê°’ 480 (8ë¶„)
                --aspect 16:9      ì¢…íš¡ë¹„ (16:9 / 9:16)
                --style cyberpunk  ìŠ¤íƒ€ì¼ (minimal/cyberpunk/paper/space/geometric/stickman)
                --difficulty intermediate  ë‚œì´ë„ (beginner/intermediate/advanced)
                --voice alloy              TTS ìŒì„± (OpenAI)

  status        í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸

  tts           ë‹¨ì¼ ì”¬ TTS ìƒì„±
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --text "í…ìŠ¤íŠ¸"    ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ (í•„ìˆ˜)

  tts-all       ëª¨ë“  ì”¬ TTS ìƒì„± (scenes.json ê¸°ë°˜)

  prompts-export    ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
                    â†’ 6_image_prompts/prompts_batch.txt

  images-check      ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸
                    â†’ 9_backgrounds/ í´ë”ì˜ ì´ë¯¸ì§€ ê²€ì¦

  images-import     ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°
                    --source "í´ë”ê²½ë¡œ"  ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” (í•„ìˆ˜)

  render        ë‹¨ì¼ ì”¬ ë Œë”ë§
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --quality l        í’ˆì§ˆ (l/m/h/k)
                --no-preview       ë¯¸ë¦¬ë³´ê¸° ì—†ì´ ë Œë”ë§

  render-all    ëª¨ë“  ì”¬ ë Œë”ë§
                --quality l        í’ˆì§ˆ (l/m/h/k)

  render-collect ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘
                media/videos/ì—ì„œ 8_renders/ë¡œ íŒŒì¼ ë³µì‚¬
                state.jsonì— files.renders ì—…ë°ì´íŠ¸

  render-script ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

  subtitle-generate  ëª¨ë“  ì”¬ SRT ìë§‰ ìƒì„±
                     â†’ 7_subtitles/ í´ë”ì— s1.srt, s2.srt, ... ìƒì„±

  compose       ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --no-subtitle      ìë§‰ ì—†ì´ í•©ì„±

  compose-all   ëª¨ë“  ì”¬ í•©ì„±
                --no-subtitle      ìë§‰ ì—†ì´ í•©ì„±

  merge-final   ëª¨ë“  ì”¬ì„ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©
                â†’ final_video.mp4 ìƒì„±

  convert       í…ìŠ¤íŠ¸ë¥¼ TTSìš©ìœ¼ë¡œ ë³€í™˜
                --text "9Ã—9=81"    ë³€í™˜í•  í…ìŠ¤íŠ¸

  files         í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡

  help          ì´ ë„ì›€ë§ í‘œì‹œ

ğŸ¤ TTS ìŒì„± ì˜µì…˜ (gpt-4o-mini-tts):
  ash        ì°¨ë¶„í•œ ë‚¨ì„± [ê¸°ë³¸ê°’] â­
  onyx       ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬
  echo       ë‚¨ì„±ì , ì°¨ë¶„í•¨
  alloy      ì¤‘ì„±ì , ê· í˜•ì¡íŒ
  coral      ë”°ëœ»í•œ ì—¬ì„±
  nova       ì—¬ì„±ì , ë°ê³  ì¹œê·¼
  marin      ê³ í’ˆì§ˆ ì¶”ì²œ
  cedar      ê³ í’ˆì§ˆ ì¶”ì²œ

  ğŸ’¡ í•œêµ­ì–´ ë°œìŒ ê°œì„  + ì €ë ´í•œ ë¹„ìš© (~$0.015/ë¶„)
  ğŸ§ ìŒì„± ìƒ˜í”Œ: https://platform.openai.com/docs/guides/text-to-speech

ğŸ“– ì˜ˆì‹œ:

  # 1. ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘
  python math_video_pipeline.py init --title "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬" --duration 480

  # 2. Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±
  # "skills/script-writer.md ì½ê³  ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"

  # 3. Claude Codeì—ì„œ ì”¬ ë¶„í• 
  # "skills/scene-director.md ì½ê³  ì”¬ ë¶„í• í•´ì¤˜"

  # 4. ëª¨ë“  ì”¬ TTS ìƒì„±
  python math_video_pipeline.py tts-all

  # 5. Claude Codeì—ì„œ Manim ì½”ë“œ ìƒì„±
  # "skills/manim-coder.md ì½ê³  s1 ì½”ë“œ ìƒì„±í•´ì¤˜"

  # 6. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë‚´ë³´ë‚´ê¸°
  python math_video_pipeline.py prompts-export

  # 7. ì™¸ë¶€ì—ì„œ ì´ë¯¸ì§€ ìƒì„± í›„ ê°€ì ¸ì˜¤ê¸°
  python math_video_pipeline.py images-import --source "C:/Downloads/backgrounds"

  # 8. ì´ë¯¸ì§€ ê²€ì¦
  python math_video_pipeline.py images-check

  # 9. ë Œë”ë§
  python math_video_pipeline.py render-all

  # 10. ìë§‰ ìƒì„±
  python math_video_pipeline.py subtitle-generate

  # 11. ëª¨ë“  ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)
  python math_video_pipeline.py compose-all

  # 12. ìµœì¢… ì˜ìƒ ë³‘í•©
  python math_video_pipeline.py merge-final

ğŸ“ ì¶œë ¥ êµ¬ì¡°:
  output/{project_id}/
  â”œâ”€â”€ 0_audio/          TTS ìŒì„± + íƒ€ì´ë°
  â”œâ”€â”€ 1_script/         ëŒ€ë³¸
  â”œâ”€â”€ 2_scenes/         ì”¬ ë¶„í• 
  â”œâ”€â”€ 4_manim_code/     Manim ì½”ë“œ
  â”œâ”€â”€ 6_image_prompts/  ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
  â”œâ”€â”€ 7_subtitles/      ìë§‰
  â”œâ”€â”€ 8_renders/        Manim ë Œë”ë§ ê²°ê³¼
  â”œâ”€â”€ 9_backgrounds/    ë°°ê²½ ì´ë¯¸ì§€ (ì™¸ë¶€ ìƒì„±)
  â”œâ”€â”€ 10_scene_final/   ì”¬ë³„ í•©ì„± ì˜ìƒ
  â””â”€â”€ final_video.mp4   ìµœì¢… ì˜ìƒ

ğŸ–¼ï¸ ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼ëª… ê·œì¹™:
  s1_bg.png, s2_bg.png, s3_bg.png, ...
  (ì”¬ ID + _bg.png)

ğŸ”„ /clear ê°€ëŠ¥ ì§€ì :
  âœ… ëŒ€ë³¸ ìŠ¹ì¸ í›„ (script_approved)
  âœ… ì”¬ ë¶„í•  í›„ (scenes_approved)
  âœ… TTS ì™„ë£Œ í›„ (tts_completed)
  âœ… ë§¤ 3-5ì”¬ ì½”ë“œ ì™„ë£Œ í›„
  âœ… ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ í›„
  
  ì¬ê°œ: "ê³„ì†" ë˜ëŠ” "ìƒíƒœ" ì…ë ¥
"""
    print(help_text)


# ============================================================================
# CLI ë©”ì¸
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    parser = argparse.ArgumentParser(
        description="ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.1",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")
    
    # init ëª…ë ¹ì–´
    init_parser = subparsers.add_parser("init", help="ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”")
    init_parser.add_argument("--title", "-t", required=True, help="ì˜ìƒ ì œëª©")
    init_parser.add_argument("--duration", "-d", type=int, default=480, help="ì˜ìƒ ê¸¸ì´(ì´ˆ), ê¸°ë³¸ê°’ 480 (8ë¶„)")
    init_parser.add_argument("--style", "-s", default="cyberpunk",
                            choices=["minimal", "cyberpunk", "paper", "space", "geometric", "stickman"],
                            help="ì‹œê° ìŠ¤íƒ€ì¼")
    init_parser.add_argument("--difficulty", default="intermediate",
                            choices=["beginner", "intermediate", "advanced"],
                            help="ë‚œì´ë„")
    init_parser.add_argument("--aspect", default="16:9",
                            choices=["16:9", "9:16"],
                            help="ì¢…íš¡ë¹„")
    init_parser.add_argument("--voice", default="alloy",
                            choices=["ash", "alloy", "ballad", "coral", "echo", "fable", "onyx", "nova", "sage", "shimmer", "verse", "marin", "cedar"],
                            help="TTS ìŒì„± (OpenAI gpt-4o-mini-tts)")
    
    # status ëª…ë ¹ì–´
    subparsers.add_parser("status", help="í˜„ì¬ ìƒíƒœ í™•ì¸")

    # verify-sync ëª…ë ¹ì–´ (ëŒ€ë³¸-TTS ë™ê¸°í™” ê²€ì¦)
    verify_sync_parser = subparsers.add_parser("verify-sync", help="ëŒ€ë³¸(scenes.json)ê³¼ TTS ë…¹ìŒ ë™ê¸°í™” ê²€ì¦")
    verify_sync_parser.add_argument("scene_id", nargs="?", help="ì”¬ ID (ì˜ˆ: s7). ìƒëµí•˜ë©´ ì „ì²´ ê²€ì¦")
    
    # tts ëª…ë ¹ì–´
    tts_parser = subparsers.add_parser("tts", help="ë‹¨ì¼ ì”¬ TTS ìƒì„±")
    tts_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID")
    tts_parser.add_argument("--text", "-t", required=True, help="ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸")
    tts_parser.add_argument("--voice", "-v", help="TTS ìŒì„± (ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ì„¤ì •)")
    
    # tts-all ëª…ë ¹ì–´
    tts_all_parser = subparsers.add_parser("tts-all", help="ëª¨ë“  ì”¬ TTS ìƒì„±")
    tts_all_parser.add_argument("--start-from", "-f", type=int, default=1,
                               help="ì‹œì‘í•  ì”¬ ë²ˆí˜¸ (ì˜ˆ: 14ë©´ s14ë¶€í„° ì‹œì‘)")

    # tts-export ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°)
    subparsers.add_parser("tts-export", help="ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ JSON ë‚´ë³´ë‚´ê¸°")

    # audio-check ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ í™•ì¸)
    subparsers.add_parser("audio-check", help="ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ëˆ„ë½ í™•ì¸")

    # audio-process ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ì²˜ë¦¬)
    subparsers.add_parser("audio-process", help="ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ Whisper ë¶„ì„ + timing.json ìƒì„±")

    # asset-check ëª…ë ¹ì–´ (Supabase ì—ì…‹ ì²´í¬)
    subparsers.add_parser("asset-check", help="ì—ì…‹ ì²´í¬ (Supabase ì¡°íšŒ + ë‹¤ìš´ë¡œë“œ + ëˆ„ë½ ëª©ë¡)")

    # asset-sync ëª…ë ¹ì–´ (ë¡œì»¬ â†’ Supabase ì—…ë¡œë“œ)
    subparsers.add_parser("asset-sync", help="ì—ì…‹ ë™ê¸°í™” (ë¡œì»¬ ì‹ ê·œ íŒŒì¼ â†’ Supabase ì—…ë¡œë“œ)")

    # catalog-update ëª…ë ¹ì–´ (Supabase â†’ asset-catalog.md)
    subparsers.add_parser("catalog-update", help="ì—ì…‹ ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸ (Supabaseì—ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°)")

    # render ëª…ë ¹ì–´
    render_parser = subparsers.add_parser("render", help="ë‹¨ì¼ ì”¬ ë Œë”ë§")
    render_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID")
    render_parser.add_argument("--quality", "-q", default="l",
                              choices=["l", "m", "h", "k"],
                              help="ë Œë”ë§ í’ˆì§ˆ")
    render_parser.add_argument("--no-preview", action="store_true",
                              help="ë¯¸ë¦¬ë³´ê¸° ì—†ì´ ë Œë”ë§")
    
    # render-all ëª…ë ¹ì–´
    render_all_parser = subparsers.add_parser("render-all", help="ëª¨ë“  ì”¬ ë Œë”ë§")
    render_all_parser.add_argument("--quality", "-q", default="l",
                                   choices=["l", "m", "h", "k"],
                                   help="ë Œë”ë§ í’ˆì§ˆ")
    
    # render-script ëª…ë ¹ì–´
    subparsers.add_parser("render-script", help="ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")

    # render-collect ëª…ë ¹ì–´
    subparsers.add_parser("render-collect", help="media/videos/ì—ì„œ ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘í•˜ì—¬ 8_renders/ë¡œ ë³µì‚¬")

    # prompts-export ëª…ë ¹ì–´
    subparsers.add_parser("prompts-export", help="ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°")
    
    # images-check ëª…ë ¹ì–´
    subparsers.add_parser("images-check", help="ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸")
    
    # images-import ëª…ë ¹ì–´
    images_import_parser = subparsers.add_parser("images-import", help="ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°")
    images_import_parser.add_argument("--source", "-s", required=True, help="ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ")
    
    # convert ëª…ë ¹ì–´
    convert_parser = subparsers.add_parser("convert", help="í…ìŠ¤íŠ¸ë¥¼ TTSìš©ìœ¼ë¡œ ë³€í™˜")
    convert_parser.add_argument("--text", "-t", required=True, help="ë³€í™˜í•  í…ìŠ¤íŠ¸")
    
    # files ëª…ë ¹ì–´
    subparsers.add_parser("files", help="í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡")

    # help ëª…ë ¹ì–´
    subparsers.add_parser("help", help="ë„ì›€ë§ í‘œì‹œ")

    # subtitle-generate ëª…ë ¹ì–´
    subparsers.add_parser("subtitle-generate", help="ëª¨ë“  ì”¬ SRT ìë§‰ ìƒì„±")

    # subtitle-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ ìë§‰ ìƒì„±)
    subtitle_scene_parser = subparsers.add_parser("subtitle-scene", help="ë‹¨ì¼ ì”¬ SRT ìë§‰ ìƒì„±")
    subtitle_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")

    # tts-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ TTS ì¬ìƒì„± - scenes.jsonì—ì„œ í…ìŠ¤íŠ¸ ìë™ ë¡œë“œ)
    tts_scene_parser = subparsers.add_parser("tts-scene", help="ë‹¨ì¼ ì”¬ TTS ì¬ìƒì„± (scenes.jsonì—ì„œ í…ìŠ¤íŠ¸ ë¡œë“œ)")
    tts_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")

    # render-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ ë Œë”ë§ - ê°„í¸ ë²„ì „)
    render_scene_parser = subparsers.add_parser("render-scene", help="ë‹¨ì¼ ì”¬ Manim ë Œë”ë§")
    render_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")
    render_scene_parser.add_argument("--quality", "-q", default="l", choices=["l", "m", "h", "k"], help="ë Œë”ë§ í’ˆì§ˆ")

    # compose-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ í•©ì„± - ê°„í¸ ë²„ì „)
    compose_scene_parser = subparsers.add_parser("compose-scene", help="ë‹¨ì¼ ì”¬ í•©ì„±")
    compose_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")
    compose_scene_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # compose ëª…ë ¹ì–´ (ë‹¨ì¼ ì”¬)
    compose_parser = subparsers.add_parser("compose", help="ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)")
    compose_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID (ì˜ˆ: s1)")
    compose_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # compose-all ëª…ë ¹ì–´
    compose_all_parser = subparsers.add_parser("compose-all", help="ëª¨ë“  ì”¬ í•©ì„±")
    compose_all_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # merge-final ëª…ë ¹ì–´
    subparsers.add_parser("merge-final", help="ëª¨ë“  ì”¬ì„ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©")

    # split-scenes ëª…ë ¹ì–´
    subparsers.add_parser("split-scenes", help="scenes.jsonì„ ê°œë³„ ì”¬ íŒŒì¼ë¡œ ë¶„í•  (í† í° ì ˆì•½)")

    args = parser.parse_args()
    
    # ëª…ë ¹ì–´ ì—†ìœ¼ë©´ ë„ì›€ë§
    if not args.command:
        print_help()
        return
    
    # ìƒíƒœ ê´€ë¦¬ì ì´ˆê¸°í™”
    state = StateManager()
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "help":
        print_help()
    
    elif args.command == "init":
        project = ProjectManager(state)
        project.init_project(
            title=args.title,
            duration=args.duration,
            style=args.style,
            difficulty=args.difficulty,
            aspect_ratio=args.aspect,
            voice=args.voice
        )
    
    elif args.command == "status":
        project = ProjectManager(state)
        project.show_status()

    elif args.command == "verify-sync":
        tts = TTSGenerator(state)
        tts.verify_sync(args.scene_id)
    
    elif args.command == "tts":
        tts = TTSGenerator(state)
        tts.generate(args.scene, args.text, args.voice)
    
    elif args.command == "tts-all":
        tts = TTSGenerator(state)
        start_from = getattr(args, 'start_from', 1)
        tts.generate_all_from_scenes(start_from=start_from)

    elif args.command == "tts-export":
        tts = TTSGenerator(state)
        tts.export_texts()

    elif args.command == "audio-check":
        tts = TTSGenerator(state)
        tts.check_audio_files()

    elif args.command == "audio-process":
        tts = TTSGenerator(state)
        tts.process_audio_files()

    elif args.command == "asset-check":
        assets = AssetManager(state)
        assets.check_assets()

    elif args.command == "asset-sync":
        assets = AssetManager(state)
        assets.sync_assets()

    elif args.command == "catalog-update":
        assets = AssetManager(state)
        assets.update_catalog()

    elif args.command == "render":
        renderer = RenderManager(state)
        renderer.render_scene(
            args.scene,
            quality=args.quality,
            preview=not args.no_preview
        )
    
    elif args.command == "render-all":
        renderer = RenderManager(state)
        renderer.render_all(quality=args.quality, preview=False)
    
    elif args.command == "render-script":
        renderer = RenderManager(state)
        renderer.generate_render_script()

    elif args.command == "render-collect":
        renderer = RenderManager(state)
        renderer.collect_renders()

    elif args.command == "prompts-export":
        images = ImageManager(state)
        images.export_prompts()
    
    elif args.command == "images-check":
        images = ImageManager(state)
        images.check_images()
    
    elif args.command == "images-import":
        images = ImageManager(state)
        images.import_images(args.source)
    
    elif args.command == "convert":
        result = convert_to_tts_text(args.text)
        print(f"\nì…ë ¥: {args.text}")
        print(f"ë³€í™˜: {result}")
    
    elif args.command == "files":
        files = FileManager(state)
        file_list = files.list_files()

        if not file_list:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ê±°ë‚˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("\nğŸ“ í”„ë¡œì íŠ¸ íŒŒì¼:")
            for folder, items in sorted(file_list.items()):
                print(f"\n  {folder}/")
                for item in sorted(items):
                    print(f"    - {item}")

    elif args.command == "subtitle-generate":
        composer = ComposerManager(state)
        composer.generate_subtitles()

    elif args.command == "subtitle-scene":
        composer = ComposerManager(state)
        composer.generate_subtitle_for_scene(args.scene_id)

    elif args.command == "tts-scene":
        tts = TTSGenerator(state)
        tts.generate_for_scene(args.scene_id)

    elif args.command == "render-scene":
        renderer = RenderManager(state)
        renderer.render_scene(args.scene_id, quality=args.quality, preview=False)

    elif args.command == "compose-scene":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_scene(args.scene_id, with_subtitle=with_subtitle)

    elif args.command == "compose":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_scene(args.scene, with_subtitle=with_subtitle)

    elif args.command == "compose-all":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_all(with_subtitle=with_subtitle)

    elif args.command == "merge-final":
        composer = ComposerManager(state)
        composer.merge_final()

    elif args.command == "split-scenes":
        scene_splitter = SceneSplitter(state)
        scene_splitter.split()

    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {args.command}")
        print("   python math_video_pipeline.py help ë¡œ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”.")


# ============================================================================
# ì§„ì…ì 
# ============================================================================

if __name__ == "__main__":
    main()


