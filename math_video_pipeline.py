
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.1
=====================================

Claude Code í†µí•© ë²„ì „
- ì°½ì˜ì  ì‘ì—…(ëŒ€ë³¸, ì”¬, Manim ì½”ë“œ): Claude Codeê°€ skills/*.md ì°¸ì¡°í•˜ì—¬ ìƒì„±
- API ì‘ì—…(TTS, Whisper): ì´ Python ìŠ¤í¬ë¦½íŠ¸ê°€ ë‹´ë‹¹
- íŒŒì¼ ê´€ë¦¬: state.jsonìœ¼ë¡œ ì§„í–‰ ìƒíƒœ ì¶”ì 

ì‚¬ìš©ë²•:
    python math_video_pipeline.py --help
    python math_video_pipeline.py init --title "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬" --duration 480
    python math_video_pipeline.py tts --scene s1 --text "ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸"
    python math_video_pipeline.py tts-all
    python math_video_pipeline.py status
    python math_video_pipeline.py render --scene s1
    python math_video_pipeline.py render-all
"""

import argparse
import json
import os
import sys
import io
import subprocess
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì • (Windows ì½˜ì†” í˜¸í™˜)
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ============================================================================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (TTS + Whisper)
# ============================================================================

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (TTS/Whisperìš©).")
    print("   ì„¤ì¹˜: pip install openai")

try:
    from google.cloud import texttospeech
    GOOGLE_TTS_AVAILABLE = True
except ImportError:
    GOOGLE_TTS_AVAILABLE = False
    print("âš ï¸  Google Cloud TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install google-cloud-texttospeech")

# Gemini TTS (google-genai)
try:
    from google import genai
    from google.genai import types
    GEMINI_TTS_AVAILABLE = True
except ImportError:
    GEMINI_TTS_AVAILABLE = False
    print("âš ï¸  Gemini TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install google-genai")

import wave

# Supabase (ì—ì…‹ ê´€ë¦¬)
try:
    from supabase import create_client, Client as SupabaseClient
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âš ï¸  Supabase ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install supabase")

# PIL (ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°)
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False


# ============================================================================
# ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤
# ============================================================================

class QuotaExceededException(Exception):
    """API ì¼ì¼ í•œë„ ì´ˆê³¼ ì˜ˆì™¸"""
    pass


def get_openai_client() -> Optional['OpenAI']:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if not OPENAI_AVAILABLE:
        return None
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("OPENAI_API_KEY="):
                        api_key = line.split("=", 1)[1].strip().strip('"\'')
                        break
    
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— OPENAI_API_KEY=sk-... ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None
    
    return OpenAI(api_key=api_key)


def get_google_tts_client() -> Optional['texttospeech.TextToSpeechClient']:
    """Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if not GOOGLE_TTS_AVAILABLE:
        return None

    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if not credentials_path:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("GOOGLE_APPLICATION_CREDENTIALS="):
                        credentials_path = line.split("=", 1)[1].strip().strip('"\'')
                        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
                        break

    if not credentials_path or not Path(credentials_path).exists():
        print("âŒ GOOGLE_APPLICATION_CREDENTIALSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— GOOGLE_APPLICATION_CREDENTIALS=ê²½ë¡œ ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    try:
        return texttospeech.TextToSpeechClient()
    except Exception as e:
        print(f"âŒ Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def get_gemini_client() -> Optional['genai.Client']:
    """Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± (TTSìš©)"""
    if not GEMINI_TTS_AVAILABLE:
        return None

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("GOOGLE_API_KEY="):
                        api_key = line.split("=", 1)[1].strip().strip('"\'')
                        break

    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Gemini TTSìš©).")
        print("   .env íŒŒì¼ì— GOOGLE_API_KEY=... ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    try:
        return genai.Client(api_key=api_key)
    except Exception as e:
        print(f"âŒ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


# ============================================================================
# ì„¤ì • ë° ìƒìˆ˜
# ============================================================================

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬)
PROJECT_ROOT = Path(__file__).parent.resolve()

# ì£¼ìš” ê²½ë¡œ
STATE_FILE = PROJECT_ROOT / "state.json"
OUTPUT_DIR = PROJECT_ROOT / "output"
SKILLS_DIR = PROJECT_ROOT / "skills"

# TTS ì„¤ì • (OpenAI gpt-4o-mini-tts)
TTS_CONFIG = {
    "voices": {
        "ash": "ì°¨ë¶„í•œ ë‚¨ì„± (ê¸°ë³¸ê°’)",
        "alloy": "ì¤‘ì„±ì , ê· í˜•ì¡íŒ",
        "ballad": "ë¶€ë“œëŸ¬ìš´ ë‚­ë…",
        "coral": "ë”°ëœ»í•œ ì—¬ì„±",
        "echo": "ë‚¨ì„±ì , ì°¨ë¶„í•¨",
        "fable": "ì˜êµ­ì‹ ì–µì–‘",
        "onyx": "ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬",
        "nova": "ì—¬ì„±ì , ë°ê³  ì¹œê·¼",
        "sage": "ì§€ì ì¸ í†¤",
        "shimmer": "ì—¬ì„±ì , ë¶€ë“œëŸ¬ì›€",
        "verse": "í‘œí˜„ë ¥ í’ë¶€",
        "marin": "ê³ í’ˆì§ˆ",
        "cedar": "ê³ í’ˆì§ˆ"
    },
    "default_voice": "alloy",
    "model": "gpt-4o-mini-tts",
    "audio_encoding": "MP3"
}

# ìŠ¤íƒ€ì¼ ì„¤ì •
STYLE_CONFIG = {
    "minimal": {
        "glow": False,
        "primary_color": "WHITE",
        "background_color": "BLACK",
        "flash_frequency": "low"
    },
    "cyberpunk": {
        "glow": True,
        "primary_color": "CYAN",
        "background_color": "#0a0a0a",
        "flash_frequency": "high"
    },
    "paper": {
        "glow": False,
        "primary_color": "BLACK",
        "background_color": "#f5f5dc",
        "flash_frequency": "medium"
    },
    "space": {
        "glow": True,
        "primary_color": "BLUE",
        "background_color": "#000011",
        "flash_frequency": "medium"
    },
    "geometric": {
        "glow": False,
        "primary_color": "GOLD",
        "background_color": "#1a1a1a",
        "flash_frequency": "medium"
    },
    "stickman": {
        "glow": False,
        "primary_color": "WHITE",
        "background_color": "#1a1a2e",
        "flash_frequency": "medium"
    }
}

# ì»¬ëŸ¬ íŒ”ë ˆíŠ¸
COLOR_PALETTE = {
    "variable": "YELLOW",
    "constant": "ORANGE",
    "result": "GREEN",
    "emphasis": "RED",
    "auxiliary": "GRAY_B"
}


# ============================================================================
# ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class StateManager:
    """í”„ë¡œì íŠ¸ ìƒíƒœ ê´€ë¦¬"""
    
    def __init__(self, state_file: Path = STATE_FILE):
        self.state_file = state_file
        self._state = None
    
    def load(self) -> Dict[str, Any]:
        """state.json ë¡œë“œ"""
        if self._state is not None:
            return self._state

        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    self._state = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸  {self.state_file} íŒŒì‹± ì˜¤ë¥˜. ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                self._state = self._default_state()
        else:
            self._state = self._default_state()

        return self._state

    def reload(self) -> Dict[str, Any]:
        """state.json ê°•ì œ ì¬ë¡œë“œ (ìºì‹œ ë¬´ì‹œ)"""
        self._state = None
        return self.load()
    
    def save(self) -> None:
        """state.json ì €ì¥"""
        if self._state is None:
            self._state = self._default_state()
        
        self._state["last_updated"] = datetime.now().isoformat()
        
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self._state, f, ensure_ascii=False, indent=2)
    
    def _default_state(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìƒíƒœ"""
        return {
            "project_id": None,
            "title": None,
            "current_phase": "idle",
            "settings": {
                "style": "cyberpunk",
                "difficulty": "intermediate",
                "duration": 480,
                "aspect_ratio": "16:9",
                "voice": "ko-KR-Neural2-C",
                "subtitle_style": "karaoke"
            },
            "scenes": {
                "total": 0,
                "completed": [],
                "pending": [],
                "current": None
            },
            "files": {
                "script": None,
                "tts_script": None,
                "scenes": None,
                "audio": [],
                "manim": [],
                "subtitles": []
            },
            "last_updated": None
        }
    
    def get(self, key: str, default: Any = None) -> Any:
        """ìƒíƒœ ê°’ ì¡°íšŒ"""
        state = self.load()
        keys = key.split(".")
        value = state
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        return value
    
    def set(self, key: str, value: Any) -> None:
        """ìƒíƒœ ê°’ ì„¤ì •"""
        state = self.load()
        keys = key.split(".")
        target = state
        for k in keys[:-1]:
            if k not in target:
                target[k] = {}
            target = target[k]
        target[keys[-1]] = value
        self._state = state
    
    def update_phase(self, phase: str) -> None:
        """í˜„ì¬ ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        self.set("current_phase", phase)
        self.save()
        print(f"âœ… state.json ì—…ë°ì´íŠ¸ë¨: current_phase = {phase}")
    
    def add_completed_scene(self, scene_id: str) -> None:
        """ì™„ë£Œëœ ì”¬ ì¶”ê°€"""
        state = self.load()
        
        if scene_id in state["scenes"]["pending"]:
            state["scenes"]["pending"].remove(scene_id)
        
        if scene_id not in state["scenes"]["completed"]:
            state["scenes"]["completed"].append(scene_id)
        
        # í˜„ì¬ ì”¬ ì—…ë°ì´íŠ¸
        if state["scenes"]["pending"]:
            state["scenes"]["current"] = state["scenes"]["pending"][0]
        else:
            state["scenes"]["current"] = None
        
        self._state = state
        self.save()
    
    def reset(self) -> None:
        """ìƒíƒœë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self._state = self._default_state()
        self.save()
        print("âœ… state.json ì´ˆê¸°í™”ë¨")

    def add_file(self, category: str, filepath: str) -> None:
        """íŒŒì¼ ê²½ë¡œ ì¶”ê°€"""
        state = self.load()
        
        if category not in state["files"]:
            state["files"][category] = []
        
        if isinstance(state["files"][category], list):
            if filepath not in state["files"][category]:
                state["files"][category].append(filepath)
        else:
            state["files"][category] = filepath
        
        self._state = state
        self.save()
    
    # ========================================================================
    # /clear í›„ ì¬ê°œë¥¼ ìœ„í•œ ìƒì„¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤
    # ========================================================================
    
    def update_script_approved(self, project_id: str) -> None:
        """Step 2 ì™„ë£Œ: ëŒ€ë³¸ ìŠ¹ì¸ í›„"""
        state = self.load()
        
        state['current_phase'] = 'script_approved'
        
        # files ì´ˆê¸°í™”
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['script'] = f"output/{project_id}/1_script/reading_script.json"
        state['files']['tts_script'] = f"output/{project_id}/1_script/tts_script.json"
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: script_approved")
        print(f"   ğŸ“ ëŒ€ë³¸ ê²½ë¡œ: {state['files']['script']}")
    
    def update_scenes_approved(self, project_id: str, scene_ids: List[str]) -> None:
        """Step 3 ì™„ë£Œ: ì”¬ ë¶„í•  ìŠ¹ì¸ í›„"""
        state = self.load()
        
        state['current_phase'] = 'scenes_approved'
        
        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['scenes'] = f"output/{project_id}/2_scenes/scenes.json"
        
        # scenes ì •ë³´ ì—…ë°ì´íŠ¸
        state['scenes'] = {
            'total': len(scene_ids),
            'completed': [],
            'pending': scene_ids,
            'current': scene_ids[0] if scene_ids else None
        }
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: scenes_approved")
        print(f"   ğŸ¬ ì”¬ ë¶„í• : {len(scene_ids)}ê°œ ì”¬")
    
    def update_tts_completed(self, project_id: str, audio_files: List[str]) -> None:
        """Step 4 ì™„ë£Œ: TTS ìƒì„± ì™„ë£Œ í›„"""
        state = self.load()
        
        state['current_phase'] = 'tts_completed'
        
        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['audio'] = audio_files
        
        self._state = state
        self.save()

        print(f"âœ… state.json ì—…ë°ì´íŠ¸: tts_completed")
        print(f"   ğŸ¤ TTS ì™„ë£Œ: {len(audio_files)}ê°œ íŒŒì¼")

    def update_tts_partial(self, project_id: str, audio_files: List[str], resume_from: int) -> None:
        """TTS ë¶€ë¶„ ì™„ë£Œ: í•œë„ ì´ˆê³¼ë¡œ ì¤‘ë‹¨ë¨"""
        state = self.load()

        state['current_phase'] = 'tts_partial'
        state['tts_resume_from'] = resume_from

        # files ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None,
                'tts_script': None,
                'scenes': None,
                'audio': [],
                'manim': [],
                'subtitles': []
            }

        state['files']['audio'] = audio_files

        self._state = state
        self.save()

        print(f"âš ï¸  state.json ì—…ë°ì´íŠ¸: tts_partial (s{resume_from}ë¶€í„° ì¬ê°œ í•„ìš”)")

    def update_manim_scene_completed(self, scene_id: str, manim_file: str) -> None:
        """Step 5 ì§„í–‰: ì”¬ë³„ Manim ì½”ë“œ ì™„ë£Œ í›„"""
        state = self.load()
        
        state['current_phase'] = 'manim_coding'
        
        # scenes ì—…ë°ì´íŠ¸
        if 'scenes' not in state:
            state['scenes'] = {'total': 0, 'completed': [], 'pending': [], 'current': None}
        
        # completedì— ì¶”ê°€
        if scene_id not in state['scenes']['completed']:
            state['scenes']['completed'].append(scene_id)
        
        # pendingì—ì„œ ì œê±°
        if scene_id in state['scenes']['pending']:
            state['scenes']['pending'].remove(scene_id)
        
        # current ì—…ë°ì´íŠ¸ (ë‹¤ìŒ pending ì”¬)
        if state['scenes']['pending']:
            state['scenes']['current'] = state['scenes']['pending'][0]
        else:
            state['scenes']['current'] = None
            state['current_phase'] = 'manim_completed'
        
        # files.manim ì—…ë°ì´íŠ¸
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        if manim_file not in state['files']['manim']:
            state['files']['manim'].append(manim_file)
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: {scene_id} ì½”ë“œ ì™„ë£Œ")
        print(f"   ì™„ë£Œ: {state['scenes']['completed']}")
        print(f"   ë‚¨ìŒ: {state['scenes']['pending']}")
    
    def update_rendering(self) -> None:
        """Step 6: ë Œë”ë§ ì‹œì‘"""
        state = self.load()
        state['current_phase'] = 'rendering'
        self._state = state
        self.save()
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: rendering")
    
    def update_completed(self, final_video_path: str) -> None:
        """ëª¨ë“  ì‘ì—… ì™„ë£Œ"""
        state = self.load()
        
        state['current_phase'] = 'completed'
        
        if 'files' not in state:
            state['files'] = {
                'script': None, 
                'tts_script': None, 
                'scenes': None, 
                'audio': [], 
                'manim': [],
                'subtitles': []
            }
        
        state['files']['final_video'] = final_video_path
        
        self._state = state
        self.save()
        
        print(f"âœ… state.json ì—…ë°ì´íŠ¸: completed")
        print(f"   ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ: {final_video_path}")
    
    def get_resume_point(self) -> tuple:
        """ì¬ê°œ ì§€ì  í™•ì¸ ë° ì•ˆë‚´"""
        state = self.load()
        
        if not state.get("project_id"):
            return ("ì‹œì‘", "ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”. python math_video_pipeline.py init --title \"ì£¼ì œ\"")
        
        phase = state.get('current_phase', 'initialized')
        
        resume_guide = {
            'idle': ('ì‹œì‘', 'ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”.'),
            'initialized': ('ëŒ€ë³¸ ì‘ì„±', 'skills/script-writer.mdë¥¼ ì°¸ì¡°í•˜ì—¬ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.'),
            'script_approved': ('ì”¬ ë¶„í• ', 'skills/scene-director.mdë¥¼ ì°¸ì¡°í•˜ì—¬ ì”¬ì„ ë¶„í• í•˜ì„¸ìš”.'),
            'scenes_approved': ('TTS ìƒì„±', 'python math_video_pipeline.py tts-all ì‹¤í–‰'),
            'tts_completed': ('Manim ì½”ë“œ', f"ì”¬ {state.get('scenes', {}).get('current', 's1')} ì½”ë“œ ì‘ì„±"),
            'manim_coding': ('Manim ì½”ë“œ ê³„ì†', f"ì”¬ {state.get('scenes', {}).get('current', 's1')} ì½”ë“œ ì‘ì„±"),
            'manim_completed': ('ë Œë”ë§', 'python math_video_pipeline.py render-all ì‹¤í–‰'),
            'rendering': ('ë Œë”ë§ ëŒ€ê¸°', 'ë Œë”ë§ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'),
            'completed': ('ì™„ë£Œ', 'í”„ë¡œì íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
        }
        
        next_step, guide = resume_guide.get(phase, ('ì•Œ ìˆ˜ ì—†ìŒ', 'ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.'))
        
        return (next_step, guide)


# ============================================================================
# í”„ë¡œì íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class ProjectManager:
    """í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ë° ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def init_project(
        self,
        title: str,
        duration: int = 480,
        style: str = "cyberpunk",
        difficulty: str = "intermediate",
        aspect_ratio: str = "16:9",
        voice: str = "ko-KR-Neural2-C"
    ) -> str:
        """ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”"""
        
        # í”„ë¡œì íŠ¸ ID ìƒì„±
        project_id = f"P{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        project_dir = OUTPUT_DIR / project_id
        folders = [
            "0_audio",
            "1_script",
            "2_scenes",
            "3_visual_plans",
            "4_manim_code",
            "5_validation",
            "6_image_prompts",
            "7_subtitles",
            "8_renders",
            "9_backgrounds",
            "10_scene_final"
        ]
        
        for folder in folders:
            (project_dir / folder).mkdir(parents=True, exist_ok=True)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state.set("project_id", project_id)
        self.state.set("title", title)
        self.state.set("current_phase", "initialized")
        self.state.set("settings.style", style)
        self.state.set("settings.difficulty", difficulty)
        self.state.set("settings.duration", duration)
        self.state.set("settings.aspect_ratio", aspect_ratio)
        self.state.set("settings.voice", voice)
        self.state.set("scenes.total", 0)
        self.state.set("scenes.completed", [])
        self.state.set("scenes.pending", [])
        self.state.set("scenes.current", None)
        self.state.set("files.script", None)
        self.state.set("files.tts_script", None)
        self.state.set("files.scenes", None)
        self.state.set("files.audio", [])
        self.state.set("files.manim", [])
        self.state.set("files.subtitles", [])
        self.state.save()
        
        print(f"âœ… í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ: {project_id}")
        print(f"   ğŸ“ ì¶œë ¥ í´ë”: {project_dir}")
        print(f"   ğŸ“ ì œëª©: {title}")
        print(f"   â±ï¸  ê¸¸ì´: {duration}ì´ˆ ({duration//60}ë¶„ {duration%60}ì´ˆ)")
        print(f"   ğŸ“ ì¢…íš¡ë¹„: {aspect_ratio}")
        print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {style}")
        print(f"   ğŸ“Š ë‚œì´ë„: {difficulty}")
        print(f"   ğŸ¤ ìŒì„±: {voice}")
        print()
        print("ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        print("   Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±ì„ ìš”ì²­í•˜ì„¸ìš”:")
        print(f'   "skills/script-writer.md ì½ê³  "{title}" ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"')
        
        return project_id
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def show_status(self) -> None:
        """í˜„ì¬ ìƒíƒœ ì¶œë ¥"""
        state = self.state.load()
        
        print("\n" + "="*60)
        print("ğŸ“Š í”„ë¡œì íŠ¸ ìƒíƒœ")
        print("="*60)
        
        if not state["project_id"]:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("\nìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘:")
            print('   python math_video_pipeline.py init --title "ì£¼ì œ"')
            return
        
        print(f"ğŸ†” í”„ë¡œì íŠ¸ ID: {state['project_id']}")
        print(f"ğŸ“ ì œëª©: {state['title']}")
        print(f"ğŸ“ í˜„ì¬ ë‹¨ê³„: {state['current_phase']}")
        print()
        
        settings = state.get("settings", {})
        print("âš™ï¸  ì„¤ì •:")
        print(f"   ìŠ¤íƒ€ì¼: {settings.get('style', 'N/A')}")
        print(f"   ë‚œì´ë„: {settings.get('difficulty', 'N/A')}")
        print(f"   ê¸¸ì´: {settings.get('duration', 0)}ì´ˆ")
        print(f"   ì¢…íš¡ë¹„: {settings.get('aspect_ratio', 'N/A')}")
        print(f"   ìŒì„±: {settings.get('voice', 'N/A')}")
        print()
        
        scenes = state.get("scenes", {})
        print("ğŸ¬ ì”¬ ì§„í–‰ ìƒí™©:")
        print(f"   ì´ ì”¬: {scenes.get('total', 0)}ê°œ")
        print(f"   ì™„ë£Œ: {len(scenes.get('completed', []))}ê°œ {scenes.get('completed', [])}")
        print(f"   ëŒ€ê¸°: {len(scenes.get('pending', []))}ê°œ {scenes.get('pending', [])}")
        print(f"   í˜„ì¬: {scenes.get('current', 'N/A')}")
        print()
        
        files = state.get("files", {})
        print("ğŸ“ íŒŒì¼:")
        print(f"   ëŒ€ë³¸: {'âœ… ' + files.get('script') if files.get('script') else 'âŒ ì—†ìŒ'}")
        print(f"   TTSëŒ€ë³¸: {'âœ… ' + files.get('tts_script') if files.get('tts_script') else 'âŒ ì—†ìŒ'}")
        print(f"   ì”¬: {'âœ… ' + files.get('scenes') if files.get('scenes') else 'âŒ ì—†ìŒ'}")
        print(f"   ì˜¤ë””ì˜¤: {len(files.get('audio', []))}ê°œ")
        print(f"   Manim: {len(files.get('manim', []))}ê°œ")
        print(f"   ìë§‰: {len(files.get('subtitles', []))}ê°œ")
        print()
        
        if state.get("last_updated"):
            print(f"ğŸ• ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {state['last_updated']}")
        
        print("="*60)
        
        # ì¬ê°œ ì§€ì  ì•ˆë‚´
        next_step, guide = self.state.get_resume_point()
        print(f"\nğŸ”„ ì¬ê°œ ì§€ì : {next_step}")
        print(f"   ğŸ“Œ {guide}")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        self._suggest_next_step(state)
    
    def _suggest_next_step(self, state: Dict) -> None:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        phase = state.get("current_phase", "idle")
        
        print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        
        if phase == "idle":
            print('   í”„ë¡œì íŠ¸ ì‹œì‘: python math_video_pipeline.py init --title "ì£¼ì œ"')
        
        elif phase == "initialized":
            print("   Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±:")
            print('   "skills/script-writer.md ì½ê³  ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"')
        
        elif phase == "script_approved":
            print("   Claude Codeì—ì„œ ì”¬ ë¶„í• :")
            print('   "skills/scene-director.md ì½ê³  ì”¬ ë¶„í• í•´ì¤˜"')
        
        elif phase == "scenes_approved":
            print("   TTS ìƒì„±: python math_video_pipeline.py tts-all")
        
        elif phase == "tts_completed":
            current = state.get("scenes", {}).get("current", "s1")
            print(f"   Claude Codeì—ì„œ Manim ì½”ë“œ:")
            print(f'   "skills/manim-coder.md ì½ê³  {current} ì½”ë“œ ìƒì„±í•´ì¤˜"')
        
        elif phase == "manim_coding":
            pending = state.get("scenes", {}).get("pending", [])
            if pending:
                next_scene = pending[0]
                print(f"   ë‹¤ìŒ ì”¬ ì²˜ë¦¬: {next_scene}")
                print(f'   "skills/manim-coder.md ì½ê³  {next_scene} ì½”ë“œ ìƒì„±í•´ì¤˜"')
            else:
                print("   ëª¨ë“  ì”¬ ì™„ë£Œ! ë Œë”ë§ ì¤€ë¹„:")
                print("   python math_video_pipeline.py render-all")
        
        elif phase == "manim_completed":
            print("   ë Œë”ë§ ì‹¤í–‰:")
            print("   python math_video_pipeline.py render-all")
        
        elif phase == "completed":
            print("   ğŸ‰ í”„ë¡œì íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    def list_projects(self) -> List[Dict]:
        """output í´ë” ë‚´ ëª¨ë“  í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ"""
        projects = []

        if not OUTPUT_DIR.exists():
            print("âŒ output í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return projects

        for item in OUTPUT_DIR.iterdir():
            if item.is_dir() and item.name.startswith("P"):
                # í”„ë¡œì íŠ¸ í´ë” ì •ë³´ ìˆ˜ì§‘
                project_info = {
                    "id": item.name,
                    "path": str(item),
                    "folders": {},
                    "total_size": 0
                }

                # ê° í•˜ìœ„ í´ë” ìƒíƒœ í™•ì¸
                for folder in item.iterdir():
                    if folder.is_dir():
                        files = list(folder.glob("*"))
                        file_count = len([f for f in files if f.is_file()])
                        folder_size = sum(f.stat().st_size for f in files if f.is_file())
                        project_info["folders"][folder.name] = {
                            "files": file_count,
                            "size": folder_size
                        }
                        project_info["total_size"] += folder_size

                projects.append(project_info)

        # ë‚ ì§œ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
        projects.sort(key=lambda x: x["id"], reverse=True)

        # ì¶œë ¥
        print("\n" + "="*70)
        print("ğŸ“ í”„ë¡œì íŠ¸ ëª©ë¡")
        print("="*70)

        if not projects:
            print("âŒ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return projects

        current_project = self.state.get("project_id")

        for p in projects:
            is_current = "â­" if p["id"] == current_project else "  "
            size_mb = p["total_size"] / (1024 * 1024)
            print(f"{is_current} {p['id']} ({size_mb:.1f} MB)")

            # ì£¼ìš” í´ë” ìƒíƒœ
            folder_status = []
            folder_order = ["1_script", "2_scenes", "0_audio", "4_manim_code", "8_renders", "10_scene_final"]
            for fname in folder_order:
                if fname in p["folders"]:
                    count = p["folders"][fname]["files"]
                    if count > 0:
                        folder_status.append(f"{fname.split('_')[-1]}:{count}")

            if folder_status:
                print(f"      â””â”€ {', '.join(folder_status)}")

        print("="*70)
        print(f"ì´ {len(projects)}ê°œ í”„ë¡œì íŠ¸")

        return projects

    def delete_project(self, project_id: str, force: bool = False) -> bool:
        """í”„ë¡œì íŠ¸ ì‚­ì œ"""
        import shutil

        project_dir = OUTPUT_DIR / project_id

        if not project_dir.exists():
            print(f"âŒ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_id}")
            return False

        # í˜„ì¬ í™œì„± í”„ë¡œì íŠ¸ì¸ì§€ í™•ì¸
        current_project = self.state.get("project_id")
        is_current = project_id == current_project

        # ì‚­ì œ ì „ ì •ë³´ í‘œì‹œ
        total_size = sum(f.stat().st_size for f in project_dir.rglob("*") if f.is_file())
        file_count = len(list(project_dir.rglob("*")))

        print(f"\nğŸ—‘ï¸  ì‚­ì œ ëŒ€ìƒ: {project_id}")
        print(f"   ğŸ“ ê²½ë¡œ: {project_dir}")
        print(f"   ğŸ“Š íŒŒì¼: {file_count}ê°œ")
        print(f"   ğŸ’¾ í¬ê¸°: {total_size / (1024*1024):.1f} MB")
        if is_current:
            print(f"   âš ï¸  í˜„ì¬ í™œì„± í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤!")

        if not force:
            print("\nâš ï¸  ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("   ì‚­ì œë¥¼ í™•ì¸í•˜ë ¤ë©´ --force ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”:")
            print(f"   python math_video_pipeline.py delete {project_id} --force")
            return False

        # ì‚­ì œ ì‹¤í–‰
        try:
            shutil.rmtree(project_dir)
            print(f"\nâœ… í”„ë¡œì íŠ¸ ì‚­ì œ ì™„ë£Œ: {project_id}")

            # í˜„ì¬ í”„ë¡œì íŠ¸ì˜€ë‹¤ë©´ state ì´ˆê¸°í™”
            if is_current:
                self.state.reset()
                print("   state.json ì´ˆê¸°í™”ë¨")

            return True
        except Exception as e:
            print(f"âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    def clean_project(self, project_id: str = None, folders: List[str] = None, force: bool = False) -> bool:
        """í”„ë¡œì íŠ¸ íŠ¹ì • í´ë” ë‚´ìš© ì •ë¦¬ (í´ë” êµ¬ì¡°ëŠ” ìœ ì§€)"""
        import shutil

        # í”„ë¡œì íŠ¸ ID ê²°ì •
        if project_id is None:
            project_id = self.state.get("project_id")

        if not project_id:
            print("âŒ í”„ë¡œì íŠ¸ IDë¥¼ ì§€ì •í•˜ê±°ë‚˜ í™œì„± í”„ë¡œì íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return False

        project_dir = OUTPUT_DIR / project_id

        if not project_dir.exists():
            print(f"âŒ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_id}")
            return False

        # ì •ë¦¬í•  í´ë” ê²°ì •
        all_folders = [
            "0_audio", "1_script", "2_scenes", "3_visual_plans",
            "4_manim_code", "5_validation", "6_image_prompts",
            "7_subtitles", "8_renders", "9_backgrounds", "10_scene_final"
        ]

        if folders is None:
            target_folders = all_folders
        else:
            # ì‚¬ìš©ì ì§€ì • í´ë” ê²€ì¦
            target_folders = []
            for f in folders:
                # ìˆ«ìë§Œ ì…ë ¥í•´ë„ ë§¤ì¹­
                matched = [af for af in all_folders if f in af or af.startswith(f)]
                target_folders.extend(matched)
            target_folders = list(set(target_folders))

        if not target_folders:
            print("âŒ ì •ë¦¬í•  í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ì •ë¦¬ ëŒ€ìƒ ì •ë³´ í‘œì‹œ
        print(f"\nğŸ§¹ ì •ë¦¬ ëŒ€ìƒ: {project_id}")
        total_files = 0
        total_size = 0

        for folder_name in sorted(target_folders):
            folder_path = project_dir / folder_name
            if folder_path.exists():
                files = list(folder_path.glob("*"))
                file_count = len([f for f in files if f.is_file()])
                folder_size = sum(f.stat().st_size for f in files if f.is_file())
                if file_count > 0:
                    print(f"   ğŸ“ {folder_name}: {file_count}ê°œ ({folder_size/(1024*1024):.1f} MB)")
                    total_files += file_count
                    total_size += folder_size

        if total_files == 0:
            print("   âœ… ì •ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return True

        print(f"\n   ğŸ“Š ì´ {total_files}ê°œ íŒŒì¼, {total_size/(1024*1024):.1f} MB")

        if not force:
            print("\nâš ï¸  ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("   ì •ë¦¬ë¥¼ í™•ì¸í•˜ë ¤ë©´ --force ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”")
            return False

        # ì •ë¦¬ ì‹¤í–‰
        cleaned_count = 0
        for folder_name in target_folders:
            folder_path = project_dir / folder_name
            if folder_path.exists():
                for item in folder_path.iterdir():
                    if item.is_file():
                        item.unlink()
                        cleaned_count += 1
                    elif item.is_dir():
                        shutil.rmtree(item)
                        cleaned_count += 1

        print(f"\nâœ… ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ í•­ëª© ì‚­ì œ")
        return True

    def reset_project(self, project_id: str = None, from_phase: str = None, force: bool = False) -> bool:
        """í”„ë¡œì íŠ¸ë¥¼ íŠ¹ì • ë‹¨ê³„ë¡œ ë¦¬ì…‹ (í•´ë‹¹ ë‹¨ê³„ ì´í›„ ì‚°ì¶œë¬¼ ì‚­ì œ)"""

        # í”„ë¡œì íŠ¸ ID ê²°ì •
        if project_id is None:
            project_id = self.state.get("project_id")

        if not project_id:
            print("âŒ í”„ë¡œì íŠ¸ IDë¥¼ ì§€ì •í•˜ê±°ë‚˜ í™œì„± í”„ë¡œì íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return False

        project_dir = OUTPUT_DIR / project_id

        if not project_dir.exists():
            print(f"âŒ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_id}")
            return False

        # ë‹¨ê³„ë³„ ì‚­ì œ ëŒ€ìƒ í´ë” ì •ì˜
        phase_folders = {
            "initialized": ["1_script", "2_scenes", "3_visual_plans", "4_manim_code",
                           "5_validation", "6_image_prompts", "7_subtitles",
                           "8_renders", "9_backgrounds", "10_scene_final", "0_audio"],
            "script_approved": ["2_scenes", "3_visual_plans", "4_manim_code",
                               "5_validation", "6_image_prompts", "7_subtitles",
                               "8_renders", "9_backgrounds", "10_scene_final", "0_audio"],
            "scenes_completed": ["3_visual_plans", "4_manim_code", "5_validation",
                                "6_image_prompts", "7_subtitles", "8_renders",
                                "9_backgrounds", "10_scene_final", "0_audio"],
            "assets_checked": ["3_visual_plans", "4_manim_code", "5_validation",
                              "6_image_prompts", "7_subtitles", "8_renders",
                              "9_backgrounds", "10_scene_final", "0_audio"],
            "tts_completed": ["3_visual_plans", "4_manim_code", "5_validation",
                             "6_image_prompts", "7_subtitles", "8_renders",
                             "9_backgrounds", "10_scene_final"],
            "visual_prompts_completed": ["4_manim_code", "5_validation",
                                        "8_renders", "10_scene_final"],
            "manim_completed": ["5_validation", "8_renders", "10_scene_final"],
            "manim_validated": ["8_renders", "10_scene_final"],
            "images_ready": ["10_scene_final"],
            "rendered": ["10_scene_final"],
        }

        if from_phase is None:
            print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì…‹ ì§€ì :")
            for phase in phase_folders.keys():
                folders = phase_folders[phase]
                print(f"   {phase}: {len(folders)}ê°œ í´ë” ì‚­ì œ")
            print("\nì‚¬ìš©ë²•: python math_video_pipeline.py reset --from <phase> --force")
            return False

        if from_phase not in phase_folders:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ê³„: {from_phase}")
            print(f"   ì‚¬ìš© ê°€ëŠ¥: {', '.join(phase_folders.keys())}")
            return False

        target_folders = phase_folders[from_phase]

        print(f"\nğŸ”„ ë¦¬ì…‹ ëŒ€ìƒ: {project_id}")
        print(f"   ğŸ“ ë¦¬ì…‹ ì§€ì : {from_phase}")
        print(f"   ğŸ“ ì‚­ì œ í´ë”: {', '.join(target_folders)}")

        if not force:
            print("\nâš ï¸  ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print(f"   python math_video_pipeline.py reset --from {from_phase} --force")
            return False

        # ë¦¬ì…‹ ì‹¤í–‰
        return self.clean_project(project_id, target_folders, force=True)


# ============================================================================
# TTS ìƒì„±ê¸° í´ë˜ìŠ¤
# ============================================================================

class TTSGenerator:
    """OpenAI TTS (gpt-4o-mini-tts) - ë¬¸ì¥ë³„ ë¶„í•  ìƒì„±"""

    # OpenAI gpt-4o-mini-tts ì§€ì› ìŒì„± (13ê°œ)
    OPENAI_VOICES = {
        "alloy": "ì¤‘ì„±ì , ê· í˜•ì¡íŒ",
        "ash": "ì°¨ë¶„í•œ ë‚¨ì„± [ê¸°ë³¸ê°’]",
        "ballad": "ë¶€ë“œëŸ¬ìš´ ë‚­ë…",
        "coral": "ë”°ëœ»í•œ ì—¬ì„±",
        "echo": "ë‚¨ì„±ì , ì°¨ë¶„í•¨",
        "fable": "ì˜êµ­ì‹ ì–µì–‘",
        "onyx": "ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬",
        "nova": "ì—¬ì„±ì , ë°ê³  ì¹œê·¼",
        "sage": "ì§€ì ì¸ í†¤",
        "shimmer": "ì—¬ì„±ì , ë¶€ë“œëŸ¬ì›€",
        "verse": "í‘œí˜„ë ¥ í’ë¶€",
        "marin": "ê³ í’ˆì§ˆ ì¶”ì²œ",
        "cedar": "ê³ í’ˆì§ˆ ì¶”ì²œ",
    }

    # í•œêµ­ì–´ TTS ê¸°ë³¸ instructions
    DEFAULT_INSTRUCTIONS = "Speak in a deep, calm, educational Korean tone with clear pronunciation."

    def __init__(self, state_manager: StateManager):
        self.state = state_manager
        self.openai_client = get_openai_client()

    def _split_into_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ì¤„ë°”ê¿ˆ ê¸°ì¤€)

        TTS ë…¹ìŒì„ ìœ„í•´ ê° ì¤„ì„ ê°œë³„ ë¬¸ì¥ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        - \n\n (ë¹ˆ ì¤„): ë¬¸ë‹¨ êµ¬ë¶„
        - \n (ì¤„ë°”ê¿ˆ): ë¬¸ì¥ êµ¬ë¶„
        """
        # ëª¨ë“  ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í•  (ë¹ˆ ì¤„ì´ë“  ë‹¨ì¼ ì¤„ë°”ê¿ˆì´ë“ )
        lines = [line.strip() for line in text.split('\n') if line.strip()]

        return lines

    def _save_wav(self, filename: Path, pcm_data: bytes, channels: int = 1, rate: int = 24000, sample_width: int = 2):
        """PCM ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥"""
        with wave.open(str(filename), "wb") as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(rate)
            wf.writeframes(pcm_data)

    def _get_wav_duration(self, filename: Path) -> float:
        """WAV íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ê³„ì‚°"""
        try:
            with wave.open(str(filename), "rb") as wf:
                frames = wf.getnframes()
                rate = wf.getframerate()
                return frames / float(rate)
        except:
            return 0.0

    def _save_partial_timing(self, audio_dir: Path, scene_id: str, voice_name: str,
                             sentence_results: list, audio_files: list, total_duration: float):
        """ë¶€ë¶„ ì™„ë£Œëœ TTS íƒ€ì´ë° ì €ì¥ (í•œë„ ì´ˆê³¼ ì‹œ ì‚¬ìš©)"""
        timing_file = audio_dir / f"{scene_id}_timing_partial.json"
        timing_data = {
            "scene_id": scene_id,
            "voice": voice_name,
            "total_duration": total_duration,
            "sentence_count": len(sentence_results),
            "sentences": sentence_results,
            "audio_files": audio_files,
            "created_at": datetime.now().isoformat(),
            "status": "partial"  # ë¶€ë¶„ ì™„ë£Œ í‘œì‹œ
        }
        with open(timing_file, 'w', encoding='utf-8') as f:
            json.dump(timing_data, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ“ ë¶€ë¶„ ì €ì¥: {timing_file}")

    def _generate_openai_tts(self, text: str, voice: str, output_file: Path,
                              instructions: str = None, max_retries: int = 3) -> bool:
        """OpenAI gpt-4o-mini-ttsë¡œ ìŒì„± ìƒì„± (MP3 ì¶œë ¥)"""
        import time

        # instructions ê¸°ë³¸ê°’
        if instructions is None:
            instructions = self.DEFAULT_INSTRUCTIONS

        for attempt in range(max_retries):
            try:
                response = self.openai_client.audio.speech.create(
                    model="gpt-4o-mini-tts",  # ìƒˆ ëª¨ë¸ (í•œêµ­ì–´ í’ˆì§ˆ ê°œì„ , ì €ë ´)
                    voice=voice,
                    input=text,
                    instructions=instructions,  # ìŒì„± ìŠ¤íƒ€ì¼ ì§€ì •
                    response_format="mp3"
                )

                # MP3 íŒŒì¼ë¡œ ì €ì¥
                mp3_file = output_file.with_suffix('.mp3')
                response.stream_to_file(str(mp3_file))

                # ì„±ê³µ í›„ ì§§ì€ ëŒ€ê¸° (Rate limit ë°©ì§€)
                time.sleep(0.3)
                return True

            except Exception as e:
                error_str = str(e).lower()
                if "429" in str(e) or "rate" in error_str:
                    wait_time = 5 * (2 ** attempt)  # 5, 10, 20ì´ˆ
                    print(f"      â³ Rate limit - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"      âŒ OpenAI TTS ì‹¤íŒ¨: {e}")
                    if attempt < max_retries - 1:
                        time.sleep(2)

        return False

    def _get_mp3_duration(self, filename: Path) -> float:
        """MP3 íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ê³„ì‚° (mutagen ë˜ëŠ” ffprobe ì‚¬ìš©)"""
        try:
            # mutagen ì‹œë„
            from mutagen.mp3 import MP3
            audio = MP3(str(filename))
            return audio.info.length
        except ImportError:
            pass
        except Exception:
            pass

        try:
            # ffprobe ì‹œë„
            import subprocess
            result = subprocess.run(
                ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                 '-of', 'csv=p=0', str(filename)],
                capture_output=True, text=True
            )
            if result.returncode == 0 and result.stdout.strip():
                return float(result.stdout.strip())
        except Exception:
            pass

        return 0.0

    def _extract_voice_name(self, voice_setting: str) -> str:
        """ì„¤ì •ì—ì„œ OpenAI ìŒì„± ì´ë¦„ ì¶”ì¶œ"""
        voice_setting_lower = voice_setting.lower()
        for voice_name in self.OPENAI_VOICES.keys():
            if voice_name in voice_setting_lower:
                return voice_name
        return "ash"  # ê¸°ë³¸ê°’

    # ========================================================================
    # [DEPRECATED] ê¸°ì¡´ generate() - ë¬¸ì¥ë³„ TTS ë°©ì‹
    # ========================================================================
    # ì´ìœ : ë¬¸ì¥ë³„ë¡œ TTSë¥¼ í˜¸ì¶œí•˜ë©´ ë¬¸ì¥ ì‚¬ì´ê°€ ë¶€ìì—°ìŠ¤ëŸ½ê²Œ ëŠê¸°ê³ ,
    #       ìë§‰ì´ 2ì¤„ë¡œ ë‚˜ì˜¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŒ.
    # ê°œì„ : ì”¬ ì „ì²´ë¥¼ í•œ ë²ˆì— TTS â†’ Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ
    # ========================================================================
    # def generate_old(
    #     self,
    #     scene_id: str,
    #     text: str,
    #     voice: Optional[str] = None
    # ) -> Optional[Dict[str, Any]]:
    #     """OpenAI TTS - ë¬¸ì¥ë³„ ìŒì„± ìƒì„± (DEPRECATED)"""
    #
    #     if not self.openai_client:
    #         print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    #         print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    #         return None
    #
    #     project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
    #     audio_dir = project_dir / "0_audio"
    #     audio_dir.mkdir(parents=True, exist_ok=True)
    #
    #     # ìŒì„± ì„¤ì • (ê¸°ë³¸ê°’: ash)
    #     voice_setting = voice or self.state.get("settings.voice", "ash")
    #     voice_name = self._extract_voice_name(voice_setting)
    #
    #     print(f"\nğŸ¤ [{scene_id}] TTS ìƒì„± ì¤‘... (OpenAI)")
    #     print(f"   ìŒì„±: {voice_name}")
    #
    #     # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    #     sentences = self._split_into_sentences(text)
    #     print(f"   ë¬¸ì¥ ìˆ˜: {len(sentences)}ê°œ")
    #
    #     sentence_results = []
    #     total_duration = 0.0
    #     audio_files = []
    #
    #     for idx, sentence in enumerate(sentences, 1):
    #         sentence_id = f"{scene_id}_{idx}"
    #         audio_file = audio_dir / f"{sentence_id}.mp3"
    #
    #         # ë¬¸ì¥ ë¯¸ë¦¬ë³´ê¸° (ë„ˆë¬´ ê¸¸ë©´ ìë¦„)
    #         preview = sentence[:40] + "..." if len(sentence) > 40 else sentence
    #         print(f"      [{idx}/{len(sentences)}] {preview}")
    #
    #         # OpenAI TTS ìƒì„±
    #         success = self._generate_openai_tts(sentence, voice_name, audio_file)
    #
    #         if success:
    #             duration = self._get_mp3_duration(audio_file)
    #             gap = 0.1  # ë¬¸ì¥ ì‚¬ì´ ì—¬ìœ  ì‹œê°„
    #             sentence_results.append({
    #                 "sentence_id": sentence_id,
    #                 "sentence_index": idx,
    #                 "text": sentence,
    #                 "audio_file": str(audio_file),
    #                 "start": total_duration,
    #                 "end": total_duration + duration + gap,
    #                 "duration": duration + gap
    #             })
    #             audio_files.append(str(audio_file))
    #             total_duration += duration + gap
    #             print(f"         âœ… {duration:.2f}ì´ˆ (+{gap}s gap)")
    #         else:
    #             print(f"         âŒ ì‹¤íŒ¨")
    #
    #     if not sentence_results:
    #         return None
    #
    #     # íƒ€ì´ë° JSON ì €ì¥
    #     timing_file = audio_dir / f"{scene_id}_timing.json"
    #     timing_data = {
    #         "scene_id": scene_id,
    #         "voice": voice_name,
    #         "total_duration": total_duration,
    #         "sentence_count": len(sentence_results),
    #         "sentences": sentence_results,
    #         "audio_files": audio_files,
    #         "created_at": datetime.now().isoformat()
    #     }
    #
    #     with open(timing_file, 'w', encoding='utf-8') as f:
    #         json.dump(timing_data, f, ensure_ascii=False, indent=2)
    #
    #     print(f"   âœ… ì™„ë£Œ: {len(sentence_results)}ê°œ ë¬¸ì¥, ì´ {total_duration:.2f}ì´ˆ")
    #
    #     # stateì— ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€
    #     for af in audio_files:
    #         self.state.add_file("audio", af)
    #
    #     return timing_data
    # ========================================================================

    def _transcribe_with_whisper(self, audio_file: Path, original_text: str) -> Optional[Dict[str, Any]]:
        """Whisper APIë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„í•˜ì—¬ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ

        Args:
            audio_file: ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            original_text: ì›ë³¸ í…ìŠ¤íŠ¸ (íŒíŠ¸ìš©)

        Returns:
            {
                "segments": [...],  # ë¬¸ì¥ë³„ ì‹œê°„ ì •ë³´
                "words": [...],     # ë‹¨ì–´ë³„ ì‹œê°„ ì •ë³´ (ìˆì„ ê²½ìš°)
                "full_text": "...", # ì „ì‚¬ëœ ì „ì²´ í…ìŠ¤íŠ¸
                "duration": 10.5    # ì´ ê¸¸ì´
            }
        """
        if not self.openai_client:
            return None

        try:
            print(f"   ğŸ“Š Whisper íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì¤‘...")

            # Whisper í”„ë¡¬í”„íŠ¸ (ì¸ì‹ ì •í™•ë„ í–¥ìƒìš©)
            prompt = f"""[ì—„ê²© ê·œì¹™]
1. ìŒì„±ì— ë“¤ë¦° ë‚´ìš©ë§Œ ì •í™•íˆ ì „ì‚¬
2. ì¸ì‚¬ë§, ê°ì‚¬, ì¶”ì„ìƒˆ, ê°íƒ„ì‚¬ ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€
3. íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì‹¤ì œ ë°œí™” ì‹œê°„ ì •í™•íˆ ë°˜ì˜

ì´ê²ƒì€ ìˆ˜í•™ êµìœ¡ ì˜ìƒ ë‚˜ë ˆì´ì…˜ì…ë‹ˆë‹¤.
ìˆ˜í•™ ìš©ì–´: ë¯¸ë¶„, ì ë¶„, ë²¡í„°, ë‚´ì , ì œê³±ê·¼, í•¨ìˆ˜, ê·¸ë˜í”„ ë“±

ì˜ˆìƒ ë‚´ìš©: {original_text[:200]}"""

            with open(audio_file, "rb") as f:
                # verbose_jsonìœ¼ë¡œ segmentë³„ timestamp íšë“
                response = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ko",
                    response_format="verbose_json",
                    timestamp_granularities=["segment", "word"],
                    prompt=prompt
                )

            result = {
                "segments": [],
                "words": [],
                "full_text": response.text,
                "duration": response.duration if hasattr(response, 'duration') else 0
            }

            # Segment ì •ë³´ ì¶”ì¶œ (ë¬¸ì¥ ë‹¨ìœ„)
            if hasattr(response, 'segments') and response.segments:
                for seg in response.segments:
                    result["segments"].append({
                        "text": seg.text.strip() if hasattr(seg, 'text') else "",
                        "start": seg.start if hasattr(seg, 'start') else 0,
                        "end": seg.end if hasattr(seg, 'end') else 0,
                        "duration": (seg.end - seg.start) if hasattr(seg, 'end') and hasattr(seg, 'start') else 0
                    })

            # Word ì •ë³´ ì¶”ì¶œ (ë‹¨ì–´ ë‹¨ìœ„) - ìˆìœ¼ë©´
            if hasattr(response, 'words') and response.words:
                for word in response.words:
                    result["words"].append({
                        "text": word.word.strip() if hasattr(word, 'word') else "",
                        "start": word.start if hasattr(word, 'start') else 0,
                        "end": word.end if hasattr(word, 'end') else 0
                    })

            print(f"      âœ… {len(result['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(result['words'])}ê°œ ë‹¨ì–´ ì¶”ì¶œ")

            return result

        except Exception as e:
            print(f"      âŒ Whisper ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def generate(
        self,
        scene_id: str,
        text: str,
        voice: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """OpenAI TTS + Whisper - ì”¬ ì „ì²´ ìŒì„± ìƒì„± í›„ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ

        ê°œì„ ì :
        - ì”¬ ì „ì²´ë¥¼ í•œ ë²ˆì— TTS â†’ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±
        - Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ â†’ ì •í™•í•œ ìë§‰ íƒ€ì´ë°
        - íŒŒì¼ 1ê°œë¡œ ê´€ë¦¬ ìš©ì´
        """

        if not self.openai_client:
            print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return None

        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        audio_dir = project_dir / "0_audio"
        audio_dir.mkdir(parents=True, exist_ok=True)

        # ìŒì„± ì„¤ì • (ê¸°ë³¸ê°’: alloy)
        voice_setting = voice or self.state.get("settings.voice", "alloy")
        voice_name = self._extract_voice_name(voice_setting)

        print(f"\nğŸ¤ [{scene_id}] TTS ìƒì„± ì¤‘... (OpenAI + Whisper)")
        print(f"   ìŒì„±: {voice_name}")

        # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        preview = text[:60] + "..." if len(text) > 60 else text
        print(f"   í…ìŠ¤íŠ¸: {preview}")

        # 1. ì”¬ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ TTS ìƒì„± (íŒŒì¼ 1ê°œ)
        audio_file = audio_dir / f"{scene_id}.mp3"
        print(f"   ğŸ”Š TTS ìƒì„± ì¤‘...")

        success = self._generate_openai_tts(text, voice_name, audio_file)

        if not success:
            print(f"   âŒ TTS ìƒì„± ì‹¤íŒ¨")
            return None

        # ì „ì²´ duration í™•ì¸
        total_duration = self._get_mp3_duration(audio_file)
        print(f"   âœ… TTS ì™„ë£Œ: {total_duration:.2f}ì´ˆ")

        # 2. Whisperë¡œ ë¬¸ì¥ë³„ timestamp ì¶”ì¶œ
        whisper_result = self._transcribe_with_whisper(audio_file, text)

        if not whisper_result or not whisper_result.get("segments"):
            # Whisper ì‹¤íŒ¨ ì‹œ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ segmentë¡œ ì²˜ë¦¬
            print(f"   âš ï¸ Whisper ë¶„ì„ ì‹¤íŒ¨, ì „ì²´ë¥¼ ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬")
            whisper_result = {
                "segments": [{
                    "text": text,
                    "start": 0,
                    "end": total_duration,
                    "duration": total_duration
                }],
                "words": [],
                "full_text": text,
                "duration": total_duration
            }

        # 3. timing.json í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê¸°ì¡´ í˜•ì‹ í˜¸í™˜)
        sentence_results = []
        for idx, seg in enumerate(whisper_result["segments"], 1):
            sentence_results.append({
                "sentence_id": f"{scene_id}_{idx}",
                "sentence_index": idx,
                "text": seg["text"],
                "start": seg["start"],
                "end": seg["end"],
                "duration": seg["duration"]
            })

        # íƒ€ì´ë° JSON ì €ì¥
        timing_file = audio_dir / f"{scene_id}_timing.json"
        timing_data = {
            "scene_id": scene_id,
            "voice": voice_name,
            "total_duration": total_duration,
            "sentence_count": len(sentence_results),
            "sentences": sentence_results,
            "audio_files": [str(audio_file)],  # ì´ì œ íŒŒì¼ 1ê°œ
            "words": whisper_result.get("words", []),  # ë‹¨ì–´ë³„ íƒ€ì´ë° (ë³´ë„ˆìŠ¤)
            "whisper_text": whisper_result.get("full_text", ""),  # Whisper ì „ì‚¬ ê²°ê³¼
            "created_at": datetime.now().isoformat(),
            "method": "tts_whisper"  # ìƒˆ ë°©ì‹ í‘œì‹œ
        }

        with open(timing_file, 'w', encoding='utf-8') as f:
            json.dump(timing_data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… ì™„ë£Œ: {len(sentence_results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì´ {total_duration:.2f}ì´ˆ")

        # ì „ì‚¬ ì •í™•ë„ í‘œì‹œ
        if whisper_result.get("full_text"):
            # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ì²´í¬
            original_clean = text.replace(" ", "").replace(",", "").replace(".", "")
            whisper_clean = whisper_result["full_text"].replace(" ", "").replace(",", "").replace(".", "")
            if original_clean and whisper_clean:
                # ê³µí†µ ê¸€ì ìˆ˜ ê¸°ë°˜ ìœ ì‚¬ë„
                common = sum(1 for c in whisper_clean if c in original_clean)
                similarity = (common / max(len(original_clean), len(whisper_clean))) * 100
                print(f"   ğŸ“ ì „ì‚¬ ìœ ì‚¬ë„: {similarity:.1f}%")

        # stateì— ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€
        self.state.add_file("audio", str(audio_file))

        return timing_data
    
    def _get_narration_tts(self, project_dir: Path, scene_id: str, scene_data: dict) -> str:
        """narration_tts í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´ (ìš°ì„ ìˆœìœ„: narration#.json > scenes.json)

        Args:
            project_dir: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
            scene_id: ì”¬ ID (ì˜ˆ: s1)
            scene_data: scenes.jsonì—ì„œ ì½ì€ ì”¬ ë°ì´í„° (fallbackìš©)

        Returns:
            narration_tts í…ìŠ¤íŠ¸
        """
        # 1. narration#.json ìš°ì„  í™•ì¸
        narration_file = project_dir / "2_narration" / f"{scene_id}_narration.json"
        if narration_file.exists():
            try:
                with open(narration_file, 'r', encoding='utf-8') as f:
                    narration_data = json.load(f)
                    narration_tts = narration_data.get("narration_tts", "")
                    if narration_tts:
                        return narration_tts
            except Exception:
                pass

        # 2. Fallback: scenes.jsonì˜ narration_tts ë˜ëŠ” narration_display
        return scene_data.get("narration_tts") or scene_data.get("narration_display", "")

    def generate_all_from_scenes(self, start_from: int = 1) -> List[Dict[str, Any]]:
        """scenes.jsonì˜ ëª¨ë“  ì”¬ì— ëŒ€í•´ TTS ìƒì„± (ë¬¸ì¥ë³„)

        Args:
            start_from: ì‹œì‘í•  ì”¬ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘, ì˜ˆ: 14ë©´ s14ë¶€í„° ì‹œì‘)

        í…ìŠ¤íŠ¸ ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„:
            1. 2_narration/{scene_id}_narration.jsonì˜ narration_tts
            2. 2_scenes/scenes.jsonì˜ narration_tts (fallback)
            3. 2_scenes/scenes.jsonì˜ narration_display (fallback)
        """
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        audio_dir = project_dir / "0_audio"

        if not scenes_file.exists():
            print(f"âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
            return []

        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # scenes.jsonì´ ë°°ì—´ì´ë©´ ì§ì ‘ ì‚¬ìš©, ê°ì²´ë©´ scenes í‚¤ ì‚¬ìš©
        if isinstance(data, list):
            scenes = data
        else:
            scenes = data if isinstance(data, list) else data.get("scenes", [])
        if not scenes:
            print("âŒ ì”¬ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # narration íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        narration_dir = project_dir / "2_narration"
        use_narration_files = narration_dir.exists() and list(narration_dir.glob("*_narration.json"))

        print(f"\nğŸ¬ ì´ {len(scenes)}ê°œ ì”¬ TTS ìƒì„± ì‹œì‘ (OpenAI TTS)")
        if use_narration_files:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_narration/")
        else:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_scenes/scenes.json (fallback)")
        if start_from > 1:
            print(f"   s{start_from}ë¶€í„° ì‹œì‘ (s1-s{start_from-1} ê±´ë„ˆëœ€)")
        print("="*60)

        results = []
        all_audio_files = []
        total_sentences = 0
        total_duration = 0.0
        skipped = 0

        for i, scene in enumerate(scenes, 1):
            scene_id = scene.get("scene_id", f"s{i}")

            # start_from ì´ì „ì˜ ì”¬ì€ ê±´ë„ˆë›°ê¸°
            scene_num = int(scene_id[1:]) if scene_id.startswith('s') and scene_id[1:].isdigit() else i
            if scene_num < start_from:
                # ê¸°ì¡´ íƒ€ì´ë° íŒŒì¼ì´ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
                timing_file = audio_dir / f"{scene_id}_timing.json"
                if timing_file.exists():
                    with open(timing_file, 'r', encoding='utf-8') as f:
                        existing = json.load(f)
                        results.append(existing)
                        all_audio_files.extend(existing.get("audio_files", []))
                        total_sentences += existing.get("sentence_count", 0)
                        total_duration += existing.get("total_duration", 0.0)
                skipped += 1
                continue

            # narration_tts í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (narration#.json ìš°ì„ )
            text = self._get_narration_tts(project_dir, scene_id, scene)

            if not text:
                print(f"\nâš ï¸  [{scene_id}] ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            print(f"\n[{i}/{len(scenes)}] {scene_id}")

            try:
                result = self.generate(scene_id, text)
            except QuotaExceededException:
                # í•œë„ ì´ˆê³¼ ì‹œ í˜„ì¬ê¹Œì§€ ì§„í–‰ ìƒí™© ì €ì¥ í›„ ì¤‘ë‹¨
                print("\n" + "="*60)
                print(f"âš ï¸  TTS ìƒì„± ì¤‘ë‹¨: {len(results)}/{len(scenes)}ê°œ ì”¬ ì™„ë£Œ")
                print(f"   ì´ ë¬¸ì¥: {total_sentences}ê°œ")
                print(f"   ì´ ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")
                print(f"\n   ğŸ“Œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì´ì–´ì„œ ì§„í–‰í•˜ì„¸ìš”:")
                print(f"   python math_video_pipeline.py tts-all --start-from {scene_num}")
                print("="*60)

                # ë¶€ë¶„ ì™„ë£Œ ìƒíƒœ ì €ì¥
                if results:
                    self.state.update_tts_partial(project_id, all_audio_files, scene_num)

                return results  # í˜„ì¬ê¹Œì§€ ê²°ê³¼ ë°˜í™˜

            if result:
                results.append(result)
                # ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ì§‘
                all_audio_files.extend(result.get("audio_files", []))
                total_sentences += result.get("sentence_count", 0)
                total_duration += result.get("total_duration", 0.0)

        print("\n" + "="*60)
        print(f"âœ… TTS ìƒì„± ì™„ë£Œ: {len(results)}/{len(scenes)}ê°œ ì”¬")
        print(f"   ì´ ë¬¸ì¥: {total_sentences}ê°œ")
        print(f"   ì´ ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")

        if results:
            self.state.update_tts_completed(project_id, all_audio_files)

        return results

    def generate_for_scene(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ì”¬ì˜ TTS ì¬ìƒì„± (narration#.json ìš°ì„ , scenes.json fallback)"""
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_dir = project_dir / "2_scenes"

        # ê°œë³„ ì”¬ íŒŒì¼ ë¨¼ì € í™•ì¸
        scene_file = scenes_dir / f"{scene_id}.json"
        if scene_file.exists():
            with open(scene_file, 'r', encoding='utf-8') as f:
                scene_data = json.load(f)
        else:
            # scenes.jsonì—ì„œ ì°¾ê¸°
            scenes_file = scenes_dir / "scenes.json"
            if not scenes_file.exists():
                print(f"âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
                return None

            with open(scenes_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            scenes = data if isinstance(data, list) else data.get("scenes", [])
            scene_data = None
            for scene in scenes:
                if scene.get("scene_id") == scene_id:
                    scene_data = scene
                    break

            if not scene_data:
                print(f"âŒ ì”¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_id}")
                return None

        # narration_tts í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (narration#.json ìš°ì„ )
        text = self._get_narration_tts(project_dir, scene_id, scene_data)
        if not text:
            print(f"âŒ {scene_id}: ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print(f"\nğŸ¤ {scene_id} TTS ì¬ìƒì„± ì‹œì‘...")
        result = self.generate(scene_id, text)

        if result:
            print(f"âœ… {scene_id} TTS ìƒì„± ì™„ë£Œ: {result.get('total_duration', 0):.1f}ì´ˆ")

        return result

    def verify_sync(self, scene_id: Optional[str] = None) -> dict:
        """ëŒ€ë³¸(scenes.json)ê³¼ TTS ë…¹ìŒ(timing.json) ë™ê¸°í™” ê²€ì¦

        Args:
            scene_id: íŠ¹ì • ì”¬ë§Œ ê²€ì¦ (Noneì´ë©´ ì „ì²´ ê²€ì¦)

        Returns:
            {"ok": [...], "mismatch": [...], "missing_scene": [...], "missing_timing": [...]}
        """
        project_id = self.state.get("project_id", "unknown")
        project_dir = OUTPUT_DIR / project_id
        scenes_dir = project_dir / "2_scenes"
        audio_dir = project_dir / "0_audio"

        result = {"ok": [], "mismatch": [], "missing_scene": [], "missing_timing": []}

        def normalize(text: str) -> str:
            """ë¹„êµë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ê·œí™” (êµ¬ë‘ì /ê³µë°± ì œê±°)"""
            return text.replace(',', '').replace('.', '').replace('...', '').replace(' ', '').replace('?', '').replace('!', '')[:40]

        def check_scene(sid: str):
            scene_file = scenes_dir / f"{sid}.json"
            timing_file = audio_dir / f"{sid}_timing.json"

            if not scene_file.exists():
                result["missing_scene"].append(sid)
                return
            if not timing_file.exists():
                result["missing_timing"].append(sid)
                return

            with open(scene_file, 'r', encoding='utf-8') as f:
                scene_data = json.load(f)
            with open(timing_file, 'r', encoding='utf-8') as f:
                timing_data = json.load(f)

            scene_tts = scene_data.get('narration_tts', '').strip()
            whisper_text = timing_data.get('whisper_text', '').strip()

            if normalize(scene_tts) == normalize(whisper_text):
                result["ok"].append(sid)
            else:
                result["mismatch"].append({
                    "scene_id": sid,
                    "script": scene_tts[:60] + "..." if len(scene_tts) > 60 else scene_tts,
                    "recorded": whisper_text[:60] + "..." if len(whisper_text) > 60 else whisper_text
                })

        if scene_id:
            # ë‹¨ì¼ ì”¬ ê²€ì¦
            check_scene(scene_id)
        else:
            # ì „ì²´ ê²€ì¦ - scenes í´ë”ì˜ ëª¨ë“  s*.json
            import re
            scene_files = sorted(scenes_dir.glob("s*.json"),
                                key=lambda p: (int(re.match(r's(\d+)', p.stem).group(1)) if re.match(r's(\d+)', p.stem) else 0, p.stem))
            for sf in scene_files:
                sid = sf.stem
                if re.match(r's\d+[a-z]?$', sid):  # s1, s2, s32a ë“±
                    check_scene(sid)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“‹ ëŒ€ë³¸-TTS ë™ê¸°í™” ê²€ì¦ ê²°ê³¼")
        print("="*60)

        if result["ok"]:
            print(f"\nâœ… ì¼ì¹˜: {len(result['ok'])}ê°œ")
            if len(result["ok"]) <= 10:
                print(f"   {', '.join(result['ok'])}")

        if result["mismatch"]:
            print(f"\nâŒ ë¶ˆì¼ì¹˜: {len(result['mismatch'])}ê°œ")
            for m in result["mismatch"][:5]:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                print(f"\n   [{m['scene_id']}]")
                print(f"   ëŒ€ë³¸: {m['script']}")
                print(f"   ë…¹ìŒ: {m['recorded']}")
            if len(result["mismatch"]) > 5:
                mismatch_ids = [m["scene_id"] for m in result["mismatch"][5:]]
                print(f"\n   ... ì™¸ {len(mismatch_ids)}ê°œ: {', '.join(mismatch_ids)}")

            # TTS ì¬ìƒì„± ì•ˆë‚´
            first_mismatch = result["mismatch"][0]["scene_id"]
            scene_num = int(first_mismatch[1:]) if first_mismatch[1:].isdigit() else 1
            print(f"\n   ğŸ’¡ í•´ê²°: python math_video_pipeline.py tts-all --start-from {scene_num}")

        if result["missing_scene"]:
            print(f"\nâš ï¸ ì”¬ íŒŒì¼ ì—†ìŒ: {', '.join(result['missing_scene'])}")

        if result["missing_timing"]:
            print(f"\nâš ï¸ íƒ€ì´ë° íŒŒì¼ ì—†ìŒ: {', '.join(result['missing_timing'])}")

        if not result["mismatch"] and not result["missing_scene"] and not result["missing_timing"]:
            print("\nğŸ‰ ëª¨ë“  ì”¬ì´ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")

        print("\n" + "="*60)

        return result

    def export_texts(self) -> Optional[Path]:
        """ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ JSON ë‚´ë³´ë‚´ê¸°

        narration#.json (ìš°ì„ ) ë˜ëŠ” scenes.jsonì—ì„œ ëª¨ë“  ì”¬ì˜ narration_ttsë¥¼
        ë¬¸ì¥ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ 0_audio/tts_texts.jsonìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

        Returns:
            ìƒì„±ëœ JSON íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        project_dir = OUTPUT_DIR / project_id
        scenes_file = project_dir / "2_scenes" / "scenes.json"

        if not scenes_file.exists():
            print(f"âŒ scenes.jsonì´ ì—†ìŠµë‹ˆë‹¤: {scenes_file}")
            return None

        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes_data = json.load(f)

        # scenes.jsonì€ ë°°ì—´ í˜•íƒœì¼ ìˆ˜ë„, {"scenes": [...]} í˜•íƒœì¼ ìˆ˜ë„ ìˆìŒ
        if isinstance(scenes_data, list):
            scenes = scenes_data
        else:
            scenes = scenes_data.get("scenes", [])

        if not scenes:
            print("âŒ scenes.jsonì— ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì˜¤ë””ì˜¤ í´ë” ìƒì„±
        audio_dir = project_dir / "0_audio"
        audio_dir.mkdir(parents=True, exist_ok=True)

        # narration íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        narration_dir = project_dir / "2_narration"
        use_narration_files = narration_dir.exists() and list(narration_dir.glob("*_narration.json"))

        # ë¬¸ì¥ë³„ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        tts_texts = {}
        total_sentences = 0

        print(f"ğŸ™ï¸ ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°")
        if use_narration_files:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_narration/")
        else:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_scenes/scenes.json (fallback)")
        print("=" * 60)

        for scene in scenes:
            scene_id = scene.get("scene_id", "")

            # narration_tts ê°€ì ¸ì˜¤ê¸° (narration#.json ìš°ì„ )
            narration_tts = self._get_narration_tts(project_dir, scene_id, scene)

            if not narration_tts:
                continue

            # ë¬¸ì¥ ë¶„í• 
            sentences = self._split_into_sentences(narration_tts)

            for idx, sentence in enumerate(sentences, 1):
                key = f"{scene_id}_{idx}"
                tts_texts[key] = sentence
                total_sentences += 1

            print(f"   {scene_id}: {len(sentences)}ê°œ ë¬¸ì¥")

        # JSON ì €ì¥
        output_file = audio_dir / "tts_texts.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(tts_texts, f, ensure_ascii=False, indent=2)

        print("=" * 60)
        print(f"âœ… í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!")
        print(f"   ğŸ“ íŒŒì¼: {output_file}")
        print(f"   ğŸ“Š ì´ {len(scenes)}ê°œ ì”¬, {total_sentences}ê°œ ë¬¸ì¥")
        print()
        print("ğŸ“‹ ë…¹ìŒ ì•ˆë‚´:")
        print("   1. ê° ë¬¸ì¥ë³„ë¡œ ê°œë³„ íŒŒì¼ ë…¹ìŒ")
        print("   2. íŒŒì¼ëª…: s1_1.mp3, s1_2.mp3, s2_1.wav ...")
        print(f"   3. ì €ì¥ ìœ„ì¹˜: {audio_dir}")
        print()
        print('ë…¹ìŒ ì™„ë£Œ í›„ "python math_video_pipeline.py audio-check" ì‹¤í–‰')

        return output_file

    def check_audio_files(self) -> Dict[str, List[str]]:
        """ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ëˆ„ë½ í™•ì¸

        tts_texts.jsonê³¼ ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¹„êµí•˜ì—¬
        ëˆ„ë½ëœ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            {"available": [...], "missing": [...]}
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"available": [], "missing": []}

        project_dir = OUTPUT_DIR / project_id
        audio_dir = project_dir / "0_audio"
        texts_file = audio_dir / "tts_texts.json"

        if not texts_file.exists():
            print(f"âŒ tts_texts.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ë¨¼ì € 'python math_video_pipeline.py tts-export' ì‹¤í–‰í•˜ì„¸ìš”.")
            return {"available": [], "missing": []}

        with open(texts_file, 'r', encoding='utf-8') as f:
            tts_texts = json.load(f)

        # íŒŒì¼ í™•ì¸
        available = []
        missing = []

        print(f"ğŸ” ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ í™•ì¸")
        print("=" * 60)

        for key in tts_texts.keys():
            # mp3 ë˜ëŠ” wav í™•ì¸
            mp3_file = audio_dir / f"{key}.mp3"
            wav_file = audio_dir / f"{key}.wav"

            if mp3_file.exists():
                available.append(f"{key}.mp3")
            elif wav_file.exists():
                available.append(f"{key}.wav")
            else:
                missing.append(key)

        total = len(tts_texts)

        if missing:
            print(f"âš ï¸  ëˆ„ë½ëœ íŒŒì¼: {len(missing)}/{total}ê°œ")
            print()
            for key in missing[:20]:  # ìµœëŒ€ 20ê°œë§Œ í‘œì‹œ
                print(f"   âŒ {key}.mp3 (ë˜ëŠ” .wav)")
                print(f"      í…ìŠ¤íŠ¸: {tts_texts[key][:50]}...")
            if len(missing) > 20:
                print(f"   ... ì™¸ {len(missing) - 20}ê°œ")
            print()
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {audio_dir}")
        else:
            print(f"âœ… ëª¨ë“  íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ! ({len(available)}/{total}ê°œ)")
            print()
            print('ë‹¤ìŒ ë‹¨ê³„: "python math_video_pipeline.py audio-process"')

        print("=" * 60)

        return {"available": available, "missing": missing}

    def process_audio_files(self) -> bool:
        """ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ì²˜ë¦¬ (Whisper ë¶„ì„ + timing.json ìƒì„±)

        ê° ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ durationì„ ì¸¡ì •í•˜ê³ 
        ì”¬ë³„ timing.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        project_dir = OUTPUT_DIR / project_id
        audio_dir = project_dir / "0_audio"
        texts_file = audio_dir / "tts_texts.json"

        if not texts_file.exists():
            print(f"âŒ tts_texts.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ë¨¼ì € 'python math_video_pipeline.py tts-export' ì‹¤í–‰í•˜ì„¸ìš”.")
            return False

        # ëˆ„ë½ íŒŒì¼ í™•ì¸
        check_result = self.check_audio_files()
        if check_result["missing"]:
            print(f"\nâŒ ëˆ„ë½ëœ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë…¹ìŒì„ ì™„ë£Œí•˜ì„¸ìš”.")
            return False

        with open(texts_file, 'r', encoding='utf-8') as f:
            tts_texts = json.load(f)

        print()
        print(f"ğŸ§ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)

        # ì”¬ë³„ë¡œ ê·¸ë£¹í™”
        scene_sentences = {}
        for key, text in tts_texts.items():
            # key: s1_1, s1_2, s2_1 ...
            parts = key.rsplit('_', 1)
            scene_id = parts[0]
            sentence_idx = int(parts[1])

            if scene_id not in scene_sentences:
                scene_sentences[scene_id] = []
            scene_sentences[scene_id].append({
                "key": key,
                "index": sentence_idx,
                "text": text
            })

        # ê° ì”¬ë³„ë¡œ ì²˜ë¦¬
        all_audio_files = []

        for scene_id in sorted(scene_sentences.keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 0):
            sentences = sorted(scene_sentences[scene_id], key=lambda x: x["index"])

            print(f"\n[{scene_id}] {len(sentences)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì¤‘...")

            sentence_results = []
            audio_files = []
            current_time = 0.0

            for sent in sentences:
                key = sent["key"]

                # íŒŒì¼ ì°¾ê¸° (mp3 ë˜ëŠ” wav)
                mp3_file = audio_dir / f"{key}.mp3"
                wav_file = audio_dir / f"{key}.wav"

                if mp3_file.exists():
                    audio_file = mp3_file
                    file_ext = "mp3"
                else:
                    audio_file = wav_file
                    file_ext = "wav"

                # duration ì¸¡ì •
                duration = self._get_audio_duration(audio_file)
                gap = 0.1  # ë¬¸ì¥ ì‚¬ì´ ì—¬ìœ  ì‹œê°„

                sentence_results.append({
                    "index": sent["index"],
                    "text": sent["text"],
                    "file": f"{key}.{file_ext}",
                    "start": round(current_time, 3),
                    "end": round(current_time + duration + gap, 3),
                    "duration": round(duration + gap, 3)
                })

                audio_files.append(f"{key}.{file_ext}")
                all_audio_files.append(f"{key}.{file_ext}")
                current_time += duration + gap

                print(f"   {key}: {duration:.2f}ì´ˆ (+{gap}s gap)")

            # timing.json ì €ì¥
            timing_file = audio_dir / f"{scene_id}_timing.json"
            timing_data = {
                "scene_id": scene_id,
                "voice": "external_recording",
                "total_duration": round(current_time, 3),
                "sentence_count": len(sentence_results),
                "sentences": sentence_results,
                "audio_files": audio_files,
                "created_at": datetime.now().isoformat()
            }

            with open(timing_file, 'w', encoding='utf-8') as f:
                json.dump(timing_data, f, ensure_ascii=False, indent=2)

            print(f"   âœ… {timing_file.name} ì €ì¥ (ì´ {current_time:.2f}ì´ˆ)")

        # state ì—…ë°ì´íŠ¸
        self.state.update_tts_completed(project_id, all_audio_files)

        print()
        print("=" * 60)
        print(f"âœ… ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   ğŸ“Š {len(scene_sentences)}ê°œ ì”¬, {len(all_audio_files)}ê°œ íŒŒì¼")
        print(f"   ğŸ“ timing.json ìƒì„± ì™„ë£Œ")
        print()
        print("ë‹¤ìŒ ë‹¨ê³„: Manim ì½”ë“œ ìƒì„±")

        return True

    def _get_audio_duration(self, audio_file: Path) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì¬ìƒ ì‹œê°„ ì¸¡ì • (mp3/wav ì§€ì›)"""
        import subprocess

        try:
            # ffprobe ì‚¬ìš©
            result = subprocess.run(
                [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    str(audio_file)
                ],
                capture_output=True,
                text=True
            )
            return float(result.stdout.strip())
        except:
            pass

        # wav íŒŒì¼ì¸ ê²½ìš° wave ëª¨ë“ˆ ì‚¬ìš©
        if audio_file.suffix.lower() == ".wav":
            return self._get_wav_duration(audio_file)

        # mp3 íŒŒì¼ì¸ ê²½ìš° mutagen ì‹œë„
        try:
            from mutagen.mp3 import MP3
            audio = MP3(str(audio_file))
            return audio.info.length
        except:
            pass

        print(f"      âš ï¸  duration ì¸¡ì • ì‹¤íŒ¨: {audio_file.name}")
        return 0.0

# ============================================================================
# íŒŒì¼ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class FileManager:
    """íŒŒì¼ ì €ì¥ ë° ë¡œë“œ"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def save_script(self, script: Dict[str, Any]) -> Optional[Path]:
        """ëŒ€ë³¸ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        project_id = self.state.get("project_id")
        script_dir = project_dir / "1_script"
        script_dir.mkdir(parents=True, exist_ok=True)
        
        # JSON ì €ì¥
        json_file = script_dir / "reading_script.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(script, f, ensure_ascii=False, indent=2)
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        md_file = script_dir / "reading_script.md"
        md_content = self._script_to_markdown(script)
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        self.state.update_script_approved(project_id)
        
        print(f"âœ… ëŒ€ë³¸ ì €ì¥ ì™„ë£Œ")
        print(f"   JSON: {json_file}")
        print(f"   Markdown: {md_file}")
        
        return json_file
    
    def _script_to_markdown(self, script: Dict[str, Any]) -> str:
        """ëŒ€ë³¸ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        lines = [
            f"# {script.get('title', 'ì œëª© ì—†ìŒ')}",
            "",
            "## Hook",
            script.get('hook', ''),
            "",
            "## ë¶„ì„",
            script.get('analysis', ''),
            "",
            "## í•µì‹¬ ìˆ˜í•™",
            script.get('core_math', ''),
            "",
            "## ì ìš©",
            script.get('application', ''),
            "",
            "## ì•„ì›ƒíŠ¸ë¡œ",
            script.get('outro', ''),
            "",
            "---",
            "",
            "## ë©”íƒ€ ì •ë³´",
        ]
        
        meta = script.get('meta', {})
        for key, value in meta.items():
            lines.append(f"- {key}: {value}")
        
        return "\n".join(lines)
    
    def save_scenes(self, scenes: List[Dict[str, Any]]) -> Optional[Path]:
        """ì”¬ ë¶„í•  ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        project_id = self.state.get("project_id")
        scenes_dir = project_dir / "2_scenes"
        scenes_dir.mkdir(parents=True, exist_ok=True)
        
        scenes_file = scenes_dir / "scenes.json"
        
        data = {
            "project_id": project_id,
            "total_scenes": len(scenes),
            "total_duration": sum(s.get("duration", 0) for s in scenes),
            "scenes": scenes,
            "created_at": datetime.now().isoformat()
        }
        
        with open(scenes_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        self.state.update_scenes_approved(project_id, scene_ids)
        
        print(f"âœ… ì”¬ ë¶„í•  ì €ì¥ ì™„ë£Œ")
        print(f"   íŒŒì¼: {scenes_file}")
        print(f"   ì´ ì”¬: {len(scenes)}ê°œ")
        print(f"   ì´ ì‹œê°„: {data['total_duration']}ì´ˆ")
        
        return scenes_file
    
    def save_manim_code(self, scene_id: str, code: str) -> Optional[Path]:
        """Manim ì½”ë“œ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        code_dir = project_dir / "4_manim_code"
        code_dir.mkdir(parents=True, exist_ok=True)
        
        code_file = code_dir / f"{scene_id}_manim.py"
        
        with open(code_file, 'w', encoding='utf-8') as f:
            f.write(code)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        self.state.update_manim_scene_completed(scene_id, str(code_file))
        
        print(f"âœ… Manim ì½”ë“œ ì €ì¥: {code_file}")
        
        return code_file
    
    def save_subtitles(self, scene_id: str, subtitles: Dict[str, Any]) -> Optional[Path]:
        """ìë§‰ ë°ì´í„° ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        subtitles_dir = project_dir / "7_subtitles"
        subtitles_dir.mkdir(parents=True, exist_ok=True)
        
        subtitles_file = subtitles_dir / f"{scene_id}_subtitles.json"
        
        with open(subtitles_file, 'w', encoding='utf-8') as f:
            json.dump(subtitles, f, ensure_ascii=False, indent=2)
        
        self.state.add_file("subtitles", str(subtitles_file))
        
        print(f"âœ… ìë§‰ ì €ì¥: {subtitles_file}")
        
        return subtitles_file
    
    def save_image_prompt(self, scene_id: str, prompt: str) -> Optional[Path]:
        """ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì €ì¥"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        prompts_dir = project_dir / "6_image_prompts"
        prompts_dir.mkdir(parents=True, exist_ok=True)
        
        prompt_file = prompts_dir / f"{scene_id}_background.txt"
        
        with open(prompt_file, 'w', encoding='utf-8') as f:
            f.write(prompt)
        
        print(f"âœ… ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompt_file}")
        
        return prompt_file
    
    def load_scenes(self) -> Optional[List[Dict[str, Any]]]:
        """ì”¬ ë°ì´í„° ë¡œë“œ"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        
        if not scenes_file.exists():
            return None
        
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return data.get("scenes", [])
    
    def load_timing(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """íƒ€ì´ë° ë°ì´í„° ë¡œë“œ"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return None
        
        timing_file = project_dir / "0_audio" / f"{scene_id}_timing.json"
        
        if not timing_file.exists():
            return None
        
        with open(timing_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def list_files(self) -> Dict[str, List[str]]:
        """í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡"""
        project_dir = self.get_project_dir()
        if not project_dir:
            return {}
        
        files = {}
        
        for folder in project_dir.iterdir():
            if folder.is_dir():
                files[folder.name] = [f.name for f in folder.iterdir() if f.is_file()]
        
        return files


# ============================================================================
# Supabase í´ë¼ì´ì–¸íŠ¸
# ============================================================================

def get_supabase_client() -> Optional['SupabaseClient']:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Service Role Key ì‚¬ìš©)"""
    if not SUPABASE_AVAILABLE:
        return None

    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_KEY")

    if not url or not key:
        # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("SUPABASE_URL="):
                        url = line.split("=", 1)[1].strip().strip('"\'')
                    elif line.startswith("SUPABASE_SERVICE_KEY="):
                        key = line.split("=", 1)[1].strip().strip('"\'')

    if not url or not key:
        print("âŒ SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    return create_client(url, key)


# ============================================================================
# ì—ì…‹ ê´€ë¦¬ í´ë˜ìŠ¤ (Supabase ì—°ë™)
# ============================================================================

class AssetManager:
    """ì—ì…‹ ê´€ë¦¬ (Supabase Storage + DB ì—°ë™)"""

    BUCKET_NAME = "math-video-assets"
    ASSETS_DIR = Path("assets")

    def __init__(self, state_manager: StateManager):
        self.state = state_manager
        self.supabase = get_supabase_client()

    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None

    def check_assets(self) -> dict:
        """
        ì—ì…‹ ì²´í¬: Supabase ì¡°íšŒ + ë‹¤ìš´ë¡œë“œ + ëˆ„ë½ ëª©ë¡ ìƒì„± + scenes.json í™•ì¥ì ì—…ë°ì´íŠ¸

        Returns:
            {"available": [...], "missing": [...], "downloaded": [...]}
        """
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"available": [], "missing": [], "downloaded": []}

        scenes_file = project_dir / "2_scenes" / "scenes.json"
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì”¬ ë¶„í• ì„ ì§„í–‰í•˜ì„¸ìš”.")
            return {"available": [], "missing": [], "downloaded": []}

        # 1. scenes.jsonì—ì„œ required_elements ìˆ˜ì§‘
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        scenes = data if isinstance(data, list) else data.get("scenes", [])

        required_assets = {}  # file_path -> {scenes, description, tags, original_name}
        for scene in scenes:
            scene_id = scene.get("scene_id", "unknown")

            # 1. required_elementsì—ì„œ ì¶”ì¶œ
            elements = scene.get("required_elements", [])
            for elem in elements:
                if isinstance(elem, str) and "/" in elem:
                    # ì´ë¯¸ ê²½ë¡œ í˜•ì‹
                    base_name = elem.rsplit(".", 1)[0] if "." in elem else elem
                    if base_name not in required_assets:
                        required_assets[base_name] = {"scenes": [], "description": "", "tags": [], "original_name": elem}
                    required_assets[base_name]["scenes"].append(scene_id)
                elif isinstance(elem, dict) and elem.get("type") in ["image", "icon"]:
                    # {"type": "image"/"icon", "asset": "snack_bag" ë˜ëŠ” "snack_bag.png", "role": "..."} í˜•ì‹
                    asset_name = elem.get("asset", elem.get("file", elem.get("path", "")))
                    elem_type = elem.get("type")
                    if asset_name:
                        # í™•ì¥ì ì œê±°
                        base_name = asset_name.rsplit(".", 1)[0] if "." in asset_name else asset_name

                        # ì¹´í…Œê³ ë¦¬ ê²°ì •: typeì´ iconì´ë©´ icons/, ì•„ë‹ˆë©´ ê¸°ì¡´ ë¡œì§
                        if elem_type == "icon":
                            file_path = f"icons/{base_name}"
                        elif "stickman" in base_name or "pigou" in base_name:
                            file_path = f"characters/{base_name}"
                        elif "_icon" in base_name or base_name in ["question_mark", "exclamation", "lightbulb", "checkmark", "arrow_right", "star", "heart", "clock", "calendar", "battery_low", "server_icon", "algorithm_icon", "amazon_logo", "dollar_sign"]:
                            file_path = f"icons/{base_name}"
                        else:
                            file_path = f"objects/{base_name}"

                        if file_path not in required_assets:
                            required_assets[file_path] = {
                                "scenes": [],
                                "description": elem.get("role", elem.get("description", "")),
                                "tags": [],
                                "original_name": asset_name
                            }
                        required_assets[file_path]["scenes"].append(scene_id)

            # 2. required_assetsì—ì„œë„ ì¶”ì¶œ (ë³„ë„ í•„ë“œ)
            assets_list = scene.get("required_assets", [])
            for asset in assets_list:
                if isinstance(asset, dict):
                    category = asset.get("category", "objects")
                    filename = asset.get("filename", "")
                    if filename:
                        # í™•ì¥ì ì œê±°
                        base_name = filename.rsplit(".", 1)[0] if "." in filename else filename
                        file_path = f"{category}/{base_name}"
                        if file_path not in required_assets:
                            required_assets[file_path] = {
                                "scenes": [],
                                "description": asset.get("description", ""),
                                "tags": [category, base_name],
                                "original_name": filename
                            }
                        if scene_id not in required_assets[file_path]["scenes"]:
                            required_assets[file_path]["scenes"].append(scene_id)

        print(f"\nğŸ“‹ í•„ìš”í•œ ì—ì…‹: {len(required_assets)}ê°œ")

        # 2. ì‹¤ì œ íŒŒì¼ í™•ì¥ì ì°¾ê¸° (ë¡œì»¬ì—ì„œ .png ë˜ëŠ” .svg íƒìƒ‰)
        resolved_assets = {}  # base_path -> actual_path (with extension)
        for base_path in required_assets.keys():
            # ë¡œì»¬ì—ì„œ .png, .svg ìˆœì„œë¡œ ì°¾ê¸°
            for ext in [".png", ".svg"]:
                local_path = self.ASSETS_DIR / f"{base_path}{ext}"
                if local_path.exists():
                    resolved_assets[base_path] = f"{base_path}{ext}"
                    break
            # ì—†ìœ¼ë©´ ì¼ë‹¨ .pngë¡œ ê°€ì • (ëˆ„ë½ ëª©ë¡ì— ì¶”ê°€ë¨)
            if base_path not in resolved_assets:
                resolved_assets[base_path] = f"{base_path}.png"

        if not self.supabase:
            print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨. ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸í•©ë‹ˆë‹¤.")
            result = self._check_local_only(required_assets, resolved_assets)
            # scenes.json ì—…ë°ì´íŠ¸
            self._update_scenes_with_extensions(scenes_file, scenes, resolved_assets)
            return result

        # 3. Supabaseì—ì„œ ë³´ìœ  ëª©ë¡ ì¡°íšŒ
        try:
            result = self.supabase.table("assets").select("file_path, folder, file_name, description, tags").execute()
            supabase_assets = {item["file_path"]: item for item in result.data}
            print(f"â˜ï¸  Supabase ë³´ìœ : {len(supabase_assets)}ê°œ")

            # Supabaseì—ì„œë„ í™•ì¥ì ì°¾ê¸°
            for base_path in required_assets.keys():
                if base_path not in resolved_assets or not (self.ASSETS_DIR / resolved_assets[base_path]).exists():
                    for ext in [".png", ".svg"]:
                        full_path = f"{base_path}{ext}"
                        if full_path in supabase_assets:
                            resolved_assets[base_path] = full_path
                            break
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            supabase_assets = {}

        available = []
        missing = []
        downloaded = []

        # 4. ê° ì—ì…‹ í™•ì¸ (í™•ì¥ì í¬í•¨ëœ ê²½ë¡œë¡œ)
        for base_path, info in required_assets.items():
            file_path = resolved_assets.get(base_path, f"{base_path}.png")
            local_path = self.ASSETS_DIR / file_path

            if file_path in supabase_assets:
                # Supabaseì— ìˆìŒ
                if local_path.exists():
                    # ë¡œì»¬ì—ë„ ìˆìŒ
                    available.append(file_path)
                else:
                    # ë¡œì»¬ì— ì—†ìŒ â†’ ë‹¤ìš´ë¡œë“œ
                    if self._download_asset(file_path):
                        downloaded.append(file_path)
                        available.append(file_path)
                    else:
                        missing.append({
                            "file_path": file_path,
                            "base_path": base_path,
                            "folder": file_path.rsplit("/", 1)[0] if "/" in file_path else "",
                            "file_name": file_path.rsplit("/", 1)[-1],
                            "description": supabase_assets[file_path].get("description", ""),
                            "tags": supabase_assets[file_path].get("tags", []),
                            "used_in_scenes": info["scenes"],
                            "spec": {"min_size": "500x500", "format": "PNG or SVG", "background": "transparent"}
                        })
            else:
                # Supabaseì— ì—†ìŒ
                if local_path.exists():
                    # ë¡œì»¬ì—ë§Œ ìˆìŒ (ì—…ë¡œë“œ í•„ìš”)
                    available.append(file_path)
                else:
                    # ì–´ë””ì—ë„ ì—†ìŒ
                    missing.append({
                        "file_path": file_path,
                        "base_path": base_path,
                        "folder": file_path.rsplit("/", 1)[0] if "/" in file_path else "",
                        "file_name": file_path.rsplit("/", 1)[-1],
                        "description": info.get("description", f"ì—ì…‹: {file_path}"),
                        "tags": info.get("tags", [file_path.split("/")[0], base_path.rsplit("/", 1)[-1]]),
                        "used_in_scenes": info["scenes"],
                        "spec": {"min_size": "500x500", "format": "PNG or SVG", "background": "transparent"}
                    })

        # 5. ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥: {len(available)}ê°œ")
        if downloaded:
            print(f"â¬‡ï¸  ë‹¤ìš´ë¡œë“œë¨: {len(downloaded)}ê°œ")
            for fp in downloaded:
                print(f"   - {fp}")

        if missing:
            print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")
            for m in missing:
                print(f"   - {m['file_path']} (ì”¬: {', '.join(m['used_in_scenes'])})")

            # missing_assets.json ì €ì¥
            missing_file = project_dir / "missing_assets.json"
            with open(missing_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "missing": missing,
                    "generated_at": datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“„ ëˆ„ë½ ëª©ë¡ ì €ì¥: {missing_file}")
        else:
            print("\nğŸ‰ ëª¨ë“  ì—ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
            # state.json ì—…ë°ì´íŠ¸
            self.state.set("assets.required", [resolved_assets[k] for k in required_assets.keys()])
            self.state.set("assets.available", available)
            self.state.set("assets.missing", [])
            self.state.update_phase("assets_checked")

        # 6. scenes.json ì—…ë°ì´íŠ¸ (í™•ì¥ì ë°˜ì˜)
        self._update_scenes_with_extensions(scenes_file, scenes, resolved_assets)

        return {"available": available, "missing": missing, "downloaded": downloaded}

    def _update_scenes_with_extensions(self, scenes_file: Path, scenes: list, resolved_assets: dict) -> bool:
        """scenes.jsonì— ì‹¤ì œ íŒŒì¼ í™•ì¥ìë¥¼ ë°˜ì˜"""
        updated = False

        for scene in scenes:
            # 1. required_elements ì—…ë°ì´íŠ¸
            elements = scene.get("required_elements", [])
            for elem in elements:
                if isinstance(elem, dict) and elem.get("type") == "image":
                    asset_name = elem.get("asset", "")
                    if asset_name:
                        base_name = asset_name.rsplit(".", 1)[0] if "." in asset_name else asset_name

                        # ì¹´í…Œê³ ë¦¬ ì¶”ì¸¡
                        if "stickman" in base_name or "pigou" in base_name:
                            base_path = f"characters/{base_name}"
                        elif "_icon" in base_name or base_name in ["question_mark", "exclamation", "lightbulb", "checkmark", "arrow_right", "star", "heart", "clock", "calendar", "battery_low", "server_icon", "algorithm_icon", "amazon_logo", "dollar_sign"]:
                            base_path = f"icons/{base_name}"
                        else:
                            base_path = f"objects/{base_name}"

                        if base_path in resolved_assets:
                            new_name = resolved_assets[base_path].rsplit("/", 1)[-1]  # íŒŒì¼ëª…ë§Œ
                            if asset_name != new_name:
                                elem["asset"] = new_name
                                updated = True

            # 2. required_assets ì—…ë°ì´íŠ¸
            assets_list = scene.get("required_assets", [])
            for asset in assets_list:
                if isinstance(asset, dict):
                    category = asset.get("category", "objects")
                    filename = asset.get("filename", "")
                    if filename:
                        base_name = filename.rsplit(".", 1)[0] if "." in filename else filename
                        base_path = f"{category}/{base_name}"

                        if base_path in resolved_assets:
                            new_filename = resolved_assets[base_path].rsplit("/", 1)[-1]
                            if filename != new_filename:
                                asset["filename"] = new_filename
                                updated = True

        if updated:
            with open(scenes_file, 'w', encoding='utf-8') as f:
                json.dump(scenes, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“ scenes.json ì—…ë°ì´íŠ¸ë¨ (í™•ì¥ì ë°˜ì˜)")

        return updated

    def _check_local_only(self, required_assets: dict, resolved_assets: dict) -> dict:
        """ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸ (Supabase ì—†ì„ ë•Œ)

        Args:
            required_assets: í•„ìš”í•œ ì—ì…‹ (í™•ì¥ì ì—†ëŠ” ê²½ë¡œ -> info)
            resolved_assets: ì‹¤ì œ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì—†ëŠ” ê²½ë¡œ -> í™•ì¥ì ìˆëŠ” ê²½ë¡œ)
        """
        available = []
        missing = []

        for base_path, info in required_assets.items():
            # resolved_assetsì—ì„œ ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸
            if base_path in resolved_assets:
                actual_path = resolved_assets[base_path]
                available.append(actual_path)
            else:
                # ëˆ„ë½ëœ ì—ì…‹
                category = base_path.rsplit("/", 1)[0] if "/" in base_path else ""
                is_icon = category == "icons"
                missing.append({
                    "file_path": base_path,  # í™•ì¥ì ì—†ëŠ” ê²½ë¡œ
                    "folder": category,
                    "file_name": base_path.rsplit("/", 1)[-1],
                    "description": info.get("description", f"ì—ì…‹: {base_path}"),
                    "tags": info.get("tags", []),
                    "used_in_scenes": info["scenes"],
                    "spec": {
                        "min_size": "300x300" if is_icon else "500x500",
                        "format": "SVG (ê¶Œì¥) ë˜ëŠ” PNG" if is_icon else "PNG",
                        "background": "transparent"
                    }
                })

        print(f"âœ… ë¡œì»¬ ì¡´ì¬: {len(available)}ê°œ")
        print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")

        return {"available": available, "missing": missing, "downloaded": []}

    def _download_asset(self, file_path: str) -> bool:
        """Supabase Storageì—ì„œ ì—ì…‹ ë‹¤ìš´ë¡œë“œ"""
        try:
            local_path = self.ASSETS_DIR / file_path
            local_path.parent.mkdir(parents=True, exist_ok=True)

            data = self.supabase.storage.from_(self.BUCKET_NAME).download(file_path)

            with open(local_path, 'wb') as f:
                f.write(data)

            return True
        except Exception as e:
            print(f"   âš ï¸  ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")
            return False

    def sync_assets(self) -> dict:
        """
        ì—ì…‹ ë™ê¸°í™”: ë¡œì»¬ ì‹ ê·œ íŒŒì¼ â†’ Supabase ì—…ë¡œë“œ
        missing_assets.json ì°¸ì¡°í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì ìš©

        Returns:
            {"uploaded": [...], "failed": [...]}
        """
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"uploaded": [], "failed": []}

        if not self.supabase:
            print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨.")
            return {"uploaded": [], "failed": []}

        # missing_assets.json ë¡œë“œ
        missing_file = project_dir / "missing_assets.json"
        missing_metadata = {}
        if missing_file.exists():
            with open(missing_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data.get("missing", []):
                    missing_metadata[item["file_path"]] = item

        # Supabase ë³´ìœ  ëª©ë¡ ì¡°íšŒ
        try:
            result = self.supabase.table("assets").select("file_path").execute()
            supabase_paths = {item["file_path"] for item in result.data}
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            supabase_paths = set()

        uploaded = []
        failed = []

        # ë¡œì»¬ assets í´ë” ìŠ¤ìº” (PNG + SVG)
        asset_files = list(self.ASSETS_DIR.rglob("*.png")) + list(self.ASSETS_DIR.rglob("*.svg"))

        for asset_file in asset_files:
            rel_path = asset_file.relative_to(self.ASSETS_DIR).as_posix()

            if rel_path in supabase_paths:
                continue  # ì´ë¯¸ ì—…ë¡œë“œë¨

            print(f"\nğŸ“¤ ì—…ë¡œë“œ ì¤‘: {rel_path}")

            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            metadata = missing_metadata.get(rel_path, {})
            folder = rel_path.rsplit("/", 1)[0] if "/" in rel_path else ""
            file_name = rel_path.rsplit("/", 1)[-1]

            if self._upload_asset(asset_file, rel_path, folder, file_name, metadata):
                uploaded.append(rel_path)
            else:
                failed.append(rel_path)

        print(f"\n{'='*50}")
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {len(uploaded)}ê°œ")
        if failed:
            print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
            for fp in failed:
                print(f"   - {fp}")

        # ì—…ë¡œë“œ í›„ ë‹¤ì‹œ ì²´í¬
        if uploaded:
            print("\nğŸ”„ ì—ì…‹ ìƒíƒœ ì¬í™•ì¸ ì¤‘...")
            self.check_assets()

        # ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸
        self.update_catalog()

        return {"uploaded": uploaded, "failed": failed}

    def update_catalog(self) -> bool:
        """
        Supabaseì—ì„œ ì „ì²´ ì—ì…‹ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ asset-catalog.md ìë™ ìƒì„±
        """
        if not self.supabase:
            print("âš ï¸  Supabase ì—°ê²° ì—†ìŒ. ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸ ìƒëµ.")
            return False

        try:
            result = self.supabase.table("assets").select("*").execute()
            assets = result.data
        except Exception as e:
            print(f"âš ï¸  Supabase ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return False

        if not assets:
            print("âš ï¸  Supabaseì— ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        categories = {
            "characters": [],
            "objects": [],
            "icons": [],
            "metaphors": []
        }

        for asset in assets:
            folder = asset.get("folder", "objects")
            if folder not in categories:
                folder = "objects"
            categories[folder].append(asset)

        # Markdown ìƒì„±
        catalog_path = Path("skills/asset-catalog.md")

        lines = [
            "# ì—ì…‹ ì¹´íƒˆë¡œê·¸",
            "",
            "> ì´ íŒŒì¼ì€ `asset-sync` ì‹¤í–‰ ì‹œ Supabaseì—ì„œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.",
            "> ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”.",
            "",
            f"**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ì´ ì—ì…‹ ìˆ˜**: {len(assets)}ê°œ",
            "",
            "---",
            "",
        ]

        # ì¹´í…Œê³ ë¦¬ë³„ í…Œì´ë¸” ìƒì„±
        category_info = {
            "characters": ("ìºë¦­í„°", "characters/"),
            "objects": ("ë¬¼ì²´", "objects/"),
            "icons": ("ì•„ì´ì½˜", "icons/"),
            "metaphors": ("ì€ìœ /ë¹„ìœ ", "metaphors/")
        }

        for cat_key, (cat_name, cat_path) in category_info.items():
            cat_assets = categories.get(cat_key, [])
            if not cat_assets:
                continue

            lines.append(f"## {cat_name} ({cat_path})")
            lines.append("")
            lines.append("| íŒŒì¼ëª… | ì„¤ëª… | í¬ê¸° | íƒœê·¸ |")
            lines.append("|--------|------|------|------|")

            for asset in sorted(cat_assets, key=lambda x: x.get("file_name", "")):
                file_name = asset.get("file_name", "unknown")
                description = asset.get("description", "")[:50]  # 50ì ì œí•œ
                width = asset.get("width", "?")
                height = asset.get("height", "?")
                size_str = f"{width}x{height}" if width and height else "?"
                tags = asset.get("tags", [])
                # tagsê°€ ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° flatten
                if tags and isinstance(tags[0], list):
                    tags = [item for sublist in tags for item in sublist]
                # ë¬¸ìì—´ë§Œ í•„í„°ë§
                tags = [t for t in tags if isinstance(t, str)]
                tags_str = ", ".join(tags[:3]) if tags else ""  # íƒœê·¸ 3ê°œê¹Œì§€

                lines.append(f"| `{file_name}` | {description} | {size_str} | {tags_str} |")

            lines.append("")

        # íŒŒì¼ ì‚¬ì–‘ ì„¹ì…˜
        lines.extend([
            "---",
            "",
            "## ì—ì…‹ íŒŒì¼ ì‚¬ì–‘",
            "",
            "| ì¹´í…Œê³ ë¦¬ | ê¶Œì¥ í¬ê¸° | ìŠ¤íƒ€ì¼ |",
            "|----------|-----------|--------|",
            "| characters | 500x700 px | ì¡¸ë¼ë§¨ stick figure |",
            "| objects | 500x500 px | minimalist 2D |",
            "| icons | 300x300 px | minimalist 2D |",
            "| metaphors | 700x500 px | minimalist 2D |",
            "",
            "**ê³µí†µ ì‚¬ì–‘**:",
            "- í¬ë§·: PNG (íˆ¬ëª… ë°°ê²½)",
            "- ìƒì„± ì‹œ í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ìƒì„± í›„ ë°°ê²½ ì œê±°",
            "- ë‚´ë¶€ëŠ” ë°˜ë“œì‹œ solid colorë¡œ ì±„ìš°ê¸°",
            "",
        ])

        # íŒŒì¼ ì €ì¥
        catalog_path.parent.mkdir(parents=True, exist_ok=True)
        with open(catalog_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

        print(f"\nğŸ“‹ ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸: {catalog_path}")
        print(f"   - ì´ {len(assets)}ê°œ ì—ì…‹ ë“±ë¡")

        return True

    def _upload_asset(self, local_path: Path, storage_path: str, folder: str, file_name: str, metadata: dict) -> bool:
        """ë‹¨ì¼ ì—ì…‹ ì—…ë¡œë“œ (Storage + DB)"""
        try:
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            is_svg = file_name.lower().endswith(".svg")
            content_type = "image/svg+xml" if is_svg else "image/png"

            # 1. Storage ì—…ë¡œë“œ
            with open(local_path, 'rb') as f:
                file_data = f.read()

            try:
                self.supabase.storage.from_(self.BUCKET_NAME).upload(
                    path=storage_path,
                    file=file_data,
                    file_options={"content-type": content_type}
                )
                print(f"   [STORAGE] OK")
            except Exception as e:
                if "Duplicate" in str(e) or "already exists" in str(e):
                    print(f"   [STORAGE] Already exists")
                else:
                    raise e

            # 2. ì´ë¯¸ì§€ ì •ë³´
            width, height, file_size = None, None, local_path.stat().st_size

            if is_svg:
                # SVG íŒŒì¼ì€ viewBoxì—ì„œ í¬ê¸° ì¶”ì¶œ ì‹œë„
                try:
                    import re
                    svg_content = local_path.read_text(encoding='utf-8')
                    # viewBox="0 0 300 300" ë˜ëŠ” width="300" height="300" ì¶”ì¶œ
                    viewbox_match = re.search(r'viewBox="[^"]*\s+(\d+)\s+(\d+)"', svg_content)
                    if viewbox_match:
                        width, height = int(viewbox_match.group(1)), int(viewbox_match.group(2))
                    else:
                        width_match = re.search(r'width="(\d+)"', svg_content)
                        height_match = re.search(r'height="(\d+)"', svg_content)
                        if width_match and height_match:
                            width, height = int(width_match.group(1)), int(height_match.group(1))
                except:
                    pass
            elif PIL_AVAILABLE:
                try:
                    with Image.open(local_path) as img:
                        width, height = img.size
                except:
                    pass

            # 3. DB ì €ì¥
            # í™•ì¥ì ì œê±° (íƒœê·¸ìš©)
            base_name = file_name.rsplit(".", 1)[0] if "." in file_name else file_name

            db_data = {
                "file_name": file_name,
                "folder": folder,
                "storage_path": storage_path,
                "description": metadata.get("description", f"{folder} asset: {file_name}"),
                "tags": metadata.get("tags", [folder, base_name]),
                "width": width,
                "height": height,
                "file_size": file_size,
            }

            self.supabase.table("assets").upsert(
                db_data,
                on_conflict="folder,file_name"
            ).execute()
            print(f"   [DB] OK")

            return True
        except Exception as e:
            print(f"   [ERROR] {e}")
            return False


# ============================================================================
# ì´ë¯¸ì§€ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class ImageManager:
    """ë°°ê²½ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë° íŒŒì¼ ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def get_project_dir(self) -> Optional[Path]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬"""
        project_id = self.state.get("project_id")
        if project_id:
            return OUTPUT_DIR / project_id
        return None
    
    def export_prompts(self) -> Optional[Path]:
        """ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        prompts_dir = project_dir / "6_image_prompts"
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì”¬ ë¶„í• ì„ ì§„í–‰í•˜ì„¸ìš”.")
            return None
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        if not scenes:
            print("âŒ ì”¬ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ìŠ¤íƒ€ì¼ ì •ë³´
        style = self.state.get("settings.style", "cyberpunk")
        aspect_ratio = self.state.get("settings.aspect_ratio", "16:9")
        
        # ë°°ì¹˜ íŒŒì¼ ìƒì„±
        batch_file = prompts_dir / "prompts_batch.txt"
        prompts_dir.mkdir(parents=True, exist_ok=True)
        
        lines = [
            "=" * 70,
            f"í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            f"ì œëª©: {self.state.get('title')}",
            f"ìŠ¤íƒ€ì¼: {style}",
            f"ì¢…íš¡ë¹„: {aspect_ratio}",
            f"ì´ ì”¬: {len(scenes)}ê°œ",
            "=" * 70,
            "",
            "ğŸ“Œ ì‚¬ìš©ë²•:",
            "1. ê° í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± AIì— ì…ë ¥",
            "2. ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ",
            f"3. íŒŒì¼ëª…ì„ s1_bg.png, s2_bg.png, ... í˜•ì‹ìœ¼ë¡œ ë³€ê²½",
            f"4. 9_backgrounds/ í´ë”ì— ì €ì¥",
            "5. python math_video_pipeline.py images-check ë¡œ ê²€ì¦",
            "",
            "=" * 70,
            ""
        ]
        
        # ê° ì”¬ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        for i, scene in enumerate(scenes):
            scene_id = scene.get("scene_id", f"s{i+1}")
            section = scene.get("section", "")
            duration = scene.get("duration", 0)
            visual_concept = scene.get("visual_concept", "")
            
            # ê°œë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ë„ ì €ì¥
            prompt = self._generate_prompt(style, aspect_ratio, visual_concept, section)
            
            prompt_file = prompts_dir / f"{scene_id}_background.txt"
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(prompt)
            
            # ë°°ì¹˜ íŒŒì¼ì— ì¶”ê°€
            lines.append(f"=== Scene {scene_id} ({section}) ===")
            lines.append(f"[Duration: {duration}ì´ˆ]")
            lines.append(f"[Visual: {visual_concept[:50]}...]" if len(visual_concept) > 50 else f"[Visual: {visual_concept}]")
            lines.append("")
            lines.append(prompt)
            lines.append("")
            lines.append("-" * 70)
            lines.append("")
        
        # ë°°ì¹˜ íŒŒì¼ ì €ì¥
        with open(batch_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
        
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ")
        print(f"   ğŸ“„ ë°°ì¹˜ íŒŒì¼: {batch_file}")
        print(f"   ğŸ“ ê°œë³„ íŒŒì¼: {prompts_dir}/")
        print(f"   ğŸ¬ ì´ {len(scenes)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        
        return batch_file
    
    def _generate_prompt(self, style: str, aspect_ratio: str, visual_concept: str, section: str) -> str:
        """ìŠ¤íƒ€ì¼ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± - ì¥ì‹ ìš”ì†ŒëŠ” í¬ë¯¸í•œ íšŒìƒ‰ìœ¼ë¡œ í†µì¼"""

        # ìŠ¤íƒ€ì¼ë³„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ë°”íƒ•ìƒ‰ ìœ ì§€, ì¥ì‹ì€ faint gray)
        style_prompts = {
            "minimal": {
                "base": "minimalist mathematical background, clean dark gradient",
                "tint": "soft muted blue undertones",
                "decoration": "very faint gray geometric patterns, barely visible grid lines, subtle ghost-like shapes at 15% opacity",
            },
            "cyberpunk": {
                "base": "cyberpunk mathematical background, very dark futuristic scene, near-black base",
                "tint": "subtle purple tint",
                "decoration": "faint gray digital grid barely visible, ghost-like circuit patterns in light gray, very subtle gray holographic rectangles at 15% opacity, all decorative elements in muted gray",
            },
            "paper": {
                "base": "paper texture background, warm beige to cream gradient, subtle paper grain texture",
                "tint": "",
                "decoration": "faint gray digital grid barely visible, ghost-like circuit patterns in light gray, very subtle gray holographic rectangles at 15% opacity, faint gray futuristic UI elements, barely visible tech lines and connection nodes, very faint gray mathematical formulas scattered in background like integral signs and sigma notation and partial derivatives and matrix brackets and limit expressions, all decorative elements in muted gray #BBBBBB to #CCCCCC",
            },
            "space": {
                "base": "space background, deep dark space scene, near-black",
                "tint": "subtle purple tint",
                "decoration": "very faint gray stars barely visible, ghost-like nebula hints in muted gray, subtle gray cosmic dust at 10% opacity, no bright stars, no colorful nebula",
            },
            "geometric": {
                "base": "geometric pattern background, dark gradient base",
                "tint": "subtle blue tint",
                "decoration": "very faint gray geometric shapes, barely visible symmetrical patterns, ghost-like mathematical lines in light gray, all patterns at 15% opacity",
            },
            "stickman": {
                "base": "educational background, soft dark gradient",
                "tint": "subtle teal tint",
                "decoration": "very faint gray playful shapes, barely visible doodle patterns, ghost-like circles and squares in light gray, friendly but subtle decorative elements",
            }
        }

        config = style_prompts.get(style, style_prompts["cyberpunk"])

        # ì¢…íš¡ë¹„ í…ìŠ¤íŠ¸
        ratio_text = "16:9 widescreen horizontal" if aspect_ratio == "16:9" else "9:16 vertical portrait mobile"

        # í‹´íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        tint_text = f", {config['tint']}" if config['tint'] else ""

        prompt = f"""{config['base']}{tint_text},
{config['decoration']},
no neon colors, no bright accents, no glowing elements,
mathematical education video background,
no text, no letters, no numbers, no Korean, no equations,
{ratio_text} ratio,
high contrast for text overlay, professional education aesthetic,
8K quality, sharp details

Negative prompt: text, letters, numbers, words, Korean, Chinese, Japanese, equations, formulas, mathematical symbols, writing, watermark, logo, signature, blurry, low quality, pixelated, faces, people, hands, neon colors, bright accents, glowing elements, vibrant colors, saturated colors, high contrast patterns"""

        return prompt
    
    def check_images(self) -> Dict[str, Any]:
        """ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "message": "No active project"}
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        backgrounds_dir = project_dir / "9_backgrounds"
        
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "message": "No scenes file"}
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        
        # ì´ë¯¸ì§€ í™•ì¸
        found = []
        missing = []
        
        for scene_id in scene_ids:
            # ì—¬ëŸ¬ í™•ì¥ì í™•ì¸
            image_found = False
            for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                image_file = backgrounds_dir / f"{scene_id}_bg{ext}"
                if image_file.exists():
                    found.append(str(image_file.name))
                    image_found = True
                    break
            
            if not image_found:
                missing.append(f"{scene_id}_bg.png")
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ–¼ï¸  ë°°ê²½ ì´ë¯¸ì§€ ìƒíƒœ í™•ì¸")
        print("=" * 60)
        print(f"ğŸ“ í´ë”: {backgrounds_dir}")
        print(f"ğŸ¬ ì´ ì”¬: {len(scene_ids)}ê°œ")
        print(f"âœ… ì¤€ë¹„ë¨: {len(found)}ê°œ")
        print(f"âŒ ëˆ„ë½: {len(missing)}ê°œ")
        print()
        
        if found:
            print("âœ… ì¤€ë¹„ëœ ì´ë¯¸ì§€:")
            for f in found:
                print(f"   - {f}")
            print()
        
        if missing:
            print("âŒ ëˆ„ë½ëœ ì´ë¯¸ì§€:")
            for m in missing:
                print(f"   - {m}")
            print()
            print("ğŸ“Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë ¤ë©´:")
            print("   1. python math_video_pipeline.py prompts-export")
            print("   2. í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„± (Midjourney, DALL-E ë“±)")
            print(f"   3. {backgrounds_dir}/ ì— ì €ì¥")
        else:
            print("ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        print("=" * 60)
        
        return {
            "status": "complete" if not missing else "incomplete",
            "total": len(scene_ids),
            "found": found,
            "missing": missing
        }
    
    def import_images(self, source_dir: str) -> Dict[str, Any]:
        """ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°"""
        project_dir = self.get_project_dir()
        if not project_dir:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "imported": 0}
        
        source_path = Path(source_dir)
        if not source_path.exists():
            print(f"âŒ ì†ŒìŠ¤ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_dir}")
            return {"status": "error", "imported": 0}
        
        backgrounds_dir = project_dir / "9_backgrounds"
        backgrounds_dir.mkdir(parents=True, exist_ok=True)
        
        scenes_file = project_dir / "2_scenes" / "scenes.json"
        if not scenes_file.exists():
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"status": "error", "imported": 0}
        
        # ì”¬ ì •ë³´ ë¡œë“œ
        with open(scenes_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenes = data if isinstance(data, list) else data.get("scenes", [])
        scene_ids = [s.get("scene_id", f"s{i+1}") for i, s in enumerate(scenes)]
        
        # ì†ŒìŠ¤ í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ë“¤
        image_extensions = {".png", ".jpg", ".jpeg", ".webp"}
        source_images = sorted([
            f for f in source_path.iterdir() 
            if f.is_file() and f.suffix.lower() in image_extensions
        ])
        
        if not source_images:
            print(f"âŒ ì†ŒìŠ¤ í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {source_dir}")
            return {"status": "error", "imported": 0}
        
        print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°")
        print(f"   ì†ŒìŠ¤: {source_dir}")
        print(f"   ëŒ€ìƒ: {backgrounds_dir}")
        print(f"   ë°œê²¬ëœ ì´ë¯¸ì§€: {len(source_images)}ê°œ")
        print(f"   í•„ìš”í•œ ì”¬: {len(scene_ids)}ê°œ")
        print()
        
        imported = []
        
        # ë°©ë²• 1: íŒŒì¼ëª…ì— ì”¬ IDê°€ í¬í•¨ëœ ê²½ìš°
        for scene_id in scene_ids:
            for img in source_images:
                if scene_id in img.stem.lower():
                    dest = backgrounds_dir / f"{scene_id}_bg{img.suffix}"
                    if not dest.exists():
                        import shutil
                        shutil.copy2(img, dest)
                        imported.append(f"{img.name} â†’ {dest.name}")
                        print(f"   âœ… {img.name} â†’ {dest.name}")
                    break
        
        # ë°©ë²• 2: ìˆœì„œëŒ€ë¡œ ë§¤ì¹­ (ì•„ì§ ë§¤ì¹­ ì•ˆ ëœ ê²ƒë“¤)
        remaining_scenes = [s for s in scene_ids if not (backgrounds_dir / f"{s}_bg.png").exists() 
                          and not (backgrounds_dir / f"{s}_bg.jpg").exists()
                          and not (backgrounds_dir / f"{s}_bg.jpeg").exists()
                          and not (backgrounds_dir / f"{s}_bg.webp").exists()]
        
        remaining_images = [img for img in source_images 
                          if not any(img.name in i for i in imported)]
        
        for scene_id, img in zip(remaining_scenes, remaining_images):
            dest = backgrounds_dir / f"{scene_id}_bg{img.suffix}"
            import shutil
            shutil.copy2(img, dest)
            imported.append(f"{img.name} â†’ {dest.name}")
            print(f"   âœ… {img.name} â†’ {dest.name} (ìˆœì„œ ë§¤ì¹­)")
        
        print()
        print(f"âœ… ì´ {len(imported)}ê°œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
        
        # ê²€ì¦ ì‹¤í–‰
        print()
        self.check_images()
        
        return {
            "status": "success",
            "imported": len(imported),
            "files": imported
        }


# ============================================================================
# ë Œë”ë§ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class RenderManager:
    """Manim ë Œë”ë§ ê´€ë¦¬"""
    
    def __init__(self, state_manager: StateManager):
        self.state = state_manager
    
    def render_scene(
        self,
        scene_id: str,
        quality: str = "l",  # l=low, m=medium, h=high, k=4k
        preview: bool = True
    ) -> bool:
        """ë‹¨ì¼ ì”¬ ë Œë”ë§"""
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_file = project_dir / "4_manim_code" / f"{scene_id}_manim.py"
        
        if not code_file.exists():
            print(f"âŒ ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {code_file}")
            return False
        
        # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ (scene_idë¥¼ PascalCaseë¡œ)
        class_name = scene_id.capitalize()
        
        # Manim ëª…ë ¹ì–´ êµ¬ì„±
        cmd = ["manim"]

        if preview:
            cmd.append("-p")

        cmd.append(f"-q{quality}")
        cmd.append("--transparent")  # íˆ¬ëª… ë°°ê²½ (ë°°ê²½ ì´ë¯¸ì§€ í•©ì„±ìš©)
        cmd.append(str(code_file))
        cmd.append(class_name)
        
        print(f"\nğŸ¬ ë Œë”ë§: {scene_id}")
        print(f"   ëª…ë ¹ì–´: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"   âœ… ë Œë”ë§ ì„±ê³µ")
                return True
            else:
                print(f"   âŒ ë Œë”ë§ ì‹¤íŒ¨")
                print(f"   ì˜¤ë¥˜: {result.stderr}")
                return False
                
        except FileNotFoundError:
            print("   âŒ Manimì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜: pip install manim")
            return False
        except Exception as e:
            print(f"   âŒ ë Œë”ë§ ì˜¤ë¥˜: {e}")
            return False
    
    def render_all(
        self,
        quality: str = "l",
        preview: bool = False
    ) -> Dict[str, bool]:
        """ëª¨ë“  ì”¬ ë Œë”ë§"""
        
        # ë Œë”ë§ ì‹œì‘ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state.update_rendering()
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_dir = project_dir / "4_manim_code"
        
        if not code_dir.exists():
            print(f"âŒ ì½”ë“œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {code_dir}")
            return {}
        
        # ëª¨ë“  Manim íŒŒì¼ ì°¾ê¸°
        code_files = list(code_dir.glob("*_manim.py"))
        
        if not code_files:
            print("âŒ Manim ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        print(f"\nğŸ¬ ì´ {len(code_files)}ê°œ ì”¬ ë Œë”ë§ ì‹œì‘")
        print("="*60)
        
        results = {}
        
        for code_file in sorted(code_files):
            scene_id = code_file.stem.replace("_manim", "")
            success = self.render_scene(scene_id, quality, preview)
            results[scene_id] = success
        
        print("\n" + "="*60)
        success_count = sum(1 for v in results.values() if v)
        print(f"âœ… ë Œë”ë§ ì™„ë£Œ: {success_count}/{len(results)}ê°œ ì„±ê³µ")

        # ë Œë”ë§ ì„±ê³µí•œ ê²ƒì´ ìˆìœ¼ë©´ ê²°ê³¼ë¬¼ ìë™ ìˆ˜ì§‘
        if success_count > 0:
            print("\nğŸ“¦ ë Œë”ë§ ê²°ê³¼ë¬¼ ìë™ ìˆ˜ì§‘ ì¤‘...")
            self.collect_renders()

        return results

    def collect_renders(self) -> Dict[str, str]:
        """media/videos/ í´ë”ì—ì„œ ë Œë”ë§ ê²°ê³¼ë¬¼ì„ ìˆ˜ì§‘í•˜ì—¬ 8_renders/ë¡œ ë³µì‚¬"""

        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        renders_dir = project_dir / "8_renders"
        renders_dir.mkdir(parents=True, exist_ok=True)

        # Manim ê¸°ë³¸ ì¶œë ¥ í´ë”
        media_dir = Path("media/videos")

        if not media_dir.exists():
            print(f"âŒ media/videos í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        # í”„ë¡œì íŠ¸ì˜ ì”¬ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        scenes = self.state.get("scenes", {})
        completed_scenes = scenes.get("completed", [])

        if not completed_scenes:
            # ì½”ë“œ íŒŒì¼ì—ì„œ ì”¬ ID ì¶”ì¶œ
            code_dir = project_dir / "4_manim_code"
            if code_dir.exists():
                code_files = list(code_dir.glob("*_manim.py"))
                completed_scenes = [f.stem.replace("_manim", "") for f in code_files]

        print(f"\nğŸ“¦ ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘")
        print(f"   ì†ŒìŠ¤: {media_dir}")
        print(f"   ëŒ€ìƒ: {renders_dir}")
        print(f"   ì”¬ ê°œìˆ˜: {len(completed_scenes)}")
        print("="*60)

        collected = {}
        missing = []

        for scene_id in completed_scenes:
            # ì”¬ë³„ í´ë” ì°¾ê¸° (ì˜ˆ: s1_manim, s2_manim ë“±)
            scene_folder_pattern = f"{scene_id}_manim"
            scene_folders = list(media_dir.glob(scene_folder_pattern))

            if not scene_folders:
                missing.append(scene_id)
                continue

            scene_folder = scene_folders[0]

            # í’ˆì§ˆ í´ë” ì°¾ê¸° (480p15, 720p30, 1080p60 ë“±)
            quality_folders = [d for d in scene_folder.iterdir() if d.is_dir()]

            if not quality_folders:
                missing.append(scene_id)
                continue

            # ê°€ì¥ ìµœê·¼ í´ë” ì‚¬ìš© (ë³´í†µ í•˜ë‚˜ë¿)
            quality_folder = sorted(quality_folders, key=lambda x: x.stat().st_mtime, reverse=True)[0]

            # ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸° (.mov ë˜ëŠ” .mp4)
            video_files = list(quality_folder.glob("*.mov")) + list(quality_folder.glob("*.mp4"))

            if not video_files:
                missing.append(scene_id)
                continue

            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
            source_file = sorted(video_files, key=lambda x: x.stat().st_mtime, reverse=True)[0]

            # ëŒ€ìƒ íŒŒì¼ëª… (scene_id.í™•ì¥ì)
            dest_file = renders_dir / f"{scene_id}{source_file.suffix}"

            # ë³µì‚¬
            import shutil
            shutil.copy2(source_file, dest_file)

            collected[scene_id] = str(dest_file)
            print(f"   âœ… {scene_id}: {source_file.name} â†’ {dest_file.name}")

        print("\n" + "="*60)
        print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(collected)}ê°œ")

        if missing:
            print(f"âš ï¸  ëˆ„ë½: {len(missing)}ê°œ - {', '.join(missing)}")

        # state.json ì—…ë°ì´íŠ¸
        if collected:
            state_data = self.state.load()
            state_data.setdefault("files", {})["renders"] = list(collected.values())
            state_data["current_phase"] = "rendered"
            self.state.save()
            print(f"\nğŸ“ state.json ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            print(f"   current_phase: rendered")
            print(f"   files.renders: {len(collected)}ê°œ íŒŒì¼")

        return collected

    def generate_render_script(self) -> Optional[Path]:
        """ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        
        project_dir = OUTPUT_DIR / self.state.get("project_id", "unknown")
        code_dir = project_dir / "4_manim_code"
        
        if not code_dir.exists():
            return None
        
        code_files = sorted(code_dir.glob("*_manim.py"))
        
        if not code_files:
            return None
        
        # Bash ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        script_file = project_dir / "render_all.sh"
        
        lines = [
            "#!/bin/bash",
            "# Manim ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸",
            f"# í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            f"# ìƒì„±ì¼: {datetime.now().isoformat()}",
            "",
            "set -e  # ì˜¤ë¥˜ ì‹œ ì¤‘ë‹¨",
            "",
        ]
        
        for code_file in code_files:
            scene_id = code_file.stem.replace("_manim", "")
            class_name = scene_id.capitalize()
            
            lines.append(f'echo "ë Œë”ë§: {scene_id}..."')
            lines.append(f'manim -pql "{code_file}" {class_name}')
            lines.append("")
        
        lines.append('echo "ëª¨ë“  ì”¬ ë Œë”ë§ ì™„ë£Œ!"')
        
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
        
        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ (Unix)
        try:
            script_file.chmod(0o755)
        except:
            pass
        
        # Windowsìš© ë°°ì¹˜ íŒŒì¼ë„ ìƒì„±
        bat_file = project_dir / "render_all.bat"
        
        bat_lines = [
            "@echo off",
            f"REM Manim ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸",
            f"REM í”„ë¡œì íŠ¸: {self.state.get('project_id')}",
            "",
        ]
        
        for code_file in code_files:
            scene_id = code_file.stem.replace("_manim", "")
            class_name = scene_id.capitalize()
            
            bat_lines.append(f'echo ë Œë”ë§: {scene_id}...')
            bat_lines.append(f'manim -pql "{code_file}" {class_name}')
            bat_lines.append("")
        
        bat_lines.append('echo ëª¨ë“  ì”¬ ë Œë”ë§ ì™„ë£Œ!')
        bat_lines.append("pause")
        
        with open(bat_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(bat_lines))
        
        print(f"âœ… ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
        print(f"   Bash: {script_file}")
        print(f"   Windows: {bat_file}")

        return script_file


# ============================================================================
# ì”¬ ë¶„í•  ì €ì¥ (í† í° ì ˆì•½)
# ============================================================================

class SceneSplitter:
    """scenes.jsonì„ ê°œë³„ ì”¬ íŒŒì¼ë¡œ ë¶„í• """

    def __init__(self, state: StateManager):
        self.state = state

    def split(self):
        """scenes.jsonì„ ê°œë³„ íŒŒì¼ë¡œ ë¶„í• """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        scenes_path = Path(f"output/{project_id}/2_scenes/scenes.json")
        if not scenes_path.exists():
            print(f"âŒ scenes.jsonì´ ì—†ìŠµë‹ˆë‹¤: {scenes_path}")
            return

        # scenes.json ì½ê¸°
        with open(scenes_path, "r", encoding="utf-8") as f:
            scenes = json.load(f)

        if not scenes:
            print("âŒ scenes.jsonì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return

        # ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
        output_dir = scenes_path.parent
        saved_count = 0

        for scene in scenes:
            scene_id = scene.get("scene_id", "unknown")
            scene_file = output_dir / f"{scene_id}.json"

            with open(scene_file, "w", encoding="utf-8") as f:
                json.dump(scene, f, ensure_ascii=False, indent=2)

            saved_count += 1

        print(f"âœ… {saved_count}ê°œ ì”¬ì„ ê°œë³„ íŒŒì¼ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        print(f"   ìœ„ì¹˜: {output_dir}/")
        print(f"   ì˜ˆ: {output_dir}/s1.json, s2.json, ...")
        print(f"\nğŸ’¡ ì´ì œ Claudeê°€ í•„ìš”í•œ ì”¬ë§Œ ì½ì–´ í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.")


# ============================================================================
# ë‚˜ë ˆì´ì…˜ ì¶”ì¶œ (Narration Designerìš©)
# ============================================================================

class NarrationExtractor:
    """ì”¬ íŒŒì¼ì—ì„œ narration_displayë¥¼ ì¶”ì¶œí•˜ì—¬ Narration Designerì—ê²Œ ì „ë‹¬"""

    def __init__(self, state: StateManager):
        self.state = state

    def extract(self, scene_ids: Optional[List[str]] = None):
        """ì”¬ íŒŒì¼ë“¤ì—ì„œ narration_displayë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥

        Args:
            scene_ids: ì¶”ì¶œí•  ì”¬ ID ëª©ë¡. Noneì´ë©´ ì „ì²´ ì¶”ì¶œ
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        scenes_path = Path(f"output/{project_id}/2_scenes")
        if not scenes_path.exists():
            print(f"âŒ ì”¬ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {scenes_path}")
            return

        # ì”¬ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        if scene_ids:
            scene_files = [scenes_path / f"{sid}.json" for sid in scene_ids]
            scene_files = [f for f in scene_files if f.exists()]
        else:
            scene_files = sorted(scenes_path.glob("s*.json"),
                               key=lambda x: self._scene_sort_key(x.stem))

        if not scene_files:
            print("âŒ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # narration_display ì¶”ì¶œ
        extractions = []
        for scene_file in scene_files:
            try:
                with open(scene_file, "r", encoding="utf-8") as f:
                    scene_data = json.load(f)

                scene_id = scene_data.get("scene_id", scene_file.stem)
                narration_display = scene_data.get("narration_display", "")

                if narration_display:
                    extractions.append({
                        "scene_id": scene_id,
                        "narration_display": narration_display
                    })
            except Exception as e:
                print(f"  âš ï¸ {scene_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ê²°ê³¼ ì¶œë ¥ (Claudeê°€ ì½ì–´ì„œ Narration Designerì—ê²Œ ì „ë‹¬)
        print(f"\nğŸ“ ë‚˜ë ˆì´ì…˜ ì¶”ì¶œ ì™„ë£Œ: {len(extractions)}ê°œ ì”¬")
        print("\n```json")
        print(json.dumps(extractions, ensure_ascii=False, indent=2))
        print("```")
        print(f"\nğŸ’¡ ìœ„ ë‚´ìš©ì„ Narration Designerì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.")
        print(f"   ì¶œë ¥ ìœ„ì¹˜: output/{project_id}/2_narration/")

    def _scene_sort_key(self, scene_id: str):
        """ì”¬ ID ì •ë ¬ í‚¤ (s1, s2, ..., s10, s11, ...)"""
        import re
        match = re.match(r's(\d+)([a-z]*)', scene_id)
        if match:
            return (int(match.group(1)), match.group(2))
        return (0, scene_id)

    def save_narration(self, scene_id: str, subtitle_display: str, narration_tts: str):
        """Narration Designerê°€ ìƒì„±í•œ ë‚˜ë ˆì´ì…˜ì„ ì €ì¥

        Args:
            scene_id: ì”¬ ID (ì˜ˆ: s1)
            subtitle_display: ìë§‰ìš© í…ìŠ¤íŠ¸ (;; êµ¬ë¶„ì í¬í•¨)
            narration_tts: TTS ìŒì„±ìš© í…ìŠ¤íŠ¸ (í•œê¸€ ë°œìŒ)
        """
        project_id = self.state.get("project_id")
        if not project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        narration_path = Path(f"output/{project_id}/2_narration")
        narration_path.mkdir(parents=True, exist_ok=True)

        narration_data = {
            "scene_id": scene_id,
            "subtitle_display": subtitle_display,
            "narration_tts": narration_tts
        }

        output_file = narration_path / f"{scene_id}_narration.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(narration_data, f, ensure_ascii=False, indent=2)

        print(f"  âœ… {output_file.name} ì €ì¥ë¨")
        return True

    def check_narrations(self) -> Dict[str, Any]:
        """ë‚˜ë ˆì´ì…˜ íŒŒì¼ ìƒíƒœ í™•ì¸"""
        project_id = self.state.get("project_id")
        if not project_id:
            return {"error": "í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}

        scenes_path = Path(f"output/{project_id}/2_scenes")
        narration_path = Path(f"output/{project_id}/2_narration")

        # ì”¬ ëª©ë¡
        scene_files = list(scenes_path.glob("s*.json")) if scenes_path.exists() else []
        scene_ids = [f.stem for f in scene_files]

        # ë‚˜ë ˆì´ì…˜ íŒŒì¼ ëª©ë¡
        narration_files = list(narration_path.glob("*_narration.json")) if narration_path.exists() else []
        completed_ids = [f.stem.replace("_narration", "") for f in narration_files]

        missing = [sid for sid in scene_ids if sid not in completed_ids]

        result = {
            "total_scenes": len(scene_ids),
            "completed": len(completed_ids),
            "missing": missing,
            "missing_count": len(missing)
        }

        print(f"\nğŸ“Š ë‚˜ë ˆì´ì…˜ ìƒíƒœ:")
        print(f"   ì „ì²´ ì”¬: {result['total_scenes']}ê°œ")
        print(f"   ì™„ë£Œ: {result['completed']}ê°œ")
        print(f"   ë¯¸ì™„ë£Œ: {result['missing_count']}ê°œ")
        if missing:
            print(f"   ë¯¸ì™„ë£Œ ëª©ë¡: {', '.join(missing[:10])}{'...' if len(missing) > 10 else ''}")

        return result


# ============================================================================
# ì˜ìƒ í•©ì„± ë° ìë§‰ ê´€ë¦¬
# ============================================================================

class ComposerManager:
    """ì˜ìƒ í•©ì„± ë° ìë§‰ ìƒì„± ê´€ë¦¬"""

    def __init__(self, state: StateManager):
        self.state = state
        self.ffmpeg_path = self._find_ffmpeg()
        self.ffprobe_path = self._find_ffprobe()

    def _find_ffmpeg(self) -> str:
        """FFmpeg ê²½ë¡œ ì°¾ê¸°"""
        import shutil

        # ì‹œìŠ¤í…œ PATHì—ì„œ ì°¾ê¸°
        ffmpeg = shutil.which("ffmpeg")
        if ffmpeg:
            return ffmpeg

        # Windows ì¼ë°˜ì ì¸ ê²½ë¡œë“¤
        common_paths = [
            Path(os.environ.get("LOCALAPPDATA", "")) / "Microsoft/WinGet/Links/ffmpeg.exe",
            Path("C:/ffmpeg/bin/ffmpeg.exe"),
            Path("C:/Program Files/ffmpeg/bin/ffmpeg.exe"),
        ]

        for path in common_paths:
            if path.exists():
                return str(path)

        return "ffmpeg"  # PATHì— ìˆë‹¤ê³  ê°€ì •

    def _find_ffprobe(self) -> str:
        """FFprobe ê²½ë¡œ ì°¾ê¸°"""
        import shutil

        ffprobe = shutil.which("ffprobe")
        if ffprobe:
            return ffprobe

        # FFmpegì™€ ê°™ì€ í´ë”ì—ì„œ ì°¾ê¸°
        ffmpeg_dir = Path(self.ffmpeg_path).parent
        ffprobe_path = ffmpeg_dir / "ffprobe.exe"
        if ffprobe_path.exists():
            return str(ffprobe_path)

        return "ffprobe"

    def _get_duration(self, file_path: Path) -> Optional[float]:
        """ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ê¸¸ì´ í™•ì¸ (ffprobe ì‚¬ìš©)"""
        try:
            result = subprocess.run([
                self.ffprobe_path, "-v", "error",
                "-show_entries", "format=duration",
                "-of", "csv=p=0", str(file_path)
            ], capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                return float(result.stdout.strip())
        except Exception as e:
            print(f"  âš ï¸ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return None

    def _get_project_paths(self) -> Dict[str, Path]:
        """í”„ë¡œì íŠ¸ ê²½ë¡œë“¤ ë°˜í™˜"""
        project_id = self.state.get("project_id")
        if not project_id:
            return {}

        base = Path("output") / project_id
        return {
            "base": base,
            "audio": base / "0_audio",
            "scenes": base / "2_scenes",
            "subtitles": base / "7_subtitles",
            "renders": base / "8_renders",
            "backgrounds": base / "9_backgrounds",
            "final": base / "10_scene_final",
        }

    def _format_srt_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜: HH:MM:SS,mmm"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def _get_subtitle_display(self, project_dir: Path, scene_id: str, scene_data: dict) -> str:
        """subtitle_display í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´ (ìš°ì„ ìˆœìœ„: narration#.json > scenes.json)

        Args:
            project_dir: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
            scene_id: ì”¬ ID (ì˜ˆ: s1)
            scene_data: scenes.jsonì—ì„œ ì½ì€ ì”¬ ë°ì´í„° (fallbackìš©)

        Returns:
            subtitle_display í…ìŠ¤íŠ¸
        """
        # 1. narration#.json ìš°ì„  í™•ì¸
        narration_file = project_dir / "2_narration" / f"{scene_id}_narration.json"
        if narration_file.exists():
            try:
                with open(narration_file, 'r', encoding='utf-8') as f:
                    narration_data = json.load(f)
                    subtitle_display = narration_data.get("subtitle_display", "")
                    if subtitle_display:
                        return subtitle_display
            except Exception:
                pass

        # 2. Fallback: scenes.jsonì˜ subtitle_display ë˜ëŠ” narration_display
        return scene_data.get("subtitle_display") or scene_data.get("narration_display", "")

    def generate_subtitles(self) -> bool:
        """ëª¨ë“  ì”¬ì˜ SRT ìë§‰ ìƒì„± (ë¬¸ì¥ ë‹¨ìœ„)

        í…ìŠ¤íŠ¸ ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„:
            1. 2_narration/{scene_id}_narration.jsonì˜ subtitle_display (;; í¬í•¨)
            2. 2_scenes/{scene_id}.jsonì˜ subtitle_display (fallback)
            3. 2_scenes/{scene_id}.jsonì˜ narration_display (fallback)

        íƒ€ì´ë° ì†ŒìŠ¤: timing.jsonì˜ sentences ë°°ì—´ (Whisper segments)

        ë°©ì‹:
        1. subtitle_displayë¥¼ ;; ë˜ëŠ” .?! ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¦¬ â†’ í…ìŠ¤íŠ¸
        2. timing.jsonì˜ sentences ë°°ì—´ì—ì„œ íƒ€ì´ë° ì¶”ì¶œ â†’ start/end
        3. ë¬¸ì¥ ìˆ˜ ì¼ì¹˜í•˜ë©´ 1:1 ë§¤í•‘, ë¶ˆì¼ì¹˜í•˜ë©´ ê· ë“± ë¶„ë°°
        """
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        audio_path = paths["audio"]
        subtitle_path = paths["subtitles"]
        scenes_path = paths["scenes"]
        project_dir = paths["base"]

        # ìë§‰ í´ë” ìƒì„±
        subtitle_path.mkdir(parents=True, exist_ok=True)

        # narration íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        narration_dir = project_dir / "2_narration"
        use_narration_files = narration_dir.exists() and list(narration_dir.glob("*_narration.json"))

        print(f"\nğŸ“ ìë§‰ ìƒì„± ì‹œì‘")
        if use_narration_files:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_narration/")
        else:
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_scenes/ (fallback)")
        print("="*60)

        # scenes.jsonì—ì„œ ìë§‰ í…ìŠ¤íŠ¸ ë¡œë“œ
        # ìš°ì„ ìˆœìœ„: narration#.json > subtitle_display > narration_display
        scene_texts = {}
        for scene_file in scenes_path.glob("s*.json"):
            try:
                with open(scene_file, 'r', encoding='utf-8') as f:
                    scene_data = json.load(f)
                    scene_id = scene_data.get('scene_id', scene_file.stem)
                    # subtitle_display ê°€ì ¸ì˜¤ê¸° (narration#.json ìš°ì„ )
                    subtitle_text = self._get_subtitle_display(project_dir, scene_id, scene_data)
                    scene_texts[scene_id] = subtitle_text
            except Exception as e:
                print(f"  âš ï¸ {scene_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")

        # timing íŒŒì¼ ì°¾ê¸° (s32a ê°™ì€ IDë„ ì§€ì›)
        def scene_sort_key(path):
            scene_id = path.stem.split("_")[0][1:]  # "s32a" -> "32a"
            import re
            match = re.match(r'(\d+)([a-z]*)', scene_id)
            if match:
                return (int(match.group(1)), match.group(2))
            return (0, scene_id)

        timing_files = sorted(audio_path.glob("*_timing.json"), key=scene_sort_key)

        if not timing_files:
            print("âŒ timing.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¨¼ì € TTS ìƒì„± ë˜ëŠ” audio-processë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return False

        generated = []

        for timing_file in timing_files:
            scene_id = timing_file.stem.replace("_timing", "")

            with open(timing_file, 'r', encoding='utf-8') as f:
                timing_data = json.load(f)

            # ì›ë³¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (Whisper ê²°ê³¼ê°€ ì•„ë‹Œ narration_display ì‚¬ìš©!)
            original_text = scene_texts.get(scene_id, '')
            if not original_text:
                print(f"  âš ï¸ {scene_id}: narration_display ì—†ìŒ, Whisper í…ìŠ¤íŠ¸ ì‚¬ìš©")
                original_text = timing_data.get('whisper_text', '')

            total_duration = timing_data.get('total_duration', timing_data.get('duration', 0))
            timing_sentences = timing_data.get('sentences', timing_data.get('segments', []))

            # narration_displayë¥¼ ë¬¸ì¥ ë¶„ë¦¬ (.?! ê¸°ì¤€)
            display_sentences = self._split_sentences(original_text)

            if not display_sentences or total_duration <= 0:
                # SRT íŒŒì¼ ì €ì¥ (ë¹ˆ íŒŒì¼)
                srt_file = subtitle_path / f"{scene_id}.srt"
                with open(srt_file, 'w', encoding='utf-8') as f:
                    f.write("")
                generated.append(scene_id)
                continue

            # íƒ€ì´ë° ê³„ì‚°: sentences ë°°ì—´ íƒ€ì´ë° + narration_display í…ìŠ¤íŠ¸
            sentence_timings = self._calculate_sentence_timings_from_segments(
                display_sentences, timing_sentences, total_duration
            )

            # SRT ìƒì„± - ë¬¸ì¥ ë‹¨ìœ„
            srt_lines = []
            for idx, (sentence, start, end) in enumerate(sentence_timings, 1):
                start_time = self._format_srt_time(start)
                end_time = self._format_srt_time(end)

                srt_lines.append(str(idx))
                srt_lines.append(f"{start_time} --> {end_time}")
                srt_lines.append(sentence)
                srt_lines.append("")

            # SRT íŒŒì¼ ì €ì¥
            srt_file = subtitle_path / f"{scene_id}.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write("\n".join(srt_lines))

            generated.append(scene_id)
            print(f"  âœ… {scene_id}.srt: {len(display_sentences)}ë¬¸ì¥")

        print(f"\nâœ… ìë§‰ ìƒì„± ì™„ë£Œ: {len(generated)}ê°œ íŒŒì¼")
        print(f"   ìœ„ì¹˜: {subtitle_path}")
        print(f"   â„¹ï¸  í…ìŠ¤íŠ¸: narration_display, íƒ€ì´ë°: Whisper segments")

        return True

    def generate_subtitle_for_scene(self, scene_id: str) -> bool:
        """ë‹¨ì¼ ì”¬ì˜ SRT ìë§‰ ìƒì„± (narration#.json ìš°ì„ , scenes.json fallback)"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        audio_path = paths["audio"]
        subtitle_path = paths["subtitles"]
        scenes_path = paths["scenes"]
        project_dir = paths["base"]

        subtitle_path.mkdir(parents=True, exist_ok=True)

        # ì”¬ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        scene_file = scenes_path / f"{scene_id}.json"
        if not scene_file.exists():
            print(f"âŒ ì”¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scene_file}")
            return False

        with open(scene_file, 'r', encoding='utf-8') as f:
            scene_data = json.load(f)

        # subtitle_display ê°€ì ¸ì˜¤ê¸° (narration#.json ìš°ì„ )
        original_text = self._get_subtitle_display(project_dir, scene_id, scene_data)

        # timing íŒŒì¼ ë¡œë“œ
        timing_file = audio_path / f"{scene_id}_timing.json"
        if not timing_file.exists():
            print(f"âŒ íƒ€ì´ë° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {timing_file}")
            return False

        with open(timing_file, 'r', encoding='utf-8') as f:
            timing_data = json.load(f)

        total_duration = timing_data.get('total_duration', 0)
        timing_sentences = timing_data.get('sentences', [])

        # ë¬¸ì¥ ë¶„ë¦¬ ë° íƒ€ì´ë° ê³„ì‚°
        display_sentences = self._split_sentences(original_text)

        if not display_sentences or total_duration <= 0:
            srt_file = subtitle_path / f"{scene_id}.srt"
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write("")
            print(f"  âš ï¸ {scene_id}: ë¹ˆ ìë§‰ ìƒì„±")
            return True

        sentence_timings = self._calculate_sentence_timings_from_segments(
            display_sentences, timing_sentences, total_duration
        )

        # SRT ìƒì„±
        srt_lines = []
        for idx, (sentence, start, end) in enumerate(sentence_timings, 1):
            start_time = self._format_srt_time(start)
            end_time = self._format_srt_time(end)
            srt_lines.append(str(idx))
            srt_lines.append(f"{start_time} --> {end_time}")
            srt_lines.append(sentence)
            srt_lines.append("")

        srt_file = subtitle_path / f"{scene_id}.srt"
        with open(srt_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(srt_lines))

        print(f"âœ… {scene_id}.srt ìƒì„± ì™„ë£Œ: {len(display_sentences)}ë¬¸ì¥")
        return True

    def _split_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬

        í•µì‹¬: Scene Directorê°€ s{n}.jsonì˜ subtitle_displayì— ;;ë¡œ ë¶„í•  ìœ„ì¹˜ë¥¼ ì§€ì •
        Pythonì€ ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ë§Œ ìˆ˜í–‰ (ìë™ ë¶„í•  ì—†ìŒ)

        - ;; êµ¬ë¶„ìê°€ ìˆìœ¼ë©´: ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        - ;; êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´: í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìë§‰ìœ¼ë¡œ ì‚¬ìš©
        """
        if not text:
            return []

        # ;; êµ¬ë¶„ìê°€ ìˆìœ¼ë©´ ;; ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        if ';;' in text:
            sentences = text.split(';;')
            sentences = [s.strip() for s in sentences if s.strip()]
            return sentences

        # ;; ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìë§‰ìœ¼ë¡œ ë°˜í™˜
        return [text.strip()]

    def _calculate_sentence_timings_from_segments(
        self,
        display_sentences: List[str],
        timing_sentences: List[dict],
        total_duration: float
    ) -> List[tuple]:
        """ë¬¸ì¥ë³„ íƒ€ì´ë° ê³„ì‚° (ê· ë“± ë¶„ë°° ë°©ì‹)

        ============================================================
        [ìë§‰ íƒ€ì´ë° ê³„ì‚° ë¡œì§] - ê· ë“± ë¶„ë°°
        ============================================================

        Whisperì˜ í•œê³„:
        - segments: ë°œí™” ë‹¨ìœ„(pause ê¸°ì¤€)ì´ì§€ ë¬¸ì¥ ë‹¨ìœ„(.?!)ê°€ ì•„ë‹˜
        - words: í…ìŠ¤íŠ¸ ì˜¤ì¸ì‹ ë§ìŒ ("íƒ„ë ¥ì„±" â†’ "íŒ”ë ¥ì„±")

        ë”°ë¼ì„œ ê· ë“± ë¶„ë°° ì‚¬ìš©:
        - í…ìŠ¤íŠ¸: narration_displayì—ì„œ .?! ê¸°ì¤€ ë¶„ë¦¬ (ì •í™•í•¨)
        - íƒ€ì´ë°: total_duration / ë¬¸ì¥ìˆ˜ (ê·¼ì‚¬ì¹˜)

        ì˜ˆì‹œ (s16, 14.35ì´ˆ, 5ë¬¸ì¥):
        - ë¬¸ì¥1: 0.00 ~ 2.87ì´ˆ
        - ë¬¸ì¥2: 2.87 ~ 5.74ì´ˆ
        - ë¬¸ì¥3: 5.74 ~ 8.61ì´ˆ
        - ë¬¸ì¥4: 8.61 ~ 11.48ì´ˆ
        - ë¬¸ì¥5: 11.48 ~ 14.35ì´ˆ
        ============================================================

        Args:
            display_sentences: narration_displayì—ì„œ ë¶„ë¦¬í•œ ë¬¸ì¥ë“¤ (í…ìŠ¤íŠ¸ìš©)
            timing_sentences: timing.jsonì˜ sentences ë°°ì—´ (í˜„ì¬ ë¯¸ì‚¬ìš©)
            total_duration: ì „ì²´ ì˜¤ë””ì˜¤ ê¸¸ì´

        Returns:
            List of (sentence_text, start_time, end_time)
        """
        n_display = len(display_sentences)

        # ============================================================
        # ê· ë“± ë¶„ë°°: total_duration / ë¬¸ì¥ìˆ˜
        # ============================================================
        duration_per_sentence = total_duration / n_display
        result = []
        for i, sentence in enumerate(display_sentences):
            start = i * duration_per_sentence
            end = (i + 1) * duration_per_sentence
            # ë§ˆì§€ë§‰ ë¬¸ì¥ì€ ì •í™•íˆ total_durationê¹Œì§€
            if i == n_display - 1:
                end = total_duration
            result.append((sentence, start, end))
        return result

    def _merge_audio(self, scene_id: str) -> Optional[Path]:
        """ì”¬ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ë°˜í™˜ (ìƒˆ ë°©ì‹: ë‹¨ì¼ íŒŒì¼ / êµ¬ ë°©ì‹: ë³‘í•©)"""
        paths = self._get_project_paths()
        audio_path = paths["audio"]

        # 1. ìƒˆ ë°©ì‹: ë‹¨ì¼ íŒŒì¼ (s1.mp3) í™•ì¸
        single_file = audio_path / f"{scene_id}.mp3"
        if single_file.exists():
            return single_file

        # 2. êµ¬ ë°©ì‹: ë¬¸ì¥ë³„ íŒŒì¼ë“¤ (s1_1.mp3, s1_2.mp3, ...) ë³‘í•©
        audio_files = sorted(
            audio_path.glob(f"{scene_id}_*.mp3"),
            key=lambda x: int(x.stem.split("_")[1]) if "_" in x.stem and x.stem.split("_")[1].isdigit() else 0
        )

        # timing.json, concat.txt ë“± ì œì™¸
        audio_files = [f for f in audio_files if not any(x in f.stem for x in ["timing", "concat", "merged"])]

        if not audio_files:
            print(f"  âš ï¸  {scene_id}: ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ")
            return None

        # íŒŒì¼ì´ 1ê°œë©´ ë°”ë¡œ ë°˜í™˜
        if len(audio_files) == 1:
            return audio_files[0]

        merged_file = audio_path / f"{scene_id}_merged.mp3"

        # ì´ë¯¸ ë³‘í•©ëœ íŒŒì¼ì´ ìˆê³  ìµœì‹ ì´ë©´ ì¬ì‚¬ìš©
        if merged_file.exists():
            merged_time = merged_file.stat().st_mtime
            if all(f.stat().st_mtime < merged_time for f in audio_files):
                return merged_file

        # concat íŒŒì¼ ìƒì„±
        concat_file = audio_path / f"{scene_id}_concat.txt"
        with open(concat_file, 'w', encoding='utf-8') as f:
            for audio in audio_files:
                f.write(f"file '{audio.name}'\n")

        # FFmpegë¡œ ë³‘í•©
        cmd = [
            self.ffmpeg_path,
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
            "-c", "copy",
            "-y", str(merged_file)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"  âŒ {scene_id}: ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨")
            return None

        return merged_file

    def _find_manim_render(self, scene_id: str) -> Optional[Path]:
        """Manim ë Œë”ë§ ê²°ê³¼ ì°¾ê¸°"""
        # media/videos/{scene_id}_manim í´ë”ì—ì„œ ì°¾ê¸°
        media_path = Path("media/videos") / f"{scene_id}_manim"

        if media_path.exists():
            # í’ˆì§ˆë³„ í´ë” í™•ì¸ (ë†’ì€ í’ˆì§ˆ ìš°ì„ )
            for quality in ["1080p60", "1080p30", "720p30", "480p15"]:
                quality_path = media_path / quality
                if quality_path.exists():
                    # Scene*.mov ë˜ëŠ” Scene*.mp4 ì°¾ê¸°
                    for ext in ["mov", "mp4"]:
                        scene_files = list(quality_path.glob(f"Scene*.{ext}"))
                        if scene_files:
                            return scene_files[0]

        # 8_renders í´ë”ì—ì„œë„ ì°¾ê¸°
        paths = self._get_project_paths()
        renders_path = paths.get("renders")
        if renders_path and renders_path.exists():
            for ext in ["mov", "mp4"]:
                render_files = list(renders_path.glob(f"{scene_id}*.{ext}"))
                if render_files:
                    return render_files[0]

        return None

    def _find_background(self, scene_id: str) -> Optional[Path]:
        """ë°°ê²½ ì´ë¯¸ì§€ ì°¾ê¸°"""
        paths = self._get_project_paths()
        bg_path = paths.get("backgrounds")

        if not bg_path or not bg_path.exists():
            return None

        for ext in ["png", "jpg", "jpeg", "webp"]:
            bg_file = bg_path / f"{scene_id}_bg.{ext}"
            if bg_file.exists():
                return bg_file

        return None

    def compose_scene(self, scene_id: str, with_subtitle: bool = True, end_padding: float = 1.0) -> Optional[Path]:
        """ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½ + Manim + ì˜¤ë””ì˜¤ + ìë§‰)

        Args:
            scene_id: ì”¬ ID (ì˜ˆ: s1, s2)
            with_subtitle: ìë§‰ í¬í•¨ ì—¬ë¶€
            end_padding: ì”¬ ëì— ì¶”ê°€í•  ë¬´ìŒ íŒ¨ë”© (ì´ˆ). ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€ë¨.
        """
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print(f"\nğŸ¬ {scene_id} í•©ì„± ì‹œì‘...")

        # ì¶œë ¥ í´ë” ìƒì„±
        final_path = paths["final"]
        final_path.mkdir(parents=True, exist_ok=True)

        # í•„ìš”í•œ íŒŒì¼ë“¤ ì°¾ê¸°
        manim_file = self._find_manim_render(scene_id)
        bg_file = self._find_background(scene_id)
        audio_file = self._merge_audio(scene_id)
        subtitle_file = paths["subtitles"] / f"{scene_id}.srt" if with_subtitle else None

        # íŒŒì¼ ì²´í¬
        if not manim_file:
            print(f"  âŒ Manim ë Œë”ë§ íŒŒì¼ ì—†ìŒ")
            return None

        if not audio_file:
            print(f"  âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ")
            return None

        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ì˜¤ë””ì˜¤ ê¸°ì¤€ìœ¼ë¡œ ì˜ìƒ ê¸¸ì´ ê²°ì •)
        audio_duration = self._get_duration(audio_file)
        if not audio_duration:
            print(f"  âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ë¶ˆê°€, ê¸°ë³¸ê°’ ì‚¬ìš©")
            audio_duration = 30.0

        # íŒ¨ë”© í¬í•¨ ì´ ê¸¸ì´ ê³„ì‚°
        total_duration = audio_duration + end_padding

        print(f"  ğŸ“¹ Manim: {manim_file.name}")
        print(f"  ğŸµ Audio: {audio_file.name} ({audio_duration:.2f}ì´ˆ + {end_padding}ì´ˆ íŒ¨ë”©)")
        if bg_file:
            print(f"  ğŸ–¼ï¸  Background: {bg_file.name}")
        if subtitle_file and subtitle_file.exists():
            print(f"  ğŸ“ Subtitle: {subtitle_file.name}")

        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_file = final_path / f"{scene_id}_final.mp4"

        # ìë§‰ í•„í„° ì¤€ë¹„ (ë¬¸ì¥ ë‹¨ìœ„, í™”ë©´ ë§¨ ì•„ë˜ ë°°ì¹˜)
        # MarginV=15: í™”ë©´ ì•„ë˜ ì—¬ìœ 
        # MarginL/R=20: ì¢Œìš° ì—¬ë°±
        # FontSize=20: ê°€ë…ì„± í™•ë³´
        subtitle_filter_part = ""
        if with_subtitle and subtitle_file and subtitle_file.exists():
            srt_path = str(subtitle_file).replace("\\", "/").replace(":", "\\:")
            subtitle_filter_part = (
                f",subtitles='{srt_path}':"
                f"force_style='FontName=Malgun Gothic,FontSize=20,"
                f"PrimaryColour=&HFFFFFF,OutlineColour=&H000000,"
                f"Outline=2,Shadow=1,MarginV=15,MarginL=20,MarginR=20'"
            )

        # FFmpeg í•©ì„± ëª…ë ¹ êµ¬ì„± (ë°°ê²½ + Manim + ì˜¤ë””ì˜¤ + ìë§‰ í•œ ë²ˆì—)
        # eof_action=repeat: Manim ì˜ìƒ ëë‚˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
        # apad: ì˜¤ë””ì˜¤ ëì— ë¬´ìŒ íŒ¨ë”© ì¶”ê°€ (ì”¬ ê°„ ì—¬ìœ )
        if bg_file:
            # ë°°ê²½ + Manim ì˜¤ë²„ë ˆì´ + ìë§‰
            # subtitles í•„í„°ëŠ” overlay í›„ ë³„ë„ ì²´ì¸ìœ¼ë¡œ ì ìš©
            if with_subtitle and subtitle_file and subtitle_file.exists():
                srt_path_fc = str(subtitle_file).replace("\\", "/").replace(":", "\\:")
                filter_complex = (
                    f"[0:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                    f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2[bg];"
                    f"[1:v]scale=1920:1080:force_original_aspect_ratio=decrease,format=rgba[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2:eof_action=repeat[ov];"
                    f"[ov]subtitles='{srt_path_fc}':"
                    f"force_style='FontName=Malgun Gothic,FontSize=20,"
                    f"PrimaryColour=&HFFFFFF,OutlineColour=&H000000,"
                    f"Outline=2,Shadow=1,MarginV=15,MarginL=20,MarginR=20'[outv];"
                    f"[2:a]apad=pad_dur={end_padding}[outa]"
                )
            else:
                filter_complex = (
                    f"[0:v]scale=1920:1080:force_original_aspect_ratio=decrease,"
                    f"pad=1920:1080:(ow-iw)/2:(oh-ih)/2[bg];"
                    f"[1:v]scale=1920:1080:force_original_aspect_ratio=decrease,format=rgba[fg];"
                    f"[bg][fg]overlay=(W-w)/2:(H-h)/2:eof_action=repeat[outv];"
                    f"[2:a]apad=pad_dur={end_padding}[outa]"
                )

            cmd = [
                self.ffmpeg_path,
                "-loop", "1", "-i", str(bg_file),
                "-i", str(manim_file),
                "-i", str(audio_file),
                "-filter_complex", filter_complex,
                "-map", "[outv]", "-map", "[outa]",
                "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                "-c:a", "aac", "-b:a", "192k",
                "-t", str(total_duration),
                "-y", str(output_file)
            ]
        else:
            # Manimë§Œ ì‚¬ìš© (ë°°ê²½ ì—†ìŒ) + ìë§‰
            # tpad: Manim ëë‚˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
            video_filter = f"scale=1920:1080,tpad=stop_mode=clone:stop_duration={total_duration}{subtitle_filter_part}"
            cmd = [
                self.ffmpeg_path,
                "-i", str(manim_file),
                "-i", str(audio_file),
                "-vf", video_filter,
                "-af", f"apad=pad_dur={end_padding}",
                "-c:v", "libx264", "-preset", "fast", "-crf", "23",
                "-c:a", "aac", "-b:a", "192k",
                "-t", str(total_duration),
                "-y", str(output_file)
            ]

        # í•©ì„± ì‹¤í–‰
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"  âŒ í•©ì„± ì‹¤íŒ¨: {result.stderr[:200]}")
            return None

        if with_subtitle and subtitle_file and subtitle_file.exists():
            print(f"  âœ… ìë§‰ í¬í•¨ í•©ì„± ì™„ë£Œ")

        print(f"  âœ… í•©ì„± ì™„ë£Œ: {output_file.name}")
        return output_file

    def compose_all(self, with_subtitle: bool = True) -> List[Path]:
        """ëª¨ë“  ì”¬ í•©ì„±"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # scenes.jsonì—ì„œ ì”¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        scenes_file = paths["scenes"] / "scenes.json"
        if not scenes_file.exists():
            print("âŒ scenes.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes = json.load(f)

        scene_ids = [s["scene_id"] for s in scenes]

        print(f"\nğŸ¬ ì „ì²´ ì”¬ í•©ì„± ì‹œì‘ ({len(scene_ids)}ê°œ)")
        print("=" * 50)

        composed = []
        failed = []

        for i, scene_id in enumerate(scene_ids, 1):
            print(f"\n[{i}/{len(scene_ids)}] {scene_id}")

            result = self.compose_scene(scene_id, with_subtitle=with_subtitle)

            if result:
                composed.append(result)
            else:
                failed.append(scene_id)

        print("\n" + "=" * 50)
        print(f"âœ… í•©ì„± ì™„ë£Œ: {len(composed)}ê°œ")
        if failed:
            print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ ({', '.join(failed)})")

        return composed

    def transition_generate(self) -> bool:
        """ì„¹ì…˜ ì „í™˜ í´ë¦½ ìƒì„± + concat_list.txt ìƒì„±"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # transitions.json ì½ê¸°
        transitions_file = paths["scenes"] / "transitions.json"
        if not transitions_file.exists():
            print("âš ï¸ transitions.jsonì´ ì—†ìŠµë‹ˆë‹¤. ì „í™˜ í´ë¦½ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
            # concat_list.txtë§Œ ìƒì„±
            return self._generate_concat_list(paths, [])

        with open(transitions_file, 'r', encoding='utf-8') as f:
            transitions = json.load(f)

        if not transitions:
            print("âš ï¸ ì „í™˜ í´ë¦½ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return self._generate_concat_list(paths, [])

        print(f"\nğŸ¬ ì „í™˜ í´ë¦½ ìƒì„± ({len(transitions)}ê°œ)")

        # ìŠ¤íƒ€ì¼ë³„ ìƒ‰ìƒ ì„¤ì •
        style = self.state.get("settings.style", "cyberpunk")
        style_colors = {
            "minimal": {"bg": "black", "text": "white"},
            "cyberpunk": {"bg": "#0a0a1a", "text": "#00ffff"},
            "paper": {"bg": "#2a2a2a", "text": "#f5f5dc"},
            "space": {"bg": "#000022", "text": "#4444ff"},
            "geometric": {"bg": "#1a1a1a", "text": "#ffd700"},
            "stickman": {"bg": "#1a1a2e", "text": "#ffffff"},
        }
        colors = style_colors.get(style, style_colors["cyberpunk"])

        # í•´ìƒë„ ì„¤ì •
        aspect = self.state.get("settings.aspect_ratio", "16:9")
        if aspect == "16:9":
            width, height = 1920, 1080
        else:  # 9:16
            width, height = 1080, 1920

        final_path = paths["final"]
        final_path.mkdir(parents=True, exist_ok=True)

        created_transitions = []

        for t in transitions:
            scene_id = t["after_scene"]
            text = t["text"]
            duration = t.get("duration", 2)

            output_file = final_path / f"t_after_{scene_id}.mp4"
            print(f"  {scene_id} ë’¤ ì „í™˜: \"{text}\"")

            # Windowsìš© í°íŠ¸ ê²½ë¡œ
            font_path = "C\\:/Windows/Fonts/malgun.ttf"

            # í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            escaped_text = text.replace("'", "\\'").replace(":", "\\:")

            # ë¹„ë””ì˜¤ í•„í„°: í…ìŠ¤íŠ¸ + í˜ì´ë“œì¸/ì•„ì›ƒ
            # fade=in:0:12 (0.5ì´ˆ = 12í”„ë ˆì„ @24fps), fade=out:36:12 (1.5ì´ˆ ì§€ì ë¶€í„°)
            fade_frames = 12  # 0.5ì´ˆ at 24fps
            total_frames = int(duration * 24)
            fade_out_start = total_frames - fade_frames

            vf_filter = (
                f"drawtext=text='{escaped_text}':"
                f"fontfile='{font_path}':"
                f"fontsize=56:"
                f"fontcolor={colors['text']}:"
                f"x=(w-text_w)/2:y=(h-text_h)/2,"
                f"fade=t=in:st=0:d=0.5,"
                f"fade=t=out:st={duration - 0.5}:d=0.5"
            )

            cmd = [
                self.ffmpeg_path,
                "-f", "lavfi",
                "-i", f"color=c={colors['bg']}:s={width}x{height}:d={duration}:r=24",
                "-f", "lavfi",
                "-i", f"anullsrc=r=44100:cl=stereo",
                "-t", str(duration),
                "-vf", vf_filter,
                "-c:v", "libx264",
                "-preset", "fast",
                "-crf", "23",
                "-c:a", "aac",
                "-b:a", "128k",
                "-pix_fmt", "yuv420p",
                "-y", str(output_file)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')

            if result.returncode == 0 and output_file.exists():
                print(f"    âœ… ìƒì„±: {output_file.name}")
                created_transitions.append(scene_id)
            else:
                print(f"    âŒ ì‹¤íŒ¨: {result.stderr[:200] if result.stderr else 'Unknown error'}")

        # concat_list.txt ìƒì„±
        success = self._generate_concat_list(paths, created_transitions)

        print(f"\nâœ… ì „í™˜ í´ë¦½ ìƒì„± ì™„ë£Œ: {len(created_transitions)}ê°œ")
        return success

    def _generate_concat_list(self, paths: Dict[str, Path], transition_scenes: List[str]) -> bool:
        """concat_list.txt ìƒì„± (ì „í™˜ í´ë¦½ í¬í•¨)"""
        final_path = paths["final"]
        scenes_file = paths["scenes"] / "scenes.json"

        if not scenes_file.exists():
            print("âŒ scenes.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        with open(scenes_file, 'r', encoding='utf-8') as f:
            scenes = json.load(f)

        scene_ids = [s["scene_id"] for s in scenes]
        transition_set = set(transition_scenes)

        concat_lines = []
        for scene_id in scene_ids:
            scene_file = final_path / f"{scene_id}_final.mp4"
            if scene_file.exists():
                concat_lines.append(f"file '{scene_id}_final.mp4'")

                # ì´ ì”¬ ë’¤ì— ì „í™˜ í´ë¦½ì´ ìˆëŠ”ì§€ í™•ì¸
                if scene_id in transition_set:
                    transition_file = final_path / f"t_after_{scene_id}.mp4"
                    if transition_file.exists():
                        concat_lines.append(f"file 't_after_{scene_id}.mp4'")

        # subscribe.mp4ê°€ ìˆìœ¼ë©´ ë§¨ ëì— ì¶”ê°€
        subscribe_file = Path(__file__).parent / "subscribe.mp4"
        if subscribe_file.exists():
            concat_lines.append(f"file '{subscribe_file.resolve()}'")
            print("ğŸ”” subscribe.mp4 ì¶”ê°€ë¨ (ì˜ìƒ ë)")

        concat_file = final_path / "concat_list.txt"
        with open(concat_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(concat_lines))

        print(f"ğŸ“ concat_list.txt ìƒì„±: {len(concat_lines)}ê°œ í•­ëª©")
        return True

    def _merge_with_filter_complex(self, video_files: List[str], output_file: Path, work_dir: Path) -> subprocess.CompletedProcess:
        """filter_complexë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ë³‘í•© (ì „í™˜ í´ë¦½ í¬í•¨ ì‹œ)"""
        # ì…ë ¥ íŒŒì¼ ì¸ì êµ¬ì„± (work_dir ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ)
        input_args = []
        for vf in video_files:
            input_args.extend(["-i", vf])

        # filter_complex êµ¬ì„±
        n = len(video_files)
        filter_parts = []
        for i in range(n):
            filter_parts.append(f"[{i}:v][{i}:a]")
        filter_str = "".join(filter_parts) + f"concat=n={n}:v=1:a=1[outv][outa]"

        # ì¶œë ¥ íŒŒì¼ì„ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        output_abs = output_file.resolve() if hasattr(output_file, 'resolve') else Path(output_file).resolve()

        cmd = [
            self.ffmpeg_path,
            *input_args,
            "-filter_complex", filter_str,
            "-map", "[outv]",
            "-map", "[outa]",
            "-c:v", "libx264",
            "-preset", "fast",
            "-crf", "23",
            "-c:a", "aac",
            "-b:a", "128k",
            "-y", str(output_abs)
        ]

        return subprocess.run(cmd, capture_output=True, text=True, cwd=str(work_dir))

    def _merge_in_batches(self, video_files: List[str], output_file: Path, work_dir: Path) -> subprocess.CompletedProcess:
        """íŒŒì¼ì´ ë§ì„ ë•Œ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ë³‘í•©"""
        batch_size = 15  # FFmpeg ì…ë ¥ ì œí•œ ê³ ë ¤
        temp_files = []

        # ë°°ì¹˜ë³„ë¡œ ì„ì‹œ íŒŒì¼ ìƒì„±
        for i in range(0, len(video_files), batch_size):
            batch = video_files[i:i + batch_size]
            batch_num = i // batch_size + 1
            temp_output = work_dir / f"_temp_batch_{batch_num}.mp4"
            temp_files.append(temp_output)

            print(f"    ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ({len(batch)}ê°œ)...")
            result = self._merge_with_filter_complex(batch, temp_output, work_dir)
            if result.returncode != 0:
                # ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
                for tf in temp_files:
                    if tf.exists():
                        tf.unlink()
                return result

        # ì„ì‹œ íŒŒì¼ë“¤ì„ ìµœì¢… ë³‘í•©
        if len(temp_files) == 1:
            # ë°°ì¹˜ê°€ í•˜ë‚˜ë©´ ê·¸ëƒ¥ ì´ë¦„ ë³€ê²½
            temp_files[0].rename(output_file)
            result = subprocess.CompletedProcess(args=[], returncode=0)
        else:
            print(f"    ìµœì¢… ë³‘í•© ({len(temp_files)}ê°œ ë°°ì¹˜)...")
            temp_names = [tf.name for tf in temp_files]
            result = self._merge_with_filter_complex(temp_names, output_file, work_dir)

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for tf in temp_files:
            if tf.exists():
                tf.unlink()

        return result

    def merge_final(self) -> Optional[Path]:
        """ëª¨ë“  ì”¬ì„ í•˜ë‚˜ì˜ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©"""
        paths = self._get_project_paths()
        if not paths:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        final_path = paths["final"]

        # concat_list.txtê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš© (ì „í™˜ í´ë¦½ í¬í•¨)
        concat_list_file = final_path / "concat_list.txt"
        if concat_list_file.exists():
            print("ğŸ“ concat_list.txt ì‚¬ìš© (ì „í™˜ í´ë¦½ í¬í•¨)")
            concat_file = concat_list_file
            # íŒŒì¼ ê°œìˆ˜ í™•ì¸
            with open(concat_file, 'r', encoding='utf-8') as f:
                lines = [l for l in f.readlines() if l.strip()]
            print(f"\nğŸ¬ ìµœì¢… ì˜ìƒ ë³‘í•© ({len(lines)}ê°œ í´ë¦½)")
        else:
            # ê¸°ì¡´ ë°©ì‹: scenes.jsonì—ì„œ ìˆœì„œ ê°€ì ¸ì˜¤ê¸°
            scene_files = []
            scenes_file = paths["scenes"] / "scenes.json"
            if scenes_file.exists():
                with open(scenes_file, 'r', encoding='utf-8') as f:
                    scenes = json.load(f)
                scene_ids = [s["scene_id"] for s in scenes]
            else:
                # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
                all_files = list(final_path.glob("*_final*.mp4"))
                scene_ids = sorted(set(f.stem.split("_")[0] for f in all_files),
                                 key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)

            for scene_id in scene_ids:
                scene_file = final_path / f"{scene_id}_final.mp4"
                if scene_file.exists():
                    scene_files.append(scene_file)

            if not scene_files:
                print("âŒ í•©ì„±ëœ ì”¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("   ë¨¼ì € compose-allì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                return None

            print(f"\nğŸ¬ ìµœì¢… ì˜ìƒ ë³‘í•© ({len(scene_files)}ê°œ ì”¬)")

            # concat íŒŒì¼ ìƒì„±
            concat_file = final_path / "final_concat.txt"
            with open(concat_file, 'w', encoding='utf-8') as f:
                for video in scene_files:
                    f.write(f"file '{video.name}'\n")

        # ì¶œë ¥ íŒŒì¼ (ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
        output_file = (paths["base"] / "final_video.mp4").resolve()

        # FFmpeg ë³‘í•©
        # concat_list.txtì—ì„œ íŒŒì¼ ëª©ë¡ ì½ê¸°
        with open(concat_file, 'r', encoding='utf-8') as f:
            video_files = [line.strip().replace("file '", "").replace("'", "")
                          for line in f.readlines() if line.strip()]

        has_transitions = any('t_after_' in f for f in video_files)

        if has_transitions:
            # filter_complex ë°©ì‹ ì‚¬ìš© (ì „í™˜ í´ë¦½ í¬í•¨ ì‹œ)
            print("  ë³‘í•© ì¤‘ (filter_complex)...")
            # ëª¨ë“  íŒŒì¼ì„ í•œë²ˆì— ì²˜ë¦¬ (FFmpegëŠ” ë§ì€ ì…ë ¥ ì²˜ë¦¬ ê°€ëŠ¥)
            result = self._merge_with_filter_complex(video_files, output_file, final_path)
        else:
            # ì „í™˜ ì—†ìœ¼ë©´ ë¹ ë¥¸ concat demuxer ì‚¬ìš©
            concat_file_relative = concat_file.name
            cmd = [
                self.ffmpeg_path,
                "-f", "concat",
                "-safe", "0",
                "-i", concat_file_relative,
                "-c", "copy",
                "-y", str(output_file)
            ]
            print("  ë³‘í•© ì¤‘...")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(final_path))

        if result.returncode != 0 or not output_file.exists():
            print(f"  âŒ ë³‘í•© ì‹¤íŒ¨")
            if result.stderr:
                # FFmpeg ë²„ì „ ì •ë³´ê°€ ì•„ë‹Œ ì‹¤ì œ ì˜¤ë¥˜ë§Œ ì¶œë ¥
                error_lines = [l for l in result.stderr.split('\n') if 'error' in l.lower() or 'Error' in l]
                if error_lines:
                    print(f"     {error_lines[0][:200]}")
            return None

        # íŒŒì¼ ì •ë³´ ì¶œë ¥
        probe_cmd = [
            self.ffprobe_path,
            "-v", "error",
            "-show_entries", "format=duration,size",
            "-of", "json",
            str(output_file)
        ]

        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)

        if probe_result.returncode == 0:
            info = json.loads(probe_result.stdout)
            duration = float(info.get("format", {}).get("duration", 0))
            size = int(info.get("format", {}).get("size", 0))

            mins = int(duration // 60)
            secs = int(duration % 60)
            size_mb = size / (1024 * 1024)

            print(f"\nâœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ!")
            print(f"   ğŸ“ íŒŒì¼: {output_file}")
            print(f"   â±ï¸  ê¸¸ì´: {mins}ë¶„ {secs}ì´ˆ")
            print(f"   ğŸ’¾ í¬ê¸°: {size_mb:.1f} MB")
        else:
            print(f"\nâœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_file}")

        # state.json ì—…ë°ì´íŠ¸
        self.state.set("current_phase", "completed")
        self.state.set("files.final_video", str(output_file))
        self.state.save()

        return output_file


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def convert_to_tts_text(text: str) -> str:
    """
    ì½ê¸°ìš© í…ìŠ¤íŠ¸ë¥¼ TTSìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    (ìˆ«ì/ê¸°í˜¸ â†’ í•œê¸€ ë°œìŒ)
    """
    
    # ë³€í™˜ ê·œì¹™
    conversions = [
        # ì—°ì‚°ì
        (r'Ã—', ' ê³±í•˜ê¸° '),
        (r'\*', ' ê³±í•˜ê¸° '),
        (r'Ã·', ' ë‚˜ëˆ„ê¸° '),
        (r'/', ' ë‚˜ëˆ„ê¸° '),
        (r'\+', ' í”ŒëŸ¬ìŠ¤ '),
        (r'(?<!\w)-(?!\w)', ' ë§ˆì´ë„ˆìŠ¤ '),  # ë‹¨ë… ë§ˆì´ë„ˆìŠ¤ë§Œ
        (r'=', 'ëŠ” '),
        
        # ìˆ˜í•™ ê¸°í˜¸
        (r'âˆš', 'ë£¨íŠ¸ '),
        (r'Â²', ' ì œê³±'),
        (r'Â³', ' ì„¸ì œê³±'),
        (r'âˆ«', 'ì ë¶„ '),
        (r'Î£', 'ì‹œê·¸ë§ˆ '),
        (r'âˆ', 'ë¬´í•œëŒ€'),
        (r'Ï€', 'íŒŒì´'),
        (r'Î¸', 'ì„¸íƒ€'),
        (r'Î±', 'ì•ŒíŒŒ'),
        (r'Î²', 'ë² íƒ€'),
        (r'Î³', 'ê°ë§ˆ'),
        (r'Î”', 'ë¸íƒ€'),
        
        # í•¨ìˆ˜ í‘œê¸°
        (r'f\(x\)', 'ì—í”„ì—‘ìŠ¤'),
        (r'g\(x\)', 'ì§€ì—‘ìŠ¤'),
        (r'h\(x\)', 'ì—ì´ì¹˜ì—‘ìŠ¤'),
        (r'dy/dx', 'ë””ì™€ì´ ë””ì—‘ìŠ¤'),
        (r'd/dx', 'ë”” ë””ì—‘ìŠ¤'),
        (r'dx', 'ë””ì—‘ìŠ¤'),
        (r'dy', 'ë””ì™€ì´'),
        (r'lim', 'ê·¹í•œê°’ '),
        (r'sin', 'ì‚¬ì¸ '),
        (r'cos', 'ì½”ì‚¬ì¸ '),
        (r'tan', 'íƒ„ì  íŠ¸ '),
        (r'log', 'ë¡œê·¸ '),
        (r'ln', 'ìì—°ë¡œê·¸ '),
        
        # ë‹¨ìœ„
        (r'cmÂ²', 'ì œê³±ì„¼í‹°ë¯¸í„°'),
        (r'cm', 'ì„¼í‹°ë¯¸í„°'),
        (r'mÂ²', 'ì œê³±ë¯¸í„°'),
        (r'km', 'í‚¬ë¡œë¯¸í„°'),
        (r'kg', 'í‚¬ë¡œê·¸ë¨'),
        
        # ìˆ«ì (ë‘ ìë¦¬ ì´ìƒì€ ê·¸ëŒ€ë¡œ)
        (r'\b0\b', 'ì˜'),
        (r'\b1\b', 'ì¼'),
        (r'\b2\b', 'ì´'),
        (r'\b3\b', 'ì‚¼'),
        (r'\b4\b', 'ì‚¬'),
        (r'\b5\b', 'ì˜¤'),
        (r'\b6\b', 'ìœ¡'),
        (r'\b7\b', 'ì¹ '),
        (r'\b8\b', 'íŒ”'),
        (r'\b9\b', 'êµ¬'),
        (r'\b10\b', 'ì‹­'),
    ]
    
    result = text
    for pattern, replacement in conversions:
        result = re.sub(pattern, replacement, result)
    
    # ì—°ì† ê³µë°± ì œê±°
    result = re.sub(r'\s+', ' ', result)
    
    return result.strip()


# ============================================================================
# ValidatorManager - visual.json ê²€ì¦
# ============================================================================

class ValidatorManager:
    """Visual JSON ê²€ì¦ ë§¤ë‹ˆì € (visual-review.md ê¸°ë°˜)"""

    # Manim ìƒ‰ìƒ ìƒìˆ˜ ëª©ë¡
    VALID_COLORS = {
        "WHITE", "BLACK", "GRAY", "GRAY_A", "GRAY_B", "GRAY_C", "GRAY_D", "GRAY_E",
        "RED", "RED_A", "RED_B", "RED_C", "RED_D", "RED_E",
        "GREEN", "GREEN_A", "GREEN_B", "GREEN_C", "GREEN_D", "GREEN_E",
        "BLUE", "BLUE_A", "BLUE_B", "BLUE_C", "BLUE_D", "BLUE_E",
        "YELLOW", "YELLOW_A", "YELLOW_B", "YELLOW_C", "YELLOW_D", "YELLOW_E",
        "ORANGE", "PINK", "PURPLE", "TEAL", "GOLD", "MAROON",
        "CYAN", "MAGENTA", "LIGHT_GRAY", "DARK_GRAY", "LIGHT_BROWN", "DARK_BROWN"
    }

    # íƒ€ì…ë³„ í•„ìˆ˜ í•„ë“œ
    TYPE_REQUIRED_FIELDS = {
        "ImageMobject": ["source", "size"],
        "SVGMobject": ["source", "size"],
        "Text": ["content", "font_size", "color"],
        "MathTex": ["content", "font_size", "color"],
        "Rectangle": ["width", "height"],
        "Circle": ["radius"],
        "Arrow": ["start", "end"],
        "Axes": ["x_range", "y_range", "x_length", "y_length"],
    }

    # position methodë³„ í•„ìˆ˜ í•„ë“œ
    POSITION_REQUIRED_FIELDS = {
        "shift": ["x", "y"],
        "to_edge": ["edge"],
        "to_corner": ["corner"],
        "next_to": ["reference", "direction"],
        "move_to": ["reference"],
    }

    def __init__(self, state: StateManager):
        self.state = state
        self.project_id = state.get("project_id")
        self.output_dir = Path(f"output/{self.project_id}")
        self.visual_dir = self.output_dir / "3_visual_prompts"
        self.errors = []
        self.warnings = []
        self.auto_fixed = []

    def validate_all(self, auto_fix: bool = True):
        """ëª¨ë“  visual.json íŒŒì¼ ê²€ì¦"""
        if not self.project_id:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        if not self.visual_dir.exists():
            print(f"âŒ visual_prompts í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {self.visual_dir}")
            return

        # visual íŒŒì¼ ëª©ë¡
        visual_files = sorted(self.visual_dir.glob("s*_visual.json"))
        if not visual_files:
            print("âŒ ê²€ì¦í•  visual.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nğŸ” Visual JSON ê²€ì¦ ì‹œì‘ ({len(visual_files)}ê°œ íŒŒì¼)")
        print("=" * 60)

        total_errors = 0
        total_warnings = 0
        total_fixed = 0
        failed_scenes = []

        for vf in visual_files:
            scene_id = vf.stem.replace("_visual", "")
            self.errors = []
            self.warnings = []
            self.auto_fixed = []

            try:
                with open(vf, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # ê²€ì¦ ìˆ˜í–‰
                self._validate_structure(data)
                self._validate_objects(data)
                self._validate_sequence(data)
                self._validate_3d(data)
                self._validate_timing(data)

                # ìë™ ìˆ˜ì •
                if auto_fix and (self.auto_fixed or self._needs_auto_fix(data)):
                    data = self._apply_auto_fixes(data)
                    with open(vf, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)

                # ê²°ê³¼ ì¶œë ¥
                if self.errors:
                    print(f"âŒ {scene_id}: {len(self.errors)} ì˜¤ë¥˜, {len(self.warnings)} ê²½ê³ ")
                    for e in self.errors[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"   - [ERROR] {e}")
                    if len(self.errors) > 3:
                        print(f"   ... ì™¸ {len(self.errors) - 3}ê°œ ì˜¤ë¥˜")
                    failed_scenes.append(scene_id)
                elif self.warnings:
                    print(f"âš ï¸  {scene_id}: {len(self.warnings)} ê²½ê³ ")
                    for w in self.warnings[:2]:
                        print(f"   - [WARN] {w}")
                else:
                    print(f"âœ… {scene_id}: í†µê³¼")

                if self.auto_fixed:
                    print(f"   ğŸ”§ ìë™ ìˆ˜ì •: {len(self.auto_fixed)}ê°œ")
                    total_fixed += len(self.auto_fixed)

                total_errors += len(self.errors)
                total_warnings += len(self.warnings)

            except json.JSONDecodeError as e:
                print(f"âŒ {scene_id}: JSON íŒŒì‹± ì˜¤ë¥˜ - {e}")
                total_errors += 1
                failed_scenes.append(scene_id)
            except Exception as e:
                print(f"âŒ {scene_id}: ê²€ì¦ ì˜¤ë¥˜ - {e}")
                total_errors += 1
                failed_scenes.append(scene_id)

        # ìµœì¢… ìš”ì•½
        print("\n" + "=" * 60)
        if total_errors == 0:
            print(f"âœ… ê²€ì¦ ì™„ë£Œ: ëª¨ë“  {len(visual_files)}ê°œ íŒŒì¼ í†µê³¼")
        else:
            print(f"âŒ ê²€ì¦ ê²°ê³¼: {total_errors} ì˜¤ë¥˜, {total_warnings} ê²½ê³ ")
            print(f"   ì‹¤íŒ¨ ì”¬: {', '.join(failed_scenes)}")

        if total_fixed > 0:
            print(f"ğŸ”§ ìë™ ìˆ˜ì •: ì´ {total_fixed}ê°œ í•­ëª©")

        return total_errors == 0

    def _validate_structure(self, data: dict):
        """êµ¬ì¡° ê²€ì¦ - í•„ìˆ˜ ìµœìƒìœ„ í•„ë“œ"""
        required_fields = [
            "scene_id", "is_3d", "scene_class", "style",
            "total_duration", "canvas", "objects", "sequence"
        ]

        for field in required_fields:
            if field not in data:
                self.errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")

        # canvas ê²€ì¦
        if "canvas" in data:
            canvas = data["canvas"]
            if "background" not in canvas:
                self.warnings.append("canvas.background ëˆ„ë½")
            if "safe_margin" not in canvas:
                self.warnings.append("canvas.safe_margin ëˆ„ë½")

        # ë°°ì—´ íƒ€ì… í™•ì¸
        if "objects" in data and not isinstance(data["objects"], list):
            self.errors.append("objectsëŠ” ë°°ì—´ì´ì–´ì•¼ í•¨")

        if "sequence" in data and not isinstance(data["sequence"], list):
            self.errors.append("sequenceëŠ” ë°°ì—´ì´ì–´ì•¼ í•¨")

    def _validate_objects(self, data: dict):
        """objects ê²€ì¦"""
        objects = data.get("objects", [])
        ids_seen = set()

        for i, obj in enumerate(objects):
            obj_id = obj.get("id", f"[index {i}]")

            # id ê²€ì¦
            if "id" not in obj:
                self.errors.append(f"objects[{i}]: id ëˆ„ë½")
            elif obj["id"] in ids_seen:
                self.errors.append(f"objects[{i}]: id '{obj['id']}' ì¤‘ë³µ")
            else:
                ids_seen.add(obj["id"])

            # type ê²€ì¦
            if "type" not in obj:
                self.errors.append(f"{obj_id}: type ëˆ„ë½")

            # position ê²€ì¦
            if "position" not in obj:
                self.warnings.append(f"{obj_id}: position ëˆ„ë½")
            else:
                self._validate_position(obj_id, obj["position"])

            # íƒ€ì…ë³„ í•„ìˆ˜ í•„ë“œ
            obj_type = obj.get("type", "")
            if obj_type in self.TYPE_REQUIRED_FIELDS:
                for field in self.TYPE_REQUIRED_FIELDS[obj_type]:
                    # sizeëŠ” height ë˜ëŠ” widthë¡œ ëŒ€ì²´ ê°€ëŠ¥
                    if field == "size":
                        if "size" not in obj and "height" not in obj.get("size", {}):
                            if not obj.get("size"):
                                self.warnings.append(f"{obj_id}: size ëˆ„ë½")
                    elif field not in obj:
                        self.warnings.append(f"{obj_id}: {field} ëˆ„ë½ ({obj_type} í•„ìˆ˜)")

            # í•œê¸€ í…ìŠ¤íŠ¸ í°íŠ¸ ê²€ì¦
            if obj_type == "Text":
                content = obj.get("content", "")
                if any('\uac00' <= c <= '\ud7a3' for c in content):  # í•œê¸€ í¬í•¨
                    font = obj.get("font", "")
                    if "Noto Sans KR" not in font and "NanumGothic" not in font:
                        self.warnings.append(f"{obj_id}: í•œê¸€ í…ìŠ¤íŠ¸ì— font='Noto Sans KR' ê¶Œì¥")

            # ì—ì…‹ ê²½ë¡œ ê²€ì¦
            if "source" in obj:
                source = obj["source"]
                if not source.startswith("assets/"):
                    self.errors.append(f"{obj_id}: sourceëŠ” 'assets/'ë¡œ ì‹œì‘í•´ì•¼ í•¨")
                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                asset_path = Path(source)
                if not asset_path.exists():
                    self.warnings.append(f"{obj_id}: ì—ì…‹ íŒŒì¼ ì—†ìŒ: {source}")

            # ìƒ‰ìƒ ê²€ì¦
            color = obj.get("color", "")
            if color and not color.startswith("#"):  # í—¥ìŠ¤ ì½”ë“œê°€ ì•„ë‹Œ ê²½ìš°
                if color not in self.VALID_COLORS:
                    self.warnings.append(f"{obj_id}: ì•Œ ìˆ˜ ì—†ëŠ” ìƒ‰ìƒ '{color}'")

    def _validate_position(self, obj_id: str, position: dict):
        """position ê²€ì¦"""
        method = position.get("method", "shift")

        # methodë³„ í•„ìˆ˜ í•„ë“œ
        if method in self.POSITION_REQUIRED_FIELDS:
            for field in self.POSITION_REQUIRED_FIELDS[method]:
                if field not in position:
                    self.warnings.append(f"{obj_id}: position.{field} ëˆ„ë½ (method: {method})")

        # ì„¸ì´í”„ì¡´ ê²€ì¦
        x = position.get("x", 0)
        y = position.get("y", 0)

        if abs(x) > 6.6:
            self.warnings.append(f"{obj_id}: x={x} í™”ë©´ ë°– (ê¶Œì¥: -6.6 ~ 6.6)")
            self.auto_fixed.append((obj_id, "x", max(-6.5, min(6.5, x))))

        if y < -2.5:
            self.warnings.append(f"{obj_id}: y={y} ìë§‰ ì˜ì—­ ì¹¨ë²” (ê¶Œì¥: y >= -2.5)")
            self.auto_fixed.append((obj_id, "y", -2.3))
        elif y > 3.5:
            self.warnings.append(f"{obj_id}: y={y} í™”ë©´ ë°– (ê¶Œì¥: y <= 3.5)")
            self.auto_fixed.append((obj_id, "y", 3.3))

    def _validate_sequence(self, data: dict):
        """sequence ê²€ì¦"""
        sequence = data.get("sequence", [])
        objects_ids = {obj.get("id") for obj in data.get("objects", [])}

        prev_end = 0
        for i, step in enumerate(sequence):
            step_num = step.get("step", i + 1)

            # í•„ìˆ˜ í•„ë“œ
            if "step" not in step:
                self.warnings.append(f"sequence[{i}]: step ë²ˆí˜¸ ëˆ„ë½")

            if "time_range" not in step:
                self.errors.append(f"step {step_num}: time_range ëˆ„ë½")
            else:
                tr = step["time_range"]
                if len(tr) != 2:
                    self.errors.append(f"step {step_num}: time_rangeëŠ” [start, end] í˜•ì‹")
                else:
                    start, end = tr

                    # ì‹œê°„ ì—°ì†ì„±
                    if i == 0 and start != 0:
                        self.warnings.append(f"step 1: time_range[0]ì€ 0ì´ì–´ì•¼ í•¨")
                    elif i > 0 and abs(start - prev_end) > 0.01:
                        self.warnings.append(f"step {step_num}: ì‹œê°„ ë¶ˆì—°ì† ({prev_end} â†’ {start})")

                    prev_end = end

            # actions ê²€ì¦
            actions = step.get("actions", [])
            if not actions:
                self.warnings.append(f"step {step_num}: actions ë¹„ì–´ìˆìŒ")

            for j, action in enumerate(actions):
                action_type = action.get("type", "")
                target = action.get("target", "")

                # target ì°¸ì¡° í™•ì¸
                if target and target not in objects_ids:
                    if action_type != "wait":
                        self.errors.append(f"step {step_num}: target '{target}' ë¯¸ì •ì˜")

                # run_time ê²€ì¦
                if "run_time" not in action and action_type != "wait":
                    self.warnings.append(f"step {step_num}: action[{j}] run_time ëˆ„ë½")

                # Transform ê²€ì¦
                if action_type in ["Transform", "ReplacementTransform"]:
                    to_target = action.get("to", "")
                    if not to_target:
                        self.errors.append(f"step {step_num}: {action_type}ì— 'to' í•„ë“œ í•„ìˆ˜")
                    elif to_target not in objects_ids:
                        self.errors.append(f"step {step_num}: Transform to '{to_target}' ë¯¸ì •ì˜")

        # ë§ˆì§€ë§‰ stepê³¼ total_duration ì¼ì¹˜
        total_duration = data.get("total_duration", 0)
        if sequence and prev_end != total_duration:
            diff = abs(prev_end - total_duration)
            if diff > 0.5:
                self.warnings.append(f"sequence ë({prev_end}s)ê³¼ total_duration({total_duration}s) ë¶ˆì¼ì¹˜")

    def _validate_3d(self, data: dict):
        """3D ì”¬ ê²€ì¦"""
        is_3d = data.get("is_3d", False)
        scene_class = data.get("scene_class", "Scene")

        # 3D ê°ì²´ ì¡´ì¬ í™•ì¸
        objects = data.get("objects", [])
        three_d_types = {"Cube", "Cylinder", "Sphere", "Cone", "Surface", "ThreeDAxes"}
        has_3d_objects = any(obj.get("type") in three_d_types for obj in objects)

        if has_3d_objects and not is_3d:
            self.errors.append("3D ê°ì²´ ì‚¬ìš© ì‹œ is_3d: true í•„ìˆ˜")

        if is_3d:
            if scene_class != "ThreeDScene":
                self.errors.append("is_3d: trueì´ë©´ scene_class: 'ThreeDScene' í•„ìˆ˜")

            if "camera" not in data:
                self.warnings.append("3D ì”¬ì—ì„œ camera ì„¤ì • ê¶Œì¥")

            # í…ìŠ¤íŠ¸/ìˆ˜ì‹ fixed_in_frame í™•ì¸
            for obj in objects:
                if obj.get("type") in ["Text", "MathTex"]:
                    if not obj.get("fixed_in_frame", False):
                        self.warnings.append(f"{obj.get('id')}: 3D ì”¬ í…ìŠ¤íŠ¸ì— fixed_in_frame: true ê¶Œì¥")

    def _validate_timing(self, data: dict):
        """íƒ€ì´ë° ê²€ì¦"""
        total_duration = data.get("total_duration", 0)

        if total_duration <= 0:
            self.errors.append("total_durationì€ 0ë³´ë‹¤ ì»¤ì•¼ í•¨")

        # ì”¬ ê¸¸ì´ ê¶Œì¥ ë²”ìœ„ (5~30ì´ˆ)
        if total_duration < 5:
            self.warnings.append(f"ì”¬ ê¸¸ì´ {total_duration}sê°€ ë„ˆë¬´ ì§§ìŒ (ê¶Œì¥: 5ì´ˆ ì´ìƒ)")
        elif total_duration > 30:
            self.warnings.append(f"ì”¬ ê¸¸ì´ {total_duration}sê°€ ë„ˆë¬´ ê¹€ (ê¶Œì¥: 30ì´ˆ ì´í•˜)")

    def _needs_auto_fix(self, data: dict) -> bool:
        """ìë™ ìˆ˜ì • í•„ìš” ì—¬ë¶€"""
        return len(self.auto_fixed) > 0

    def _apply_auto_fixes(self, data: dict) -> dict:
        """ìë™ ìˆ˜ì • ì ìš©"""
        for obj_id, field, value in self.auto_fixed:
            for obj in data.get("objects", []):
                if obj.get("id") == obj_id:
                    if "position" in obj:
                        obj["position"][field] = value

        return data


def print_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    help_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.4                        â•‘
â•‘        Claude Code í†µí•© ë²„ì „ (gpt-4o-mini-tts)                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ ì‚¬ìš©ë²•:
    python math_video_pipeline.py <ëª…ë ¹ì–´> [ì˜µì…˜]

ğŸ“‹ ëª…ë ¹ì–´:

  init          ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
                --title "ì œëª©"     ì˜ìƒ ì œëª© (í•„ìˆ˜)
                --duration 480     ê¸¸ì´(ì´ˆ), ê¸°ë³¸ê°’ 480 (8ë¶„)
                --aspect 16:9      ì¢…íš¡ë¹„ (16:9 / 9:16)
                --style cyberpunk  ìŠ¤íƒ€ì¼ (minimal/cyberpunk/paper/space/geometric/stickman)
                --difficulty intermediate  ë‚œì´ë„ (beginner/intermediate/advanced)
                --voice alloy              TTS ìŒì„± (OpenAI)

  status        í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸

  list          ëª¨ë“  í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ
                output/ í´ë” ë‚´ í”„ë¡œì íŠ¸ ëª©ë¡ê³¼ í¬ê¸° í‘œì‹œ

  delete        í”„ë¡œì íŠ¸ ì‚­ì œ
                <project_id>       ì‚­ì œí•  í”„ë¡œì íŠ¸ ID (í•„ìˆ˜)
                --force, -f        í™•ì¸ ì—†ì´ ì‚­ì œ

  clean         í”„ë¡œì íŠ¸ í´ë” ë‚´ìš© ì •ë¦¬ (í´ë” êµ¬ì¡° ìœ ì§€)
                --project, -p      í”„ë¡œì íŠ¸ ID (ê¸°ë³¸: í˜„ì¬ í”„ë¡œì íŠ¸)
                --folders, -d      ì •ë¦¬í•  í´ë” (ì˜ˆ: 0_audio 8_renders)
                --force, -f        í™•ì¸ ì—†ì´ ì •ë¦¬

  reset         í”„ë¡œì íŠ¸ë¥¼ íŠ¹ì • ë‹¨ê³„ë¡œ ë¦¬ì…‹
                --project, -p      í”„ë¡œì íŠ¸ ID (ê¸°ë³¸: í˜„ì¬ í”„ë¡œì íŠ¸)
                --from             ë¦¬ì…‹ ì‹œì‘ ë‹¨ê³„ (ì˜ˆ: tts_completed)
                --force, -f        í™•ì¸ ì—†ì´ ë¦¬ì…‹

  tts           ë‹¨ì¼ ì”¬ TTS ìƒì„±
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --text "í…ìŠ¤íŠ¸"    ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ (í•„ìˆ˜)

  tts-all       ëª¨ë“  ì”¬ TTS ìƒì„±
                (í…ìŠ¤íŠ¸ ì†ŒìŠ¤: 2_narration/ ìš°ì„ , ì—†ìœ¼ë©´ scenes.json)

  narration-extract  ì”¬ì—ì„œ narration_display ì¶”ì¶œ (Narration Designerìš©)
                     --scenes s1,s2,s3  ì¶”ì¶œí•  ì”¬ ID (ì‰¼í‘œ êµ¬ë¶„, ìƒëµì‹œ ì „ì²´)

  narration-check    ë‚˜ë ˆì´ì…˜ íŒŒì¼ ìƒíƒœ í™•ì¸
                     (ì™„ë£Œ/ë¯¸ì™„ë£Œ ì”¬ ëª©ë¡ í‘œì‹œ)

  prompts-export    ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
                    â†’ 6_image_prompts/prompts_batch.txt

  images-check      ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸
                    â†’ 9_backgrounds/ í´ë”ì˜ ì´ë¯¸ì§€ ê²€ì¦

  images-import     ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°
                    --source "í´ë”ê²½ë¡œ"  ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” (í•„ìˆ˜)

  render        ë‹¨ì¼ ì”¬ ë Œë”ë§
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --quality l        í’ˆì§ˆ (l/m/h/k)
                --no-preview       ë¯¸ë¦¬ë³´ê¸° ì—†ì´ ë Œë”ë§

  render-all    ëª¨ë“  ì”¬ ë Œë”ë§
                --quality l        í’ˆì§ˆ (l/m/h/k)

  render-collect ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘
                media/videos/ì—ì„œ 8_renders/ë¡œ íŒŒì¼ ë³µì‚¬
                state.jsonì— files.renders ì—…ë°ì´íŠ¸

  render-script ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

  subtitle-generate  ëª¨ë“  ì”¬ SRT ìë§‰ ìƒì„±
                     â†’ 7_subtitles/ í´ë”ì— s1.srt, s2.srt, ... ìƒì„±

  compose       ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)
                --scene s1         ì”¬ ID (í•„ìˆ˜)
                --no-subtitle      ìë§‰ ì—†ì´ í•©ì„±

  compose-all   ëª¨ë“  ì”¬ í•©ì„±
                --no-subtitle      ìë§‰ ì—†ì´ í•©ì„±

  merge-final   ëª¨ë“  ì”¬ì„ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©
                â†’ final_video.mp4 ìƒì„±

  convert       í…ìŠ¤íŠ¸ë¥¼ TTSìš©ìœ¼ë¡œ ë³€í™˜
                --text "9Ã—9=81"    ë³€í™˜í•  í…ìŠ¤íŠ¸

  files         í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡

  help          ì´ ë„ì›€ë§ í‘œì‹œ

ğŸ¤ TTS ìŒì„± ì˜µì…˜ (gpt-4o-mini-tts):
  ash        ì°¨ë¶„í•œ ë‚¨ì„± [ê¸°ë³¸ê°’] â­
  onyx       ë‚¨ì„±ì , ê¹Šì€ ëª©ì†Œë¦¬
  echo       ë‚¨ì„±ì , ì°¨ë¶„í•¨
  alloy      ì¤‘ì„±ì , ê· í˜•ì¡íŒ
  coral      ë”°ëœ»í•œ ì—¬ì„±
  nova       ì—¬ì„±ì , ë°ê³  ì¹œê·¼
  marin      ê³ í’ˆì§ˆ ì¶”ì²œ
  cedar      ê³ í’ˆì§ˆ ì¶”ì²œ

  ğŸ’¡ í•œêµ­ì–´ ë°œìŒ ê°œì„  + ì €ë ´í•œ ë¹„ìš© (~$0.015/ë¶„)
  ğŸ§ ìŒì„± ìƒ˜í”Œ: https://platform.openai.com/docs/guides/text-to-speech

ğŸ“– ì˜ˆì‹œ:

  # 1. ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘
  python math_video_pipeline.py init --title "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬" --duration 480

  # 2. Claude Codeì—ì„œ ëŒ€ë³¸ ì‘ì„±
  # "skills/script-writer.md ì½ê³  ëŒ€ë³¸ ì‘ì„±í•´ì¤˜"

  # 3. Claude Codeì—ì„œ ì”¬ ë¶„í• 
  # "skills/scene-director.md ì½ê³  ì”¬ ë¶„í• í•´ì¤˜"

  # 4. ëª¨ë“  ì”¬ TTS ìƒì„±
  python math_video_pipeline.py tts-all

  # 5. Claude Codeì—ì„œ Manim ì½”ë“œ ìƒì„±
  # "skills/manim-coder.md ì½ê³  s1 ì½”ë“œ ìƒì„±í•´ì¤˜"

  # 6. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë‚´ë³´ë‚´ê¸°
  python math_video_pipeline.py prompts-export

  # 7. ì™¸ë¶€ì—ì„œ ì´ë¯¸ì§€ ìƒì„± í›„ ê°€ì ¸ì˜¤ê¸°
  python math_video_pipeline.py images-import --source "C:/Downloads/backgrounds"

  # 8. ì´ë¯¸ì§€ ê²€ì¦
  python math_video_pipeline.py images-check

  # 9. ë Œë”ë§
  python math_video_pipeline.py render-all

  # 10. ìë§‰ ìƒì„±
  python math_video_pipeline.py subtitle-generate

  # 11. ëª¨ë“  ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)
  python math_video_pipeline.py compose-all

  # 12. ìµœì¢… ì˜ìƒ ë³‘í•©
  python math_video_pipeline.py merge-final

ğŸ“ ì¶œë ¥ êµ¬ì¡°:
  output/{project_id}/
  â”œâ”€â”€ 0_audio/          TTS ìŒì„± + íƒ€ì´ë°
  â”œâ”€â”€ 1_script/         ëŒ€ë³¸
  â”œâ”€â”€ 2_scenes/         ì”¬ ë¶„í• 
  â”œâ”€â”€ 4_manim_code/     Manim ì½”ë“œ
  â”œâ”€â”€ 6_image_prompts/  ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
  â”œâ”€â”€ 7_subtitles/      ìë§‰
  â”œâ”€â”€ 8_renders/        Manim ë Œë”ë§ ê²°ê³¼
  â”œâ”€â”€ 9_backgrounds/    ë°°ê²½ ì´ë¯¸ì§€ (ì™¸ë¶€ ìƒì„±)
  â”œâ”€â”€ 10_scene_final/   ì”¬ë³„ í•©ì„± ì˜ìƒ
  â””â”€â”€ final_video.mp4   ìµœì¢… ì˜ìƒ

ğŸ–¼ï¸ ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼ëª… ê·œì¹™:
  s1_bg.png, s2_bg.png, s3_bg.png, ...
  (ì”¬ ID + _bg.png)

ğŸ”„ /clear ê°€ëŠ¥ ì§€ì :
  âœ… ëŒ€ë³¸ ìŠ¹ì¸ í›„ (script_approved)
  âœ… ì”¬ ë¶„í•  í›„ (scenes_approved)
  âœ… TTS ì™„ë£Œ í›„ (tts_completed)
  âœ… ë§¤ 3-5ì”¬ ì½”ë“œ ì™„ë£Œ í›„
  âœ… ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ í›„
  
  ì¬ê°œ: "ê³„ì†" ë˜ëŠ” "ìƒíƒœ" ì…ë ¥
"""
    print(help_text)


# ============================================================================
# CLI ë©”ì¸
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    parser = argparse.ArgumentParser(
        description="ìˆ˜í•™ êµìœ¡ ì˜ìƒ ì œì‘ íŒŒì´í”„ë¼ì¸ v6.1",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")
    
    # init ëª…ë ¹ì–´
    init_parser = subparsers.add_parser("init", help="ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”")
    init_parser.add_argument("--title", "-t", required=True, help="ì˜ìƒ ì œëª©")
    init_parser.add_argument("--duration", "-d", type=int, default=480, help="ì˜ìƒ ê¸¸ì´(ì´ˆ), ê¸°ë³¸ê°’ 480 (8ë¶„)")
    init_parser.add_argument("--style", "-s", default="cyberpunk",
                            choices=["minimal", "cyberpunk", "paper", "space", "geometric", "stickman"],
                            help="ì‹œê° ìŠ¤íƒ€ì¼")
    init_parser.add_argument("--difficulty", default="intermediate",
                            choices=["beginner", "intermediate", "advanced"],
                            help="ë‚œì´ë„")
    init_parser.add_argument("--aspect", default="16:9",
                            choices=["16:9", "9:16"],
                            help="ì¢…íš¡ë¹„")
    init_parser.add_argument("--voice", default="alloy",
                            choices=["ash", "alloy", "ballad", "coral", "echo", "fable", "onyx", "nova", "sage", "shimmer", "verse", "marin", "cedar"],
                            help="TTS ìŒì„± (OpenAI gpt-4o-mini-tts)")
    
    # status ëª…ë ¹ì–´
    subparsers.add_parser("status", help="í˜„ì¬ ìƒíƒœ í™•ì¸")

    # list ëª…ë ¹ì–´ (í”„ë¡œì íŠ¸ ëª©ë¡)
    subparsers.add_parser("list", help="ëª¨ë“  í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ")

    # delete ëª…ë ¹ì–´ (í”„ë¡œì íŠ¸ ì‚­ì œ)
    delete_parser = subparsers.add_parser("delete", help="í”„ë¡œì íŠ¸ ì‚­ì œ")
    delete_parser.add_argument("project_id", help="ì‚­ì œí•  í”„ë¡œì íŠ¸ ID (ì˜ˆ: P20250110_143000)")
    delete_parser.add_argument("--force", "-f", action="store_true", help="í™•ì¸ ì—†ì´ ì‚­ì œ")

    # clean ëª…ë ¹ì–´ (í´ë” ë‚´ìš© ì •ë¦¬)
    clean_parser = subparsers.add_parser("clean", help="í”„ë¡œì íŠ¸ í´ë” ë‚´ìš© ì •ë¦¬ (í´ë” êµ¬ì¡°ëŠ” ìœ ì§€)")
    clean_parser.add_argument("--project", "-p", help="í”„ë¡œì íŠ¸ ID (ê¸°ë³¸: í˜„ì¬ í”„ë¡œì íŠ¸)")
    clean_parser.add_argument("--folders", "-d", nargs="+", help="ì •ë¦¬í•  í´ë” (ì˜ˆ: 0_audio 8_renders)")
    clean_parser.add_argument("--force", "-f", action="store_true", help="í™•ì¸ ì—†ì´ ì •ë¦¬")

    # reset ëª…ë ¹ì–´ (ë‹¨ê³„ ë¦¬ì…‹)
    reset_parser = subparsers.add_parser("reset", help="í”„ë¡œì íŠ¸ë¥¼ íŠ¹ì • ë‹¨ê³„ë¡œ ë¦¬ì…‹")
    reset_parser.add_argument("--project", "-p", help="í”„ë¡œì íŠ¸ ID (ê¸°ë³¸: í˜„ì¬ í”„ë¡œì íŠ¸)")
    reset_parser.add_argument("--from", dest="from_phase", help="ë¦¬ì…‹ ì‹œì‘ ë‹¨ê³„ (ì˜ˆ: tts_completed)")
    reset_parser.add_argument("--force", "-f", action="store_true", help="í™•ì¸ ì—†ì´ ë¦¬ì…‹")

    # verify-sync ëª…ë ¹ì–´ (ëŒ€ë³¸-TTS ë™ê¸°í™” ê²€ì¦)
    verify_sync_parser = subparsers.add_parser("verify-sync", help="ëŒ€ë³¸(scenes.json)ê³¼ TTS ë…¹ìŒ ë™ê¸°í™” ê²€ì¦")
    verify_sync_parser.add_argument("scene_id", nargs="?", help="ì”¬ ID (ì˜ˆ: s7). ìƒëµí•˜ë©´ ì „ì²´ ê²€ì¦")

    # validate-all ëª…ë ¹ì–´ (visual.json ê²€ì¦)
    validate_parser = subparsers.add_parser("validate-all", help="ëª¨ë“  visual.json ê²€ì¦ (visual-review.md ê¸°ë°˜)")
    validate_parser.add_argument("--no-fix", action="store_true", help="ìë™ ìˆ˜ì • ë¹„í™œì„±í™”")

    # tts ëª…ë ¹ì–´
    tts_parser = subparsers.add_parser("tts", help="ë‹¨ì¼ ì”¬ TTS ìƒì„±")
    tts_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID")
    tts_parser.add_argument("--text", "-t", required=True, help="ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸")
    tts_parser.add_argument("--voice", "-v", help="TTS ìŒì„± (ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ì„¤ì •)")
    
    # tts-all ëª…ë ¹ì–´
    tts_all_parser = subparsers.add_parser("tts-all", help="ëª¨ë“  ì”¬ TTS ìƒì„±")
    tts_all_parser.add_argument("--start-from", "-f", type=int, default=1,
                               help="ì‹œì‘í•  ì”¬ ë²ˆí˜¸ (ì˜ˆ: 14ë©´ s14ë¶€í„° ì‹œì‘)")

    # tts-export ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°)
    subparsers.add_parser("tts-export", help="ì™¸ë¶€ ë…¹ìŒìš© í…ìŠ¤íŠ¸ JSON ë‚´ë³´ë‚´ê¸°")

    # audio-check ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ í™•ì¸)
    subparsers.add_parser("audio-check", help="ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ëˆ„ë½ í™•ì¸")

    # audio-process ëª…ë ¹ì–´ (ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ ì²˜ë¦¬)
    subparsers.add_parser("audio-process", help="ì™¸ë¶€ ë…¹ìŒ íŒŒì¼ Whisper ë¶„ì„ + timing.json ìƒì„±")

    # asset-check ëª…ë ¹ì–´ (Supabase ì—ì…‹ ì²´í¬)
    subparsers.add_parser("asset-check", help="ì—ì…‹ ì²´í¬ (Supabase ì¡°íšŒ + ë‹¤ìš´ë¡œë“œ + ëˆ„ë½ ëª©ë¡)")

    # asset-sync ëª…ë ¹ì–´ (ë¡œì»¬ â†’ Supabase ì—…ë¡œë“œ)
    subparsers.add_parser("asset-sync", help="ì—ì…‹ ë™ê¸°í™” (ë¡œì»¬ ì‹ ê·œ íŒŒì¼ â†’ Supabase ì—…ë¡œë“œ)")

    # catalog-update ëª…ë ¹ì–´ (Supabase â†’ asset-catalog.md)
    subparsers.add_parser("catalog-update", help="ì—ì…‹ ì¹´íƒˆë¡œê·¸ ì—…ë°ì´íŠ¸ (Supabaseì—ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°)")

    # render ëª…ë ¹ì–´
    render_parser = subparsers.add_parser("render", help="ë‹¨ì¼ ì”¬ ë Œë”ë§")
    render_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID")
    render_parser.add_argument("--quality", "-q", default="l",
                              choices=["l", "m", "h", "k"],
                              help="ë Œë”ë§ í’ˆì§ˆ")
    render_parser.add_argument("--no-preview", action="store_true",
                              help="ë¯¸ë¦¬ë³´ê¸° ì—†ì´ ë Œë”ë§")
    
    # render-all ëª…ë ¹ì–´
    render_all_parser = subparsers.add_parser("render-all", help="ëª¨ë“  ì”¬ ë Œë”ë§")
    render_all_parser.add_argument("--quality", "-q", default="l",
                                   choices=["l", "m", "h", "k"],
                                   help="ë Œë”ë§ í’ˆì§ˆ")
    
    # render-script ëª…ë ¹ì–´
    subparsers.add_parser("render-script", help="ë Œë”ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")

    # render-collect ëª…ë ¹ì–´
    subparsers.add_parser("render-collect", help="media/videos/ì—ì„œ ë Œë”ë§ ê²°ê³¼ë¬¼ ìˆ˜ì§‘í•˜ì—¬ 8_renders/ë¡œ ë³µì‚¬")

    # prompts-export ëª…ë ¹ì–´
    subparsers.add_parser("prompts-export", help="ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°")
    
    # images-check ëª…ë ¹ì–´
    subparsers.add_parser("images-check", help="ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸")
    
    # images-import ëª…ë ¹ì–´
    images_import_parser = subparsers.add_parser("images-import", help="ì™¸ë¶€ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°")
    images_import_parser.add_argument("--source", "-s", required=True, help="ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ")
    
    # convert ëª…ë ¹ì–´
    convert_parser = subparsers.add_parser("convert", help="í…ìŠ¤íŠ¸ë¥¼ TTSìš©ìœ¼ë¡œ ë³€í™˜")
    convert_parser.add_argument("--text", "-t", required=True, help="ë³€í™˜í•  í…ìŠ¤íŠ¸")
    
    # files ëª…ë ¹ì–´
    subparsers.add_parser("files", help="í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡")

    # help ëª…ë ¹ì–´
    subparsers.add_parser("help", help="ë„ì›€ë§ í‘œì‹œ")

    # subtitle-generate ëª…ë ¹ì–´
    subparsers.add_parser("subtitle-generate", help="ëª¨ë“  ì”¬ SRT ìë§‰ ìƒì„±")

    # subtitle-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ ìë§‰ ìƒì„±)
    subtitle_scene_parser = subparsers.add_parser("subtitle-scene", help="ë‹¨ì¼ ì”¬ SRT ìë§‰ ìƒì„±")
    subtitle_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")

    # tts-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ TTS ì¬ìƒì„± - scenes.jsonì—ì„œ í…ìŠ¤íŠ¸ ìë™ ë¡œë“œ)
    tts_scene_parser = subparsers.add_parser("tts-scene", help="ë‹¨ì¼ ì”¬ TTS ì¬ìƒì„± (scenes.jsonì—ì„œ í…ìŠ¤íŠ¸ ë¡œë“œ)")
    tts_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")

    # render-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ ë Œë”ë§ - ê°„í¸ ë²„ì „)
    render_scene_parser = subparsers.add_parser("render-scene", help="ë‹¨ì¼ ì”¬ Manim ë Œë”ë§")
    render_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")
    render_scene_parser.add_argument("--quality", "-q", default="l", choices=["l", "m", "h", "k"], help="ë Œë”ë§ í’ˆì§ˆ")

    # compose-scene ëª…ë ¹ì–´ (ê°œë³„ ì”¬ í•©ì„± - ê°„í¸ ë²„ì „)
    compose_scene_parser = subparsers.add_parser("compose-scene", help="ë‹¨ì¼ ì”¬ í•©ì„±")
    compose_scene_parser.add_argument("scene_id", help="ì”¬ ID (ì˜ˆ: s7)")
    compose_scene_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # compose ëª…ë ¹ì–´ (ë‹¨ì¼ ì”¬)
    compose_parser = subparsers.add_parser("compose", help="ë‹¨ì¼ ì”¬ í•©ì„± (ë°°ê²½+Manim+ì˜¤ë””ì˜¤+ìë§‰)")
    compose_parser.add_argument("--scene", "-s", required=True, help="ì”¬ ID (ì˜ˆ: s1)")
    compose_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # compose-all ëª…ë ¹ì–´
    compose_all_parser = subparsers.add_parser("compose-all", help="ëª¨ë“  ì”¬ í•©ì„±")
    compose_all_parser.add_argument("--no-subtitle", action="store_true", help="ìë§‰ ì—†ì´ í•©ì„±")

    # transition-generate ëª…ë ¹ì–´
    subparsers.add_parser("transition-generate", help="ì„¹ì…˜ ì „í™˜ í´ë¦½ ìƒì„± + concat_list.txt")

    # merge-final ëª…ë ¹ì–´
    subparsers.add_parser("merge-final", help="ëª¨ë“  ì”¬ì„ ìµœì¢… ì˜ìƒìœ¼ë¡œ ë³‘í•©")

    # split-scenes ëª…ë ¹ì–´
    subparsers.add_parser("split-scenes", help="scenes.jsonì„ ê°œë³„ ì”¬ íŒŒì¼ë¡œ ë¶„í•  (í† í° ì ˆì•½)")

    # narration-extract ëª…ë ¹ì–´ (Narration Designerìš©)
    narration_extract_parser = subparsers.add_parser("narration-extract", help="ì”¬ì—ì„œ narration_display ì¶”ì¶œ (Narration Designerìš©)")
    narration_extract_parser.add_argument("--scenes", "-s", help="ì¶”ì¶œí•  ì”¬ ID (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: s1,s2,s3)")

    # narration-check ëª…ë ¹ì–´ (ë‚˜ë ˆì´ì…˜ íŒŒì¼ ìƒíƒœ í™•ì¸)
    subparsers.add_parser("narration-check", help="ë‚˜ë ˆì´ì…˜ íŒŒì¼ ìƒíƒœ í™•ì¸")

    args = parser.parse_args()
    
    # ëª…ë ¹ì–´ ì—†ìœ¼ë©´ ë„ì›€ë§
    if not args.command:
        print_help()
        return
    
    # ìƒíƒœ ê´€ë¦¬ì ì´ˆê¸°í™”
    state = StateManager()
    
    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "help":
        print_help()
    
    elif args.command == "init":
        project = ProjectManager(state)
        project.init_project(
            title=args.title,
            duration=args.duration,
            style=args.style,
            difficulty=args.difficulty,
            aspect_ratio=args.aspect,
            voice=args.voice
        )
    
    elif args.command == "status":
        project = ProjectManager(state)
        project.show_status()

    elif args.command == "list":
        project = ProjectManager(state)
        project.list_projects()

    elif args.command == "delete":
        project = ProjectManager(state)
        project.delete_project(args.project_id, force=args.force)

    elif args.command == "clean":
        project = ProjectManager(state)
        project.clean_project(
            project_id=args.project,
            folders=args.folders,
            force=args.force
        )

    elif args.command == "reset":
        project = ProjectManager(state)
        project.reset_project(
            project_id=args.project,
            from_phase=args.from_phase,
            force=args.force
        )

    elif args.command == "verify-sync":
        tts = TTSGenerator(state)
        tts.verify_sync(args.scene_id)

    elif args.command == "validate-all":
        validator = ValidatorManager(state)
        auto_fix = not getattr(args, 'no_fix', False)
        validator.validate_all(auto_fix=auto_fix)

    elif args.command == "tts":
        tts = TTSGenerator(state)
        tts.generate(args.scene, args.text, args.voice)
    
    elif args.command == "tts-all":
        tts = TTSGenerator(state)
        start_from = getattr(args, 'start_from', 1)
        tts.generate_all_from_scenes(start_from=start_from)

    elif args.command == "tts-export":
        tts = TTSGenerator(state)
        tts.export_texts()

    elif args.command == "audio-check":
        tts = TTSGenerator(state)
        tts.check_audio_files()

    elif args.command == "audio-process":
        tts = TTSGenerator(state)
        tts.process_audio_files()

    elif args.command == "asset-check":
        assets = AssetManager(state)
        assets.check_assets()

    elif args.command == "asset-sync":
        assets = AssetManager(state)
        assets.sync_assets()

    elif args.command == "catalog-update":
        assets = AssetManager(state)
        assets.update_catalog()

    elif args.command == "render":
        renderer = RenderManager(state)
        renderer.render_scene(
            args.scene,
            quality=args.quality,
            preview=not args.no_preview
        )
    
    elif args.command == "render-all":
        renderer = RenderManager(state)
        renderer.render_all(quality=args.quality, preview=False)
    
    elif args.command == "render-script":
        renderer = RenderManager(state)
        renderer.generate_render_script()

    elif args.command == "render-collect":
        renderer = RenderManager(state)
        renderer.collect_renders()

    elif args.command == "prompts-export":
        images = ImageManager(state)
        images.export_prompts()
    
    elif args.command == "images-check":
        images = ImageManager(state)
        images.check_images()
    
    elif args.command == "images-import":
        images = ImageManager(state)
        images.import_images(args.source)
    
    elif args.command == "convert":
        result = convert_to_tts_text(args.text)
        print(f"\nì…ë ¥: {args.text}")
        print(f"ë³€í™˜: {result}")
    
    elif args.command == "files":
        files = FileManager(state)
        file_list = files.list_files()

        if not file_list:
            print("âŒ í™œì„± í”„ë¡œì íŠ¸ê°€ ì—†ê±°ë‚˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("\nğŸ“ í”„ë¡œì íŠ¸ íŒŒì¼:")
            for folder, items in sorted(file_list.items()):
                print(f"\n  {folder}/")
                for item in sorted(items):
                    print(f"    - {item}")

    elif args.command == "subtitle-generate":
        composer = ComposerManager(state)
        composer.generate_subtitles()

    elif args.command == "subtitle-scene":
        composer = ComposerManager(state)
        composer.generate_subtitle_for_scene(args.scene_id)

    elif args.command == "tts-scene":
        tts = TTSGenerator(state)
        tts.generate_for_scene(args.scene_id)

    elif args.command == "render-scene":
        renderer = RenderManager(state)
        renderer.render_scene(args.scene_id, quality=args.quality, preview=False)

    elif args.command == "compose-scene":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_scene(args.scene_id, with_subtitle=with_subtitle)

    elif args.command == "compose":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_scene(args.scene, with_subtitle=with_subtitle)

    elif args.command == "compose-all":
        composer = ComposerManager(state)
        with_subtitle = not getattr(args, 'no_subtitle', False)
        composer.compose_all(with_subtitle=with_subtitle)

    elif args.command == "transition-generate":
        composer = ComposerManager(state)
        composer.transition_generate()

    elif args.command == "merge-final":
        composer = ComposerManager(state)
        composer.merge_final()

    elif args.command == "split-scenes":
        scene_splitter = SceneSplitter(state)
        scene_splitter.split()

    elif args.command == "narration-extract":
        extractor = NarrationExtractor(state)
        scene_ids = None
        if hasattr(args, 'scenes') and args.scenes:
            scene_ids = [s.strip() for s in args.scenes.split(',')]
        extractor.extract(scene_ids)

    elif args.command == "narration-check":
        extractor = NarrationExtractor(state)
        extractor.check_narrations()

    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {args.command}")
        print("   python math_video_pipeline.py help ë¡œ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”.")


# ============================================================================
# ì§„ì…ì 
# ============================================================================

if __name__ == "__main__":
    main()


